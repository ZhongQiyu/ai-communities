# -*- coding: utf-8 -*-
"""multi_modal_clinical_diagnostics.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Chg9mavivZANZ8FxPs-M76hl-2aOm_3S

# Single-Modal Learning Tasks
- Audio
- Text
- Image
- Graph
- Time-Series

## Preprocessing
"""

from google.colab import drive

drive.mount("/content/drive")

"""## Audio (Audio Processing)"""

# 1. éŸ³é¢‘è½¬æ–‡æœ¬
transcribed_text = asr_system.transcribe("audio_file.wav")

# 2. æ–‡æœ¬åˆ†æ
entities, relations = nlp_process(transcribed_text)

# 3. æ„å»ºçŸ¥è¯†å›¾è°±
graph = build_knowledge_graph(entities, relations)

# 4. çŸ¥è¯†å›¾è°±åˆ†æ
analysis_results = analyze_graph(graph)

"""### Load the Audio File"""

audio_file = "drive/MyDrive/å“ãå‘¼ã²ã‚™å£°ã®å½¼æ–¹ã¸.wav"

"""### Simulation:
- Random Forest
- Support Vector Machine
"""

import librosa
import numpy as np
import soundfile as sf
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# ç”Ÿæˆæ¨¡æ‹ŸéŸ³é¢‘æ•°æ®çš„å‡½æ•°
def generate_sine_wave(freq, sample_rate, duration):
    x = np.linspace(0, duration, sample_rate * duration, endpoint=False)
    frequencies = x * freq
    y = np.sin((2 * np.pi) * frequencies)
    return y

# åŠ è½½éŸ³é¢‘æ–‡ä»¶å¹¶æå–ç‰¹å¾
def extract_features(audio, sample_rate):
    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)
    mfccs_processed = np.mean(mfccs.T, axis=0)
    return mfccs_processed

# è®¾ç½®æ ·æœ¬ç‡å’ŒæŒç»­æ—¶é—´
sample_rate = 22050
duration = 5

# ç”Ÿæˆä¸‰ä¸ªä¸åŒé¢‘ç‡çš„éŸ³é¢‘
audio1 = generate_sine_wave(440, sample_rate, duration)  # A4
audio2 = generate_sine_wave(880, sample_rate, duration)  # A5
audio3 = generate_sine_wave(1760, sample_rate, duration) # A6

# æå–ç‰¹å¾
features = []
for audio in [audio1, audio2, audio3]:
    features.append(extract_features(audio, sample_rate))

features = np.array(features)
labels = np.array([0, 1, 0])  # å‡è®¾æ ‡ç­¾

# åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)

# è®­ç»ƒ SVM æ¨¡å‹
svm_model = SVC(kernel='linear')
svm_model.fit(X_train, y_train)

# è®­ç»ƒéšæœºæ£®æ—æ¨¡å‹
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# é¢„æµ‹å¹¶è¯„ä¼° SVM æ¨¡å‹
svm_predictions = svm_model.predict(X_test)
svm_accuracy = accuracy_score(y_test, svm_predictions)
print(f"SVM Model Accuracy: {svm_accuracy}")

# é¢„æµ‹å¹¶è¯„ä¼°éšæœºæ£®æ—æ¨¡å‹
rf_predictions = rf_model.predict(X_test)
rf_accuracy = accuracy_score(y_test, rf_predictions)
print(f"Random Forest Model Accuracy: {rf_accuracy}")

"""### Pre-processing"""

def extract_features_from_signal(audio_signal, sample_rate):
    # æå–MFCCç‰¹å¾
    mfccs = librosa.feature.mfcc(y=audio_signal, sr=sample_rate, n_mfcc=13)

    # è®¡ç®—MFCCç‰¹å¾çš„ç»Ÿè®¡æ•°æ®
    mfccs_mean = np.mean(mfccs, axis=1)
    mfccs_std = np.std(mfccs, axis=1)

    # æå–éŸ³è°±è´¨å¿ƒç‰¹å¾
    spectral_centroid = librosa.feature.spectral_centroid(y=audio_signal, sr=sample_rate)
    spectral_centroid_mean = np.mean(spectral_centroid)
    spectral_centroid_std = np.std(spectral_centroid)

    # æå–è‰²åº¦é¢‘ç‡ç‰¹å¾
    chroma_stft = librosa.feature.chroma_stft(y=audio_signal, sr=sample_rate)
    chroma_stft_mean = np.mean(chroma_stft, axis=1)
    chroma_stft_std = np.std(chroma_stft, axis=1)

    # æå–å£°è°±æ»šé™ç‚¹ç‰¹å¾
    spectral_rolloff = librosa.feature.spectral_rolloff(y=audio_signal, sr=sample_rate)
    spectral_rolloff_mean = np.mean(spectral_rolloff)
    spectral_rolloff_std = np.std(spectral_rolloff)

    # æå–é›¶äº¤å‰ç‡ç‰¹å¾
    zero_crossing_rate = librosa.feature.zero_crossing_rate(y=audio_signal)
    zero_crossing_rate_mean = np.mean(zero_crossing_rate)
    zero_crossing_rate_std = np.std(zero_crossing_rate)

    # æå–å£°è°±å¸¦å®½ç‰¹å¾
    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=audio_signal, sr=sample_rate)
    spectral_bandwidth_mean = np.mean(spectral_bandwidth)
    spectral_bandwidth_std = np.std(spectral_bandwidth)

    # æå–å£°è°±å¯¹æ¯”åº¦ç‰¹å¾
    spectral_contrast = librosa.feature.spectral_contrast(y=audio_signal, sr=sample_rate)
    spectral_contrast_mean = np.mean(spectral_contrast, axis=1)
    spectral_contrast_std = np.std(spectral_contrast, axis=1)

    # å°†æ‰€æœ‰ç‰¹å¾åˆå¹¶æˆä¸€ä¸ªç‰¹å¾å‘é‡
    features = np.hstack((
        mfccs_mean, mfccs_std,
        spectral_centroid_mean, spectral_centroid_std,
        chroma_stft_mean, chroma_stft_std,
        spectral_rolloff_mean, spectral_rolloff_std,
        zero_crossing_rate_mean, zero_crossing_rate_std,
        spectral_bandwidth_mean, spectral_bandwidth_std,
        spectral_contrast_mean, spectral_contrast_std
    ))

    return features

"""### Emotion Analysis

#### Analytics
"""

def analyze_music_emotion_timeseries(audio_signal, sample_rate, window_size=5):
    # çª—å£å¤§å°ä»¥ç§’ä¸ºå•ä½
    hop_length = int(window_size * sample_rate)

    # åˆ†å‰²æˆçª—å£
    num_windows = len(audio_signal) // hop_length
    emotions_timeseries = []

    for i in range(num_windows):
        start = i * hop_length
        end = start + hop_length
        window_signal = audio_signal[start:end]

        # æå–çª—å£ä¿¡å·çš„ç‰¹å¾
        features = extract_features_from_signal(window_signal, sample_rate)
        # åˆ†ææƒ…æ„Ÿ
        emotion = analyze_music_emotion(features)
        emotions_timeseries.append(emotion)

    return emotions_timeseries

# å…¶ä»–å‡½æ•°å®šä¹‰ä¿æŒä¸å˜ï¼Œåªå±•ç¤ºä¸»ç¨‹åºéƒ¨åˆ†
audio_signal, sample_rate = librosa.load(audio_file, sr=None)

# æ—¶é—´åºåˆ—æƒ…æ„Ÿåˆ†æ
emotions_timeseries = analyze_music_emotion_timeseries(audio_signal, sample_rate, 2.5)

"""#### Visualization"""

# ç»˜åˆ¶æƒ…æ„Ÿæ—¶é—´åºåˆ—å›¾
def plot_emotion_timeseries(emotions_timeseries):
    # å°†æƒ…æ„Ÿè½¬æ¢ä¸ºæ•°å­—ä»¥ä¾¿ç»˜å›¾
    emotions_to_num = {'Happy': 1, 'Excited': 2, 'Calm': 3, 'Sad': 4}
    numeric_emotions = [emotions_to_num[e] for e in emotions_timeseries]

    # ç»˜å›¾
    plt.figure(figsize=(14, 5))
    plt.plot(numeric_emotions, marker='o', linestyle='-')
    plt.yticks([1, 2, 3, 4], ['Happy', 'Excited', 'Calm', 'Sad'])
    plt.title("Music Emotion Timeseries")
    plt.xlabel("Time Window")
    plt.ylabel("Emotion")
    plt.show()

plot_emotion_timeseries(emotions_timeseries)

"""#### Prediction: SVM"""

æœ‰æ²¡æœ‰

"""#### Prediction: Random Forest"""



"""#### Prediction: RNN"""

import librosa
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, GRU, Dense, Flatten, Conv2D, MaxPooling2D, GlobalAveragePooling2D
from tensorflow.keras.applications import MobileNetV2  # ç”¨äºMusiCNNç¤ºä¾‹

num_classes = 2  # æ ¹æ®ä½ çš„æƒ…æ„Ÿåˆ†ç±»æ•°ç›®è¿›è¡Œè®¾ç½®

# æå–éŸ³é¢‘ç‰¹å¾
def extract_audio_features(audio_file):
    signal, rate = librosa.load(audio_file)

    # æå–MFCCç‰¹å¾
    mfccs = librosa.feature.mfcc(y=signal, sr=rate, n_mfcc=13)
    mfccs_mean = np.mean(mfccs, axis=1)

    # æå–éŸ³è°±è´¨å¿ƒç‰¹å¾
    spectral_centroid = librosa.feature.spectral_centroid(y=signal, sr=rate)
    spectral_centroid_mean = np.mean(spectral_centroid)

    return mfccs_mean, spectral_centroid_mean

# è¿›è¡ŒéŸ³ä¹æƒ…æ„Ÿåˆ†æ
def analyze_music_emotion(audio_file, model):
    mfccs, spectral_centroid = extract_audio_features(audio_file)

    # åœ¨è¿™é‡Œï¼Œä½ å¯ä»¥ä½¿ç”¨é€‚åˆçš„æ¨¡å‹è¿›è¡Œæƒ…æ„Ÿåˆ†ç±»
    # æ³¨æ„ï¼šè¿™é‡Œçš„æ¨¡å‹ç¤ºä¾‹æ˜¯éšæœºåˆå§‹åŒ–çš„ï¼Œä½ éœ€è¦åŠ è½½é¢„è®­ç»ƒçš„æƒé‡æ¥è·å¾—æ›´å¥½çš„æ€§èƒ½

    # ç¤ºä¾‹ï¼šä½¿ç”¨LSTMæ¨¡å‹è¿›è¡Œæƒ…æ„Ÿåˆ†ç±»
    input_shape = (mfccs.shape[0], 1, mfccs.shape[1])
    mfccs = np.expand_dims(mfccs, axis=2)  # æ·»åŠ ä¸€ä¸ªç»´åº¦ä»¥åŒ¹é…è¾“å…¥å½¢çŠ¶
    emotion = model.predict(np.expand_dims(mfccs, axis=0))

    return emotion

"""#### Prediction: LSTM"""

def build_lstm_model(input_shape, num_classes):
    model = Sequential()
    model.add(LSTM(128, input_shape=input_shape, return_sequences=True))
    model.add(LSTM(128, return_sequences=True))
    model.add(LSTM(128))
    model.add(Dense(num_classes, activation='softmax'))
    return model

# æ„å»ºå’Œç¼–è¯‘LSTMæ¨¡å‹
lstm_model = build_lstm_model(input_shape=(None, num_classes), num_classes=num_classes)
lstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

"""#### Prediction: GRU"""

def build_gru_model(input_shape, num_classes):
    model = Sequential()
    model.add(GRU(128, input_shape=input_shape, return_sequences=True))
    model.add(GRU(128, return_sequences=True))
    model.add(GRU(128))
    model.add(Dense(num_classes, activation='softmax'))
    return model

# æ„å»ºå’Œç¼–è¯‘GRUæ¨¡å‹
    gru_model = build_gru_model(input_shape=(None, num_classes), num_classes=num_classes)
    gru_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

"""#### Prediction: MusiCNN"""

import librosa
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import matplotlib.pyplot as plt

class AudioCNN(nn.Module):
    def __init__(self, input_size, num_classes):
        super(AudioCNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)
        self.pool = nn.MaxPool2d(2, 2, padding=1)  # å¢åŠ  padding
        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)
        self.fc1 = nn.Linear(32 * (input_size[1] // 4) * (input_size[2] // 4), 128)  # å¢åŠ å…¨è¿æ¥å±‚å•å…ƒæ•°
        self.fc2 = nn.Linear(128, num_classes)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(-1, 32 * (x.size()[2] // 4) * (x.size()[3] // 4))
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x

def build_musicnn_model(input_shape, num_classes):
    model = AudioCNN(input_shape, num_classes)  # ä½¿ç”¨è‡ªå®šä¹‰çš„éŸ³é¢‘CNNæ¨¡å‹
    return model

# æ„å»ºå’Œç¼–è¯‘MusiCNNæ¨¡å‹
musicnn_model = build_musicnn_model(input_shape=(224, 224, 3), num_classes=2)
musicnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

"""#### Prediction: MusiCOG"""

# æ„å»ºMusiCOGæ¨¡å‹
def build_musicog_model(input_shape, num_classes):
    model = Sequential()
    model.add(Conv2D(64, (3, 3), activation='relu', input_shape=input_shape))
    model.add(MaxPooling2D((2, 2)))
    model.add(Conv2D(128, (3, 3), activation='relu'))
    model.add(MaxPooling2D((2, 2)))
    model.add(Flatten())
    model.add(Dense(128, activation='relu'))
    model.add(Dense(num_classes, activation='softmax'))
    return model

# æ„å»ºå’Œç¼–è¯‘MusiCOGæ¨¡å‹
musicog_model = build_musicog_model(input_shape=(mfccs.shape[0], mfccs.shape[1], 1), num_classes=num_classes)
musicog_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# ä¸»ç¨‹åº

# åˆ†æéŸ³ä¹æƒ…æ„Ÿå¹¶è¾“å‡ºç»“æœ
lstm_emotion = analyze_music_emotion(audio_file, lstm_model)
gru_emotion = analyze_music_emotion(audio_file, gru_model)
musicnn_emotion = analyze_music_emotion(audio_file, musicnn_model)
musicog_emotion = analyze_music_emotion(audio_file, musicog_model)

print(f"LSTM æ¨¡å‹çš„æƒ…æ„Ÿåˆ†æç»“æœï¼š{lstm_emotion}")
print(f"GRU æ¨¡å‹çš„æƒ…æ„Ÿåˆ†æç»“æœï¼š{gru_emotion}")
print(f"MusiCNN æ¨¡å‹çš„æƒ…æ„Ÿåˆ†æç»“æœï¼š{musicnn_emotion}")
print(f"MusiCOG æ¨¡å‹çš„æƒ…æ„Ÿåˆ†æç»“æœï¼š{musicog_emotion}")

"""#### Prediction: MusicBERT"""



"""#### RAG"""

!pip install google-cloud-speech transformers datasets

from google.cloud import speech

def audio_to_text(audio_file_path):
    client = speech.SpeechClient()

    with open(audio_file_path, "rb") as audio_file:
        content = audio_file.read()

    audio = speech.RecognitionAudio(content=content)
    config = speech.RecognitionConfig(
        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
        sample_rate_hertz=16000,
        language_code="en-US",
    )

    response = client.recognize(config=config, audio=audio)

    transcript = " ".join([result.alternatives[0].transcript for result in response.results])
    return transcript

from transformers import RagTokenizer, RagTokenForGeneration

tokenizer = RagTokenizer.from_pretrained("facebook/rag-token-nq")
model = RagTokenForGeneration.from_pretrained("facebook/rag-token-nq")

def generate_response(text_input):
    inputs = tokenizer(text_input, return_tensors="pt")
    output_ids = model.generate(**inputs)
    response_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)
    return response_text

import networkx as nx

def build_graph(text_input, response_text):
    G = nx.Graph()
    G.add_node("input", text=text_input)
    G.add_node("response", text=response_text)
    G.add_edge("input", "response", relation="generates")
    return G

# ç¤ºä¾‹æµç¨‹
audio_file_path = "path/to/your/audio.wav"
text_input = audio_to_text(audio_file_path)
response_text = generate_response(text_input)
G = build_graph(text_input, response_text)

# åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼ŒGæ˜¯ä¸€ä¸ªåŒ…å«è¾“å…¥æ–‡æœ¬å’ŒRAGç”Ÿæˆçš„å“åº”æ–‡æœ¬çš„ç®€å•å›¾

"""#### Prediction:

## Text (Natural Language Processing)
"""

import torch
import numpy as np
from sklearn.pipeline import make_pipeline
from sklearn.metrics import accuracy_score
from sklearn.naive_bayes import MultinomialNB
from sklearn.datasets import fetch_20newsgroups
from torch.utils.data import DataLoader, TensorDataset
from sklearn.feature_extraction.text import CountVectorizer

# åŠ è½½æ•°æ®é›†
data = fetch_20newsgroups(subset='train', categories=['sci.space', 'rec.autos'])
X_train, y_train = data.data, data.target

data_test = fetch_20newsgroups(subset='test', categories=['sci.space', 'rec.autos'])
X_test, y_test = data_test.data, data_test.target

"""### Naive Bayes (NB)"""

# åˆ›å»ºä¸€ä¸ªç®¡é“ï¼ŒåŒ…æ‹¬æ–‡æœ¬å‘é‡åŒ–å’Œæœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨
model = make_pipeline(CountVectorizer(), MultinomialNB())

# è®­ç»ƒæ¨¡å‹
model.fit(X_train, y_train)

# é¢„æµ‹å’Œè¯„ä¼°
predicted = model.predict(X_test)
print("Accuracy:", accuracy_score(y_test, predicted))

"""### Logistic Regression (LR)"""

from sklearn.linear_model import LogisticRegression

# ä½¿ç”¨åŒæ ·çš„æ•°æ®é›†å’Œå‘é‡åŒ–æ–¹æ³•
model_lr = make_pipeline(CountVectorizer(), LogisticRegression())

# è®­ç»ƒæ¨¡å‹
model_lr.fit(X_train, y_train)

# é¢„æµ‹å’Œè¯„ä¼°
predicted_lr = model_lr.predict(X_test)
print("Accuracy:", accuracy_score(y_test, predicted_lr))

"""### Multi-Layer Perceptron (MLP)"""

from sklearn.feature_extraction.text import CountVectorizer
import torch

# å°†æ•°æ®ä¿è¯ä¸ºå­—ç¬¦ä¸²
X_train = [str(text) for text in X_train]
X_test = [str(text) for text in X_test]

# ä½¿ç”¨ CountVectorizer è½¬æ¢æ–‡æœ¬æ•°æ®
vectorizer = CountVectorizer(max_features=5000, stop_words='english')
X_train_vec = vectorizer.fit_transform(X_train).toarray()
X_test_vec = vectorizer.transform(X_test).toarray()

# å°†æ•°æ®è½¬æ¢ä¸º torch å¼ é‡
X_train_torch = torch.tensor(X_train_vec, dtype=torch.float32)
y_train_torch = torch.tensor(y_train, dtype=torch.long)
X_test_torch = torch.tensor(X_test_vec, dtype=torch.float32)
y_test_torch = torch.tensor(y_test, dtype=torch.long)

# åˆ›å»º DataLoader
train_dataset = TensorDataset(X_train_torch, y_train_torch)
train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)

import torch
import torch.nn as nn
import torch.optim as optim

class MLP(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim):
        super(MLP, self).__init__()
        self.fc1 = nn.Linear(input_dim, hidden_dim)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(hidden_dim, output_dim)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        return x

# å®ä¾‹åŒ–æ¨¡å‹
model_mlp = MLP(input_dim, hidden_dim, 2)

# å®šä¹‰ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°
optimizer = optim.Adam(model_mlp.parameters(), lr=0.001)
criterion = nn.CrossEntropyLoss()

# è®­ç»ƒå¾ªç¯
for epoch in range(num_epochs):
    for inputs, labels in train_loader:
        optimizer.zero_grad()
        outputs = model_mlp(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
    print(f"Epoch {epoch+1}/{num_epochs} completed.")

# æµ‹è¯•æ¨¡å‹
model_mlp.eval()
with torch.no_grad():
    outputs = model_mlp(X_test_torch)
    _, predicted = torch.max(outputs, 1)
    accuracy = (predicted == y_test_torch).float().mean()
    print(f"Accuracy: {accuracy.item() * 100:.2f}%")

"""### Word2Vec + NB"""

import gensim
from sklearn.datasets import fetch_20newsgroups
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import classification_report
import numpy as np

# åŠ è½½æ•°æ®é›†
data = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))
texts = data.data
labels = data.target

# é¢„å¤„ç†å’Œåˆ†è¯
def preprocess(text):
    return gensim.utils.simple_preprocess(text)

texts = [preprocess(text) for text in texts]

# è®­ç»ƒ Word2Vec æ¨¡å‹
model_w2v = gensim.models.Word2Vec(sentences=texts, vector_size=100, window=5, min_count=2, workers=4)

# å°†æ–‡æ¡£è½¬æ¢ä¸ºè¯å‘é‡çš„å¹³å‡å€¼
def document_vector(doc):
    # ç§»é™¤ä¸åœ¨è¯æ±‡è¡¨ä¸­çš„è¯
    doc = [word for word in doc if word in model_w2v.wv.index_to_key]
    return np.mean(model_w2v.wv[doc], axis=0) if doc else np.zeros(model_w2v.vector_size)

vectors = np.array([document_vector(doc) for doc in texts])

# åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
X_train, X_test, y_train, y_test = train_test_split(vectors, labels, test_size=0.25, random_state=42)

# è®­ç»ƒæœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨
classifier = GaussianNB()
classifier.fit(X_train, y_train)

# é¢„æµ‹å’Œè¯„ä¼°
y_pred = classifier.predict(X_test)
print(classification_report(y_test, y_pred))

"""### Word2Vec + LR"""

from sklearn.datasets import fetch_20newsgroups
from gensim.models import Word2Vec
from gensim.utils import simple_preprocess
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report
import numpy as np

# åŠ è½½æ•°æ®é›†
data_train = fetch_20newsgroups(subset='train', categories=['sci.space', 'rec.autos'])
data_test = fetch_20newsgroups(subset='test', categories=['sci.space', 'rec.autos'])

# æ–‡æœ¬é¢„å¤„ç†å’Œåˆ†è¯
texts_train = [simple_preprocess(doc) for doc in data_train.data]
texts_test = [simple_preprocess(doc) for doc in data_test.data]

# è®­ç»ƒ Word2Vec æ¨¡å‹
model_w2v = Word2Vec(sentences=texts_train, vector_size=100, window=5, min_count=1, workers=4)

# å®šä¹‰ä¸€ä¸ªå‡½æ•°æ¥è·å–æ–‡æ¡£çš„å¹³å‡å‘é‡
def document_vector(doc):
    # ç§»é™¤ä¸åœ¨è¯æ±‡è¡¨ä¸­çš„å•è¯
    doc = [word for word in doc if word in model_w2v.wv]
    if len(doc) == 0:
        return np.zeros(model_w2v.vector_size)
    return np.mean(model_w2v.wv[doc], axis=0)

# å‘é‡åŒ–è®­ç»ƒå’Œæµ‹è¯•æ•°æ®
X_train = np.array([document_vector(text) for text in texts_train])
X_test = np.array([document_vector(text) for text in texts_test])

# è®­ç»ƒ Logistic Regression åˆ†ç±»å™¨
y_train = data_train.target
y_test = data_test.target

classifier = LogisticRegression(max_iter=1000)
classifier.fit(X_train, y_train)

# é¢„æµ‹å’Œè¯„ä¼°
predictions = classifier.predict(X_test)
print(classification_report(y_test, predictions, target_names=data_test.target_names))

"""### Word2Vec + MLP"""

from gensim.models import Word2Vec
from gensim.utils import simple_preprocess
from sklearn.datasets import fetch_20newsgroups
import numpy as np
import torch
from torch.utils.data import DataLoader, TensorDataset

# åŠ è½½æ•°æ®é›†
data_train = fetch_20newsgroups(subset='train', categories=['sci.space', 'rec.autos'])
data_test = fetch_20newsgroups(subset='test', categories=['sci.space', 'rec.autos'])

# æ–‡æœ¬é¢„å¤„ç†å’Œåˆ†è¯
texts_train = [simple_preprocess(doc) for doc in data_train.data]
texts_test = [simple_preprocess(doc) for doc in data_test.data]

# è®­ç»ƒ Word2Vec æ¨¡å‹
model_w2v = Word2Vec(sentences=texts_train, vector_size=5000, window=5, min_count=1, workers=4)

# å®šä¹‰å‡½æ•°æ¥å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡
def document_vector(model, doc):
    # ç§»é™¤ä¸åœ¨è¯æ±‡è¡¨ä¸­çš„è¯
    doc = [word for word in doc if word in model.wv.key_to_index]
    return np.mean(model.wv[doc], axis=0) if len(doc) > 0 else np.zeros(model.vector_size)

# å‘é‡åŒ–è®­ç»ƒå’Œæµ‹è¯•æ•°æ®
X_train = np.array([document_vector(model_w2v, doc) for doc in texts_train])
X_test = np.array([document_vector(model_w2v, doc) for doc in texts_test])

# å‡è®¾çš„ç›®æ ‡å˜é‡ (è¿™é‡Œç”¨éšæœºç”Ÿæˆçš„æ•°æ®ä½œä¸ºç¤ºä¾‹)
y_train = np.random.rand(len(texts_train))
y_test = np.random.rand(len(texts_test))

# è½¬æ¢æ•°æ®ä¸ºå¼ é‡
X_train_tensor = torch.tensor(X_train, dtype=torch.float32)
X_test_tensor = torch.tensor(X_test, dtype=torch.float32)
y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)
y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)

# æ•°æ®åŠ è½½å™¨
train_data = TensorDataset(X_train_tensor, y_train_tensor)
train_loader = DataLoader(train_data, batch_size=4, shuffle=True)

def test_model(model, test_loader, criterion):
    model.eval()
    total_loss = 0
    with torch.no_grad():
        for inputs, labels in test_loader:
            outputs = model(inputs)
            loss = criterion(outputs.squeeze(), labels)
            total_loss += loss.item()
    return total_loss / len(test_loader)

# åˆ›å»ºæµ‹è¯•æ•°æ®çš„ DataLoader
test_data = TensorDataset(X_test_tensor, y_test_tensor)
test_loader = DataLoader(test_data, batch_size=4)

# æµ‹è¯•æ¨¡å‹
test_loss = test_model(model_mlp, test_loader, criterion)
print(f"Test Loss: {test_loss:.4f}")

"""### Word2Vec + Average Bag of Words (ABoW) + NB"""

from gensim.models import Word2Vec
from gensim.utils import simple_preprocess
from sklearn.datasets import fetch_20newsgroups
from sklearn.naive_bayes import MultinomialNB
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import classification_report
import numpy as np

# åŠ è½½æ•°æ®é›†
data_train = fetch_20newsgroups(subset='train', categories=['sci.space', 'rec.autos'])
data_test = fetch_20newsgroups(subset='test', categories=['sci.space', 'rec.autos'])

# æ–‡æœ¬é¢„å¤„ç†å’Œåˆ†è¯
texts_train = [simple_preprocess(doc) for doc in data_train.data]
texts_test = [simple_preprocess(doc) for doc in data_test.data]

# è®­ç»ƒ Word2Vec æ¨¡å‹
model_w2v = Word2Vec(sentences=texts_train, vector_size=100, window=5, min_count=1, workers=4)

# å®šä¹‰å‡½æ•°ï¼Œå°†æ–‡æœ¬è½¬æ¢ä¸ºå¹³å‡ Word2Vec å‘é‡
def document_vector(doc):
    # ç§»é™¤ä¸åœ¨è¯æ±‡è¡¨ä¸­çš„è¯
    doc = [word for word in doc if word in model_w2v.wv]
    if len(doc) == 0:
        return np.zeros(model_w2v.vector_size)
    # è®¡ç®—æ–‡æ¡£çš„å¹³å‡ Word2Vec å‘é‡
    return np.mean(model_w2v.wv[doc], axis=0)

# å‘é‡åŒ–è®­ç»ƒå’Œæµ‹è¯•æ•°æ®
X_train = np.array([document_vector(doc) for doc in texts_train])
X_test = np.array([document_vector(doc) for doc in texts_test])

# å°†æ•°æ®å¹³ç§»åˆ°éè´ŸèŒƒå›´
X_train_shifted = X_train - X_train.min()
X_test_shifted = X_test - X_test.min()

# ç„¶åä½¿ç”¨ MultinomialNB
clf = MultinomialNB()
clf.fit(X_train_shifted, data_train.target)

# æµ‹è¯•æ¨¡å‹
y_pred = clf.predict(X_test)
print(classification_report(data_test.target, y_pred, target_names=data_test.target_names))

"""### Word2Vec + ABoW + LR"""

from gensim.models import Word2Vec
from gensim.utils import simple_preprocess
from sklearn.datasets import fetch_20newsgroups
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report
import numpy as np

# æ–‡æœ¬é¢„å¤„ç†å’Œåˆ†è¯
def preprocess_and_tokenize(data):
    return [simple_preprocess(doc) for doc in data]

# åŠ è½½æ•°æ®é›†
data_train = fetch_20newsgroups(subset='train', categories=['sci.space', 'rec.autos'])
data_test = fetch_20newsgroups(subset='test', categories=['sci.space', 'rec.autos'])

texts_train = preprocess_and_tokenize(data_train.data)
texts_test = preprocess_and_tokenize(data_test.data)

# ä½¿ç”¨ Word2Vec è®­ç»ƒè¯å‘é‡
model_w2v = Word2Vec(sentences=texts_train, vector_size=100, window=5, min_count=1, workers=4)

# å®šä¹‰å‡½æ•°ï¼Œå°†æ–‡æœ¬è½¬æ¢ä¸ºåŸºäº Word2Vec çš„å¹³å‡è¯å‘é‡
def get_average_word2vec(tokens_list, vector, generate_missing=False, k=100):
    if len(tokens_list) < 1:
        return np.zeros(k)
    if generate_missing:
        vectorized = [vector[word] if word in vector else np.random.rand(k) for word in tokens_list]
    else:
        vectorized = [vector[word] if word in vector else np.zeros(k) for word in tokens_list]
    length = len(vectorized)
    summed = np.sum(vectorized, axis=0)
    averaged = np.divide(summed, length)
    return averaged

def get_word2vec_embeddings(vectors, clean_comments, generate_missing=False):
    embeddings = clean_comments.apply(lambda x: get_average_word2vec(x, vectors, generate_missing=generate_missing))
    return list(embeddings)

# è·å–è®­ç»ƒå’Œæµ‹è¯•æ•°æ®çš„åµŒå…¥
train_embeddings = get_word2vec_embeddings(model_w2v.wv, pd.Series(texts_train))
test_embeddings = get_word2vec_embeddings(model_w2v.wv, pd.Series(texts_test))

# ä½¿ç”¨é€»è¾‘å›å½’æ¨¡å‹è¿›è¡Œåˆ†ç±»
model_lr = LogisticRegression(max_iter=1000)
model_lr.fit(train_embeddings, data_train.target)

# é¢„æµ‹å’Œè¯„ä¼°æ¨¡å‹
predictions = model_lr.predict(test_embeddings)
print(classification_report(data_test.target, predictions))

"""### Word2Vec + ABoW + MLP"""

# åŠ è½½æ•°æ®é›†
data_train = fetch_20newsgroups(subset='train', categories=['sci.space', 'rec.autos'])
data_test = fetch_20newsgroups(subset='test', categories=['sci.space', 'rec.autos'])

# æ–‡æœ¬é¢„å¤„ç†å’Œåˆ†è¯
texts_train = [simple_preprocess(doc) for doc in data_train.data]
texts_test = [simple_preprocess(doc) for doc in data_test.data]

# è®­ç»ƒ Word2Vec æ¨¡å‹
model_w2v = Word2Vec(sentences=texts_train, vector_size=5000, window=5, min_count=2, workers=4)

# è·å–è¯å‘é‡
def get_vector(text):
    vectors = [model_w2v.wv[word] for word in text if word in model_w2v.wv]
    if len(vectors) == 0:
        return np.zeros(model_w2v.vector_size)
    else:
        return np.mean(vectors, axis=0)

# å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡
vectors_train = [get_vector(text) for text in texts_train]
vectors_test = [get_vector(text) for text in texts_test]

# å‡†å¤‡æµ‹è¯•æ•°æ®
X_test = torch.tensor(vectors_test, dtype=torch.float32)
y_test = torch.tensor(data_test.target, dtype=torch.long)

# è¯„ä¼°æ¨¡å‹
model_mlp.eval()
with torch.no_grad():
    outputs = model_mlp(X_test)
    _, predicted = torch.max(outputs.data, 1)
    total = y_test.size(0)
    correct = (predicted == y_test).sum().item()
    print(f'Accuracy of the model_mlp on the test data: {100 * correct / total}%')

"""### RNNs

#### LSTM
"""

import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.datasets import fetch_20newsgroups
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from torch.utils.data import Dataset, DataLoader
import numpy as np

# åŠ è½½æ•°æ®é›†
data = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))
texts = data.data
targets = [len(text.split()) for text in texts]  # ç®€å•çš„å›å½’ç›®æ ‡ï¼šæ–‡æœ¬é•¿åº¦

# åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
texts_train, texts_test, targets_train, targets_test = train_test_split(texts, targets, test_size=0.2, random_state=42)

# ä½¿ç”¨CountVectorizeræ¥æ„å»ºè¯æ±‡è¡¨
vectorizer = CountVectorizer(max_features=10000).fit(texts_train)
vocab_size = len(vectorizer.vocabulary_)

def create_random_embeddings(vocab_size, embed_size):
    return torch.randn(vocab_size, embed_size)

embedding_dim = 100  # æŒ‡å®šåµŒå…¥ç»´åº¦
embeddings = create_random_embeddings(vocab_size + 1, embedding_dim)

class RNNRegressor(nn.Module):
    def __init__(self, vocab_size, embed_size, hidden_size, embedding_weights):
        super(RNNRegressor, self).__init__()
        self.embedding = nn.Embedding(vocab_size, embed_size)
        self.embedding.weight = nn.Parameter(embedding_weights, requires_grad=False)
        self.rnn = nn.LSTM(embed_size, hidden_size, batch_first=True)
        self.fc = nn.Linear(hidden_size, 1)

    def forward(self, x):
        x = self.embedding(x)
        x, _ = self.rnn(x)
        x = self.fc(x[:, -1, :])
        return x

model = RNNRegressor(vocab_size + 1, embedding_dim, 128, embeddings)

from torch.utils.data import TensorDataset, DataLoader

# æ•°æ®è½¬æ¢å‡½æ•°
def text_to_sequence(texts, word_index, max_len=500):
    sequences = np.zeros((len(texts), max_len))
    for i, text in enumerate(texts):
        words = text.split()
        for j, word in enumerate(words[:max_len]):
            if word in word_index:
                sequences[i, j] = word_index[word]
    return torch.tensor(sequences, dtype=torch.long)

# è®­ç»ƒæ•°æ®å‡†å¤‡
train_sequences = text_to_sequence(texts_train, vectorizer.vocabulary_)
train_targets = torch.tensor(targets_train, dtype=torch.float32)

# å°†æ•°æ®å’Œç›®æ ‡å°è£…åˆ° TensorDataset
train_dataset = TensorDataset(train_sequences, train_targets)

# ä½¿ç”¨ DataLoader æ¥è¿­ä»£æ•°æ®
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

# æ¨¡å‹è®­ç»ƒ
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

num_epochs = 5

for epoch in range(num_epochs):
    model.train()
    for inputs, targets in train_loader:
        inputs, targets = inputs.to(device), targets.to(device)

        optimizer.zero_grad()
        outputs = model(inputs).squeeze()
        loss = criterion(outputs, targets)
        loss.backward()
        optimizer.step()
    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')

# æµ‹è¯•æ•°æ®å‡†å¤‡
test_sequences = text_to_sequence(texts_test, vectorizer.vocabulary_)
test_targets = torch.tensor(targets_test, dtype=torch.float32)

# æµ‹è¯• DataLoader
test_data = TensorDataset(test_sequences, test_targets)
test_loader = DataLoader(test_data, batch_size=32)

def evaluate_model(model, data_loader, criterion, device):
    model.eval()  # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼
    total_loss = 0
    with torch.no_grad():  # ä¸è®¡ç®—æ¢¯åº¦
        for inputs, targets in data_loader:
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = model(inputs).squeeze()
            loss = criterion(outputs, targets)
            total_loss += loss.item()
    return total_loss / len(data_loader)

best_loss = float('inf')
best_model = None

for epoch in range(num_epochs):
    model.train()
    for inputs, targets in train_loader:
        inputs, targets = inputs.to(device), targets.to(device)
        optimizer.zero_grad()
        outputs = model(inputs).squeeze()
        loss = criterion(outputs, targets)
        loss.backward()
        optimizer.step()

    val_loss = evaluate_model(model, test_loader, criterion, device)
    print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {loss.item()}, Validation Loss: {val_loss}')

    # æ£€æŸ¥æ˜¯å¦æ˜¯æœ€ä½³æ¨¡å‹
    if val_loss < best_loss:
        best_loss = val_loss
        best_model = model.state_dict()

# ç¤ºä¾‹ï¼šå°è¯•ä¸åŒçš„å­¦ä¹ ç‡
learning_rates = [0.001, 0.0005, 0.0001]
best_lr = learning_rates[0]

for lr in learning_rates:
    model = RNNRegressor(vocab_size + 1, embedding_dim, 128, embeddings).to(device)
    optimizer = optim.Adam(model.parameters(), lr=lr)
    # ... é‡å¤è®­ç»ƒå’Œè¯„ä¼°è¿‡ç¨‹ ...

    # å¦‚æœæ–°çš„å­¦ä¹ ç‡è¡¨ç°æ›´å¥½ï¼Œåˆ™æ›´æ–°æœ€ä½³å­¦ä¹ ç‡
    if val_loss < best_loss:
        best_loss = val_loss
        best_lr = lr
        best_model = model.state_dict()

print(f'Best Learning Rate: {best_lr}')

"""#### Single-Layer"""

import torch
import torch.nn as nn

class SingleLayerRNN(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(SingleLayerRNN, self).__init__()
        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        out, _ = self.rnn(x)
        out = self.fc(out[:, -1, :])
        return out

# å®ä¾‹åŒ–æ¨¡å‹
# å‡è®¾è¾“å…¥å¤§å°ä¸º10ï¼Œéšè—å±‚å¤§å°ä¸º20ï¼Œè¾“å‡ºå¤§å°ä¸º2ï¼ˆäºŒåˆ†ç±»é—®é¢˜ï¼‰
single_layer_model = SingleLayerRNN(10, 20, 2)

def train_epoch(self):
        self.model.train()
        for x, y in self.train_loader:
            x, y = x.to(self.device), y.to(self.device).squeeze()  # ç¡®ä¿yæ˜¯ä¸€ç»´çš„
            self.optimizer.zero_grad()
            outputs = self.model(x)
            loss = self.criterion(outputs, y)
            loss.backward()
            self.optimizer.step()

    def validate(self):
        self.model.eval()
        total_loss = 0
        with torch.no_grad():
            for x, y in self.val_loader:
                x, y = x.to(self.device), y.to(self.device).squeeze()  # ç¡®ä¿yæ˜¯ä¸€ç»´çš„
                outputs = self.model(x)
                loss = self.criterion(outputs, y)
                total_loss += loss.item()
        return total_loss / len(self.val_loader)

class ModelTrainer:
    def __init__(self, model, train_loader, val_loader, test_loader, criterion, optimizer, device):
        self.model = model
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.test_loader = test_loader
        self.criterion = criterion
        self.optimizer = optimizer
        self.device = device

    def train_epoch(self):
        self.model.train()
        for x, y in self.train_loader:
            x, y = x.to(self.device), y.to(self.device)
            self.optimizer.zero_grad()
            outputs = self.model(x)
            loss = self.criterion(outputs, y)
            loss.backward()
            self.optimizer.step()

    def validate(self):
        self.model.eval()
        total_loss = 0
        with torch.no_grad():
            for x, y in self.val_loader:
                x, y = x.to(self.device), y.to(self.device)
                outputs = self.model(x)
                loss = self.criterion(outputs, y)
                total_loss += loss.item()
        return total_loss / len(self.val_loader)

    def test(self):
        self.model.eval()
        total_loss = 0
        with torch.no_grad():
            for x, y in self.test_loader:
                x, y = x.to(self.device), y.to(self.device)
                outputs = self.model(x)
                loss = self.criterion(outputs, y)
                total_loss += loss.item()
        return total_loss / len(self.test_loader)

    def train(self, num_epochs):
        for epoch in range(num_epochs):
            self.train_epoch()
            val_loss = self.validate()
            print(f"Epoch {epoch}, Validation Loss: {val_loss}")
        test_loss = self.test()
        print(f"Test Loss: {test_loss}")

"""#### Double-Layer"""

class DoubleLayerRNN(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(DoubleLayerRNN, self).__init__()
        self.rnn = nn.RNN(input_size, hidden_size, num_layers=2, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        out, _ = self.rnn(x)
        out = self.fc(out[:, -1, :])
        return out

model = DoubleLayerRNN(10, 20, 2)

# æˆ–è€…ï¼Œä»¥åŒå±‚RNNä¸ºä¾‹
trainer = ModelTrainer(double_layer_model, train_loader, val_loader, test_loader, criterion, optimizer, device)
trainer.train(num_epochs)

"""#### Multi-Layer"""

import torch
import torch.nn as nn

class MultiLayerRNN(nn.Module):
    def __init__(self, input_size, hidden_size, output_size, num_layers):
        super(MultiLayerRNN, self).__init__()
        self.rnn = nn.RNN(input_size, hidden_size, num_layers=num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        out, _ = self.rnn(x)
        out = self.fc(out[:, -1, :])
        return out

class ModelTrainer:
    def __init__(self, model, train_loader, val_loader, test_loader, criterion, optimizer, device):
        self.model = model
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.test_loader = test_loader
        self.criterion = criterion
        self.optimizer = optimizer
        self.device = device

    def train_epoch(self):
        self.model.train()
        for x, y in self.train_loader:
            x, y = x.to(self.device), y.to(self.device)
            self.optimizer.zero_grad()
            outputs = self.model(x)
            loss = self.criterion(outputs, y)
            loss.backward()
            self.optimizer.step()

    def validate(self):
        self.model.eval()
        total_loss = 0
        with torch.no_grad():
            for x, y in self.val_loader:
                x, y = x.to(self.device), y.to(self.device)
                outputs = self.model(x)
                loss = self.criterion(outputs, y)
                total_loss += loss.item()
        return total_loss / len(self.val_loader)

    def test(self):
        self.model.eval()
        total_loss = 0
        with torch.no_grad():
            for x, y in self.test_loader:
                x, y = x.to(self.device), y.to(self.device)
                outputs = self.model(x)
                loss = self.criterion(outputs, y)
                total_loss += loss.item()
        return total_loss / len(self.test_loader)

    def train(self, num_epochs):
        for epoch in range(num_epochs):
            self.train_epoch()
            val_loss = self.validate()
            print(f"Epoch {epoch}, Validation Loss: {val_loss}")
        test_loss = self.test()
        print(f"Test Loss: {test_loss}")

# å‡è®¾çš„è¾“å…¥å‚æ•°
input_size = 10
hidden_size = 20
output_size = 2
num_layers = 3
num_epochs = 5

# åˆ›å»ºæ¨¡å‹ã€æŸå¤±å‡½æ•°ã€ä¼˜åŒ–å™¨
model = MultiLayerRNN(input_size, hidden_size, output_size, num_layers).to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# å‡è®¾çš„æ•°æ®åŠ è½½å™¨ï¼ˆéœ€è¦æ›¿æ¢ä¸ºçœŸå®çš„DataLoaderï¼‰
train_loader, val_loader, test_loader = None, None, None

# è®­ç»ƒæ¨¡å‹
trainer = ModelTrainer(model, train_loader, val_loader, test_loader, criterion, optimizer, device)
trainer.train(num_epochs)

"""#### LSTM"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.preprocessing import LabelEncoder
from tqdm import tqdm
import numpy as np

# å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªCSVæ–‡ä»¶ï¼ŒåŒ…å«ä¸¤åˆ—ï¼šè¯„è®ºæ–‡æœ¬å’Œæƒ…æ„Ÿæ ‡ç­¾ï¼ˆæ­£é¢/è´Ÿé¢ï¼‰
class IMDBDataset(Dataset):
    def __init__(self, reviews, labels):
        self.reviews = reviews
        self.labels = labels

    def __len__(self):
        return len(self.reviews)

    def __getitem__(self, idx):
        return torch.tensor(self.reviews[idx], dtype=torch.float32), torch.tensor(self.labels[idx], dtype=torch.long)

# åŠ è½½æ•°æ®
df = pd.read_csv('/content/drive/MyDrive/IMDB Dataset.csv')
reviews = df['review']
labels = LabelEncoder().fit_transform(df['sentiment'])

# å°†æ–‡æœ¬è½¬æ¢ä¸ºå›ºå®šé•¿åº¦çš„æ•°å­—å‘é‡
vectorizer = CountVectorizer(max_features=5000)  # é€‰æ‹©æœ€å¸¸è§çš„5000ä¸ªè¯
reviews = vectorizer.fit_transform(reviews).toarray()
reviews = np.array(reviews)

# åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
train_reviews, test_reviews, train_labels, test_labels = train_test_split(reviews, labels, test_size=0.2, random_state=42)

train_dataset = IMDBDataset(train_reviews, train_labels)
test_dataset = IMDBDataset(test_reviews, test_labels)

train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)

class LSTMClassifier(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):
        super(LSTMClassifier, self).__init__()
        self.hidden_dim = hidden_dim
        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_dim, output_dim)

    def forward(self, x):
        x = x.unsqueeze(1)  # æ·»åŠ ä¸€ä¸ªåºåˆ—é•¿åº¦çš„ç»´åº¦
        lstm_out, _ = self.lstm(x)
        out = self.fc(lstm_out[:, -1, :])  # åªå–æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å‡º
        return out

# æ¨¡å‹å®ä¾‹åŒ–
model = LSTMClassifier(input_dim=5000, hidden_dim=128, output_dim=2, num_layers=1)
optimizer = optim.Adam(model.parameters(), lr=0.001)
criterion = nn.CrossEntropyLoss()

# è®­ç»ƒå¾ªç¯
for epoch in range(5):  # è¿è¡Œ5ä¸ªepoch
    for texts, labels in tqdm(train_loader):
        optimizer.zero_grad()
        outputs = model(texts.float())
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

# è¯„ä¼°æ¨¡å‹æ€§èƒ½
correct = 0
total = 0
with torch.no_grad():
    for texts, labels in tqdm(test_loader):
        outputs = model(texts.float())
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print('Accuracy: %d %%' % (100 * correct / total))

"""### BERT"""

class SentimentDataset(Dataset):
    def __init__(self, tokenizer, max_length=50, num_classes=3, subset='train'):
        data = fetch_20newsgroups(subset=subset, categories=['sci.space', 'rec.autos'])
        self.texts = data.data
        self.labels = torch.tensor(data.target)
        self.tokenizer = tokenizer
        self.max_length = max_length

    def __len__(self):
        return len(self.texts)

    def __getitem__(self, idx):
        text = self.texts[idx]
        # ä½¿ç”¨BERTåˆ†è¯å™¨å¤„ç†æ–‡æœ¬
        encoded = self.tokenizer.encode_plus(
            text,
            max_length=self.max_length,
            padding='max_length',
            truncation=True,
            return_tensors='pt'
        )
        input_ids = encoded['input_ids'].squeeze(0)
        attention_mask = encoded['attention_mask'].squeeze(0)
        return input_ids, attention_mask, self.labels[idx]

# åˆå§‹åŒ–BERTåˆ†è¯å™¨
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

# å®ä¾‹åŒ–æ•°æ®é›†å’Œæ•°æ®åŠ è½½å™¨
train_dataset = SentimentDataset(tokenizer=tokenizer, subset='train')
test_dataset = SentimentDataset(tokenizer=tokenizer, subset='test')

train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=4, shuffle=True)

from transformers import BertModel
import torch.nn as nn

class SentimentModel(nn.Module):
    def __init__(self, bert_model_name='bert-base-uncased', num_classes=3):
        super(SentimentModel, self).__init__()
        self.bert = BertModel.from_pretrained(bert_model_name)
        self.fc = nn.Linear(self.bert.config.hidden_size, num_classes)

    def forward(self, text, attention_mask):
        text_output = self.bert(text, attention_mask=attention_mask)[1]  # å–BERTçš„[CLS] tokenè¾“å‡º
        output = self.fc(text_output)
        return output

# å°†æ¨¡å‹åŠ è½½åˆ°è®¾å¤‡ä¸Š
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = SentimentModel().to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# è®­ç»ƒå¾ªç¯
num_epochs = 5
for epoch in range(num_epochs):
    for input_ids, attention_mask, labels in train_loader:
        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(input_ids, attention_mask)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}")

import concurrent.futures
import torch
import torch.nn as nn
import torch.optim as optim
from transformers import BertModel, BertTokenizer
from torch.utils.data import DataLoader, TensorDataset

# å‡è®¾æ‚¨å·²ç»å®šä¹‰äº†MLPå’ŒBERTæ¨¡å‹ç±»ï¼Œä»¥åŠç›¸åº”çš„æ•°æ®åŠ è½½å™¨
# model_mlp = ...
# model_bert = ...
# data_loader_mlp = ...
# data_loader_bert = ...

def train_mlp(model, data_loader):
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    for epoch in range(5):  # 5ä¸ªepochä½œä¸ºç¤ºä¾‹
        for inputs, labels in data_loader:
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            print(f"MLP Epoch [{epoch+1}/5], Loss: {loss.item():.4f}")

def train_bert(model, data_loader):
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    for epoch in range(3):  # 3ä¸ªepochä½œä¸ºç¤ºä¾‹
        for inputs, attention_masks, labels in data_loader:
            optimizer.zero_grad()
            outputs = model(inputs, attention_mask=attention_masks)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            print(f"BERT Epoch [{epoch+1}/3], Loss: {loss.item():.4f}")

# ä½¿ç”¨ProcessPoolExecutorå¹¶è¡Œè¿è¡Œä¸¤ä¸ªè®­ç»ƒè¿‡ç¨‹
with concurrent.futures.ProcessPoolExecutor() as executor:
    executor.submit(train_mlp, model_mlp, data_loader_mlp)
    executor.submit(train_bert, model_bert, data_loader_bert)

import torch
import torch.optim as optim
from torch.utils.data import DataLoader

# å°†æ¨¡å‹åŠ è½½åˆ°è®¾å¤‡ä¸Š
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = SentimentModel().to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# è®­ç»ƒå¾ªç¯
num_epochs = 5
for epoch in range(num_epochs):
    for input_ids, attention_mask, labels in train_loader:
        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(input_ids, attention_mask)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}")

"""### LLAMA"""

import requests
import json

def call_llama_api(text, params=None):
    # URL of the LLaMA API
    api_url = "http://example.com/llama"  # è¯·æ›¿æ¢æˆå®é™…çš„API URL

    # å‡†å¤‡è¯·æ±‚æ•°æ®
    data = {
        "text": text,
        "params": params if params else {}  # Add additional parameters if required
    }

    # å‘é€è¯·æ±‚
    response = requests.post(api_url, json=data)

    # æ£€æŸ¥å“åº”
    if response.status_code == 200:
        return response.json()  # è¿”å›æ¨¡å‹çš„å“åº”
    else:
        print("Error:", response.status_code, response.text)
        return None

# ä½¿ç”¨LLaMAæ¨¡å‹
text = "Your input text here"
params = {"param1": "value1", "param2": "value2"}  # ç¤ºä¾‹å‚æ•°ï¼Œæ ¹æ®APIå®é™…æƒ…å†µè¿›è¡Œè°ƒæ•´
response = call_llama_api(text, params)

# å¤„ç†æ¨¡å‹å“åº”
if response:
    print("Model Response:", response)

"""### XLNet"""

import torch
from torch import nn
from transformers import XLNetModel, XLNetTokenizer

class XLNetSentimentModel(nn.Module):
    def __init__(self, n_classes=2):
        super(XLNetSentimentModel, self).__init__()
        self.xlnet = XLNetModel.from_pretrained('xlnet-base-cased')
        self.fc = nn.Linear(self.xlnet.config.hidden_size, n_classes)

    def forward(self, input_ids, attention_mask):
        output = self.xlnet(input_ids=input_ids, attention_mask=attention_mask)
        last_hidden_state = output.last_hidden_state
        out = self.fc(last_hidden_state[:, -1, :])
        return out

# åˆ›å»ºæ¨¡å‹å®ä¾‹
model = XLNetSentimentModel()

# æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„ GPUï¼Œå¦‚æœæœ‰ï¼Œåˆ™å°†æ¨¡å‹ç§»åŠ¨åˆ° GPU
if torch.cuda.is_available():
    model = model.to('cuda')

# ç¤ºä¾‹ï¼šæ¨¡å‹è¾“å…¥
tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')
text = "This is a great product!"
inputs = tokenizer(text, return_tensors="pt")
input_ids = inputs["input_ids"].to(model.device)
attention_mask = inputs["attention_mask"].to(model.device)

# å‰å‘ä¼ é€’
with torch.no_grad():
    outputs = model(input_ids=input_ids, attention_mask=attention_mask)
    print(outputs)

from transformers import XLNetModel, XLNetTokenizer

class XLNetSentimentModel(nn.Module):
    def __init__(self):
        super(XLNetSentimentModel, self).__init__()
        self.xlnet = XLNetModel.from_pretrained('xlnet-base-cased')
        self.fc = nn.Linear(self.xlnet.config.hidden_size, 2)

    def forward(self, input_ids, attention_mask):
        output = self.xlnet(input_ids=input_ids, attention_mask=attention_mask)
        last_hidden_state = output.last_hidden_state
        out = self.fc(last_hidden_state[:, -1, :])
        return out

xlnet_model = XLNetSentimentModel()

"""### Emoji"""

!pip install emoji
import emoji

# ç¤ºä¾‹æ—¥è®°æ–‡æœ¬
diary_entries = [
    "8.1 æ£‹æ€»æ˜¯æ…¢ä¸€æ‰‹ ğŸ«¡",
    "7.29 ã‹ã‘ãŒãˆã®ãªã„ã®æ˜Ÿ è¿˜ä¼šå†å›æ¥çš„å§",
    "7.28 æƒ³è¯·æ•™ä¸€ä¸‹æœ‰åŒå­¦çŸ¥é“åœ¨ç¾å›½ä¸Šè¯¾çš„ç¬”è®°é™¤äº†ç”¨ebayè¿˜å¯ä»¥æ€ä¹ˆè½¬è®©å—ï¼Ÿè°¢è°¢",
    "7.24 æœ‰ç‚¹æƒ³è‡ªå‡ºä¸€å¥—jk",
    "7.16 æ”¶åˆ°äº†ä¸¤æœ¬ä¹¦ä¸­ç¬¬ä¸€æœ¬æ”¹ç¨¿æ„è§, æ–‡å­—è¯»æ¥ä¹Ÿæ˜¯å¦‚æ²æ˜¥é£ã€‚"
]

def replace_emojis(text):
    return emoji.demojize(text, language='alias')

# æ¨¡æ‹Ÿæ‰‹åŠ¨æ‰“æ ‡
sentiment_labels = ["ä¸­æ€§", "æ­£é¢", "ä¸­æ€§", "ä¸­æ€§", "æ­£é¢"]

# æµ‹è¯•å¤„ç†æ•ˆæœ
for entry, label in zip(diary_entries, sentiment_labels):
    processed_entry = replace_emojis(entry)
    print(f"åŸæ–‡: {entry}")
    print(f"å¤„ç†å: {processed_entry}")
    print(f"æƒ…æ„Ÿæ ‡ç­¾: {label}\n")

!pip install pdfplumber
import pdfplumber

def extractText(pdf_path):
    with pdfplumber.open(pdf_path) as pdf:
        all_text = ""
        for page in pdf.pages:
            text = page.extract_text()
            all_text += text
    return all_text

def extract_emojies(s):
   emoji_list = []
   for c in s:
       if c in emoji.EMOJI_DATA:
           emoji_list.append(c)
   return list(dict.fromkeys(emoji_list))

def get_en_senti(s_text):
   score = TextBlob(s_text).sentiment[0]
   if score > 0:
       return 1
   else:
       return 0

all_text = extractText('TheGreatGatsby')

"""### BERT-CHINESE"""



"""### TextBlob (Sentimental Analysis)"""



"""### Jieba"""



"""### HanLP"""



"""### SnowNLP"""

import spacy

# åŠ è½½è‹±è¯­æ¨¡å‹
nlp = spacy.load("en_core_web_sm")

# è¦å¤„ç†çš„æ–‡æœ¬
text = "Apple is looking at buying U.K. startup for $1 billion"

# å¤„ç†æ–‡æœ¬
doc = nlp(text)

# è¾“å‡ºè¯æ€§æ ‡æ³¨
for token in doc:
    print(token.text, token.pos_)



import nltk
from nltk.tokenize import word_tokenize

# ä¸‹è½½æ‰€éœ€çš„æ•°æ®å’Œæ ‡æ³¨å™¨æ¨¡å‹
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')

# è¦å¤„ç†çš„æ–‡æœ¬
text = "Apple is looking at buying U.K. startup for $1 billion"

# åˆ†è¯
tokens = word_tokenize(text)

# è¾“å‡ºè¯æ€§æ ‡æ³¨
print(nltk.pos_tag(tokens))



from textblob import TextBlob

phrases = ["ä¸ï¼Œä¸æ˜¯çš„", "æ˜¯ï¼Œæ˜¯è¿™æ ·"]

for phrase in phrases:
    blob = TextBlob(phrase)
    sentiment = blob.sentiment
    print(f"Phrase: '{phrase}'")
    print(f"   Polarity: {sentiment.polarity}")
    print(f"   Subjectivity: {sentiment.subjectivity}\n")



import nltk
from nltk.tokenize import word_tokenize
from nltk.tag import pos_tag
from nltk.chunk import ne_chunk

# ä¸‹è½½æ‰€éœ€çš„æ•°æ®å’Œæ¨¡å‹
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')
nltk.download('maxent_ne_chunker')
nltk.download('words')

# è¦å¤„ç†çš„æ–‡æœ¬
text = "Apple is looking at buying U.K. startup for $1 billion"

# åˆ†è¯å’Œè¯æ€§æ ‡æ³¨
tokens = word_tokenize(text)
tags = pos_tag(tokens)

# å‘½åå®ä½“è¯†åˆ«
entities = ne_chunk(tags)
print(entities)



!pip install snownlp
from snownlp import SnowNLP

phrases = ["ä¸ï¼Œä¸æ˜¯çš„", "æ˜¯ï¼Œæ˜¯è¿™æ ·"]

for phrase in phrases:
    s = SnowNLP(phrase)
    sentiment = s.sentiments
    print(f"Phrase: '{phrase}'")
    print(f"   Sentiment: {sentiment}\n")

"""### ERNIE"""

import paddle
from paddle.io import Dataset, DataLoader
from paddlenlp.transformers import ErnieTokenizer, ErnieForSequenceClassification
import numpy as np

# ä½ çš„è®­ç»ƒæ•°æ®
train_texts = ["è¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„äº§å“ã€‚", "è¿™æ˜¯ä¸€ä¸ªç³Ÿç³•çš„äº§å“ã€‚"]
train_labels = [1, 0]  # å‡è®¾1ä»£è¡¨æ­£é¢è¯„ä»·ï¼Œ0ä»£è¡¨è´Ÿé¢è¯„ä»·

# åˆå§‹åŒ–ERNIEçš„tokenizer
tokenizer = ErnieTokenizer.from_pretrained('ernie-1.0')

# æ•°æ®é¢„å¤„ç†
train_encodings = tokenizer(train_texts, padding=True, truncation=True, max_length=128, return_tensors="np")

# å®šä¹‰è‡ªå®šä¹‰æ•°æ®é›†
class CustomDataset(Dataset):
    def __init__(self, encodings, labels):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: paddle.to_tensor(val[idx]) for key, val in self.encodings.items()}
        item['labels'] = paddle.to_tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.labels)

# åˆ›å»ºæ•°æ®é›†
train_dataset = CustomDataset(train_encodings, train_labels)

# ä½¿ç”¨PaddlePaddleè¿›è¡Œè®­ç»ƒ
def train(model, optimizer, train_loader, criterion):
    model.train()
    for batch in train_loader:
        input_ids = batch['input_ids']
        labels = batch['labels']
        logits = model(input_ids)
        loss = criterion(logits, labels)
        loss.backward()
        optimizer.step()
        optimizer.clear_grad()
    return loss

# åŠ è½½ERNIEæ¨¡å‹
model = ErnieForSequenceClassification.from_pretrained('ernie-1.0', num_classes=2)
optimizer = paddle.optimizer.Adam(parameters=model.parameters(), learning_rate=5e-5)
criterion = paddle.nn.loss.CrossEntropyLoss()

# åˆ›å»ºæ•°æ®åŠ è½½å™¨
train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)

# è®­ç»ƒæ¨¡å‹
for epoch in range(3):  # è¿™é‡Œä»…æ¼”ç¤º3ä¸ªepoch
    loss = train(model, optimizer, train_loader, criterion)
    print(f"Epoch {epoch}, Loss: {loss.numpy().item()}")

# å‡†å¤‡æµ‹è¯•æ–‡æœ¬
test_texts = [
    "è¿™ä¸ªäº§å“éå¸¸å¥½ã€‚",
    "è¿™ä¸ªäº§å“ä¸å¥½ã€‚",
    "æˆ‘å¯¹è¿™ä¸ªäº§å“éå¸¸æ»¡æ„ã€‚",
    "è¿™æ¬¡è´­ç‰©ä½“éªŒå¾ˆå·®ã€‚",
    "æˆ‘å–œæ¬¢è¿™ä¸ªã€‚",
    "è¿™çœŸçš„å¾ˆç³Ÿç³•ã€‚",
    "éå¸¸æ¨èè¿™ä¸ªäº§å“ã€‚",
    "æˆ‘ä¸æ¨èè¿™ä¸ªäº§å“ã€‚"
]

# ä½¿ç”¨Tokenizerå¤„ç†æ–‡æœ¬
test_encodings = tokenizer(test_texts, max_seq_len=128, pad_to_max_seq_len=True, return_tensors="np")

# è½¬æ¢ä¸ºPaddle tensor
input_ids = paddle.to_tensor(test_encodings['input_ids'])
segment_ids = paddle.to_tensor(test_encodings['token_type_ids'])

# é¢„æµ‹
model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
with paddle.no_grad():
    logits = model(input_ids, segment_ids)
    predictions = paddle.nn.functional.softmax(logits)

# è·å–é¢„æµ‹ç±»åˆ«
pred_labels = paddle.argmax(predictions, axis=1).numpy()

# è¾“å‡ºé¢„æµ‹ç»“æœ
for text, label in zip(test_texts, pred_labels):
    print(f"Text: {text}, Predicted label: {label}")



!pip install paddlepaddle
!pip install paddlenlp

from paddlenlp.transformers import ErnieForSequenceClassification, ErnieTokenizer
import paddle

# åˆå§‹åŒ–ERNIEæ¨¡å‹å’Œåˆ†è¯å™¨
model = ErnieForSequenceClassification.from_pretrained('ernie-1.0', num_classes=2)
tokenizer = ErnieTokenizer.from_pretrained('ernie-1.0')

# æ•°æ®å‡†å¤‡
texts = ["è¿™æ˜¯ä¸€ä¸ªå¾ˆæ£’çš„äº§å“", "è¿™ä¸ªäº§å“ä¸å¥½ç”¨"]
labels = [1, 0]  # 1ä»£è¡¨æ­£é¢æƒ…æ„Ÿï¼Œ0ä»£è¡¨è´Ÿé¢æƒ…æ„Ÿ

# æ•°æ®é¢„å¤„ç†
inputs = tokenizer(texts, max_seq_len=128, pad_to_max_seq_len=True, return_attention_mask=True)
input_ids = paddle.to_tensor(inputs['input_ids'])
segment_ids = paddle.to_tensor(inputs['token_type_ids'])
attention_mask = paddle.to_tensor(inputs['attention_mask'])

# æ¨¡å‹é¢„æµ‹
paddle.set_device('cpu')  # å¦‚æœä½¿ç”¨gpuï¼Œæ”¹ä¸º'gpu'
model.eval()
with paddle.no_grad():
    logits = model(input_ids, segment_ids)
    probs = paddle.nn.functional.softmax(logits, axis=-1)
    predictions = paddle.argmax(probs, axis=1).numpy()

# è¾“å‡ºé¢„æµ‹ç»“æœ
for idx, text in enumerate(texts):
    print(f"Text: {text} - Sentiment: {'Positive' if predictions[idx] == 1 else 'Negative'}")

"""### Viterbi's Algorithm"""

"""
è¯æ€§æ ‡æ³¨ï¼ˆPart-of-Speech Taggingï¼‰ï¼š
åœ¨è¯æ€§æ ‡æ³¨ä»»åŠ¡ä¸­ï¼ŒViterbiç®—æ³•å¯ä»¥ç”¨æ¥æ‰¾å‡ºç»™å®šè¯åºåˆ—çš„æœ€å¯èƒ½çš„è¯æ€§åºåˆ—ã€‚
è¿™é€šå¸¸åœ¨åŸºäºéšé©¬å°”å¯å¤«æ¨¡å‹çš„è¯æ€§æ ‡æ³¨ç³»ç»Ÿä¸­å®ç°ã€‚
å‘½åå®ä½“è¯†åˆ«ï¼ˆNamed Entity Recognition, NERï¼‰ï¼š
åœ¨ä¸€äº›NERç³»ç»Ÿä¸­ï¼Œç‰¹åˆ«æ˜¯é‚£äº›ä½¿ç”¨éšé©¬å°”å¯å¤«æ¨¡å‹æˆ–æ¡ä»¶éšæœºåœºï¼ˆConditional Random Fields, CRFsï¼‰çš„ç³»ç»Ÿä¸­ï¼Œ
Viterbiç®—æ³•ç”¨äºæ¨æ–­æœ€å¯èƒ½çš„å®ä½“æ ‡ç­¾åºåˆ—ã€‚
"""

import random
import numpy as np

# Sigmoid å‡½æ•°
def sigmoid(x):
    return 1 / (1 + np.exp(-x))

# ç”Ÿæˆæ¨¡æ‹Ÿçš„æ—¶åºæ•°æ®ï¼ˆä¾‹å¦‚è‚¡ç¥¨ä»·æ ¼ï¼‰
def generate_time_series_data(num_points):
    return np.random.rand(num_points) * 100

# æ•°æ®å½’ä¸€åŒ–
def normalize_data(data):
    return (data - np.min(data)) / (np.max(data) - np.min(data))

# åˆå§‹åŒ–ç®—æ³•
def viterbi(obs, states, start_p, trans_p, emit_p):
    V = [{}]
    path = {}

    # åˆå§‹åŒ–åŸºæœ¬æƒ…å†µ (t == 0)
    for y in states:
        V[0][y] = start_p[y] * emit_p[y][obs[0]]
        path[y] = [y]

    # å¯¹ t > 0 çš„æ—¶åˆ»è¿è¡Œ Viterbi
    for t in range(1, len(obs)):
        V.append({})
        newpath = {}

        for y in states:
            # æ£€æŸ¥æ¯ä¸ªçŠ¶æ€ï¼Œå¹¶é€‰æ‹©å…¶ä¸­ä¸€ä¸ªçŠ¶æ€ä½œä¸ºå‰ä¸€ä¸ªçŠ¶æ€
            (prob, state) = max((V[t-1][y0] * trans_p[y0][y] * emit_p[y][obs[t]], y0) for y0 in states)
            V[t][y] = prob
            newpath[y] = path[state] + [y]

        path = newpath

    # è¿”å›æœ€å¯èƒ½çš„åºåˆ—
    n = 0           # å¦‚æœä»…æœ‰ä¸€ä¸ªè§‚å¯Ÿå€¼ï¼Œåªéœ€è¦è¿”å›åˆå§‹çŠ¶æ€
    if len(obs) != 1:
        n = t
    (prob, state) = max((V[n][y], y) for y in states)
    return path[state]

# ç»´ç‰¹æ¯”ç®—æ³•ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
def viterbi(obs, states, start_p, trans_p, emit_p):
    # ... ç»´ç‰¹æ¯”ç®—æ³•çš„å®ç° ...
    return hidden_states

# ç¤ºä¾‹ç”¨æ³•
time_series_data = generate_time_series_data(100)  # ç”Ÿæˆæ•°æ®
normalized_data = normalize_data(time_series_data)  # å½’ä¸€åŒ–æ•°æ®

# å‡è®¾çš„ HMM å‚æ•°
states = ['Up', 'Down']
start_probability = {'Up': 0.5, 'Down': 0.5}
transition_probability = {'Up': {'Up': 0.7, 'Down': 0.3}, 'Down': {'Up': 0.3, 'Down': 0.7}}
emission_probability = {'Up': {'rise': 0.6, 'fall': 0.4}, 'Down': {'rise': 0.4, 'fall': 0.6}}

# åº”ç”¨ç»´ç‰¹æ¯”ç®—æ³•
hidden_states = viterbi(normalized_data, states, start_probability, transition_probability, emission_probability)

print(hidden_states)

def map_time_series_to_observations(time_series_data):
    observations = []
    for i in range(1, len(time_series_data)):
        change = (time_series_data[i] - time_series_data[i-1]) / time_series_data[i-1]
        if change > 0.01:  # å‡è®¾å˜åŒ–è¶…è¿‡1%ä¸ºä¸Šå‡
            observations.append("up")
        elif change < -0.01:  # å‡è®¾å˜åŒ–ä½äº-1%ä¸ºä¸‹é™
            observations.append("down")
        else:
            observations.append("stable")
    return observations

states = ("bull", "bear", "neutral")  # å‡è®¾çš„å¸‚åœºçŠ¶æ€ï¼šç‰›å¸‚ã€ç†Šå¸‚ã€ä¸­æ€§å¸‚åœº
start_probability = {"bull": 0.3, "bear": 0.3, "neutral": 0.4}
transition_probability = {
    "bull": {"bull": 0.7, "bear": 0.1, "neutral": 0.2},
    "bear": {"bull": 0.1, "bear": 0.7, "neutral": 0.2},
    "neutral": {"bull": 0.3, "bear": 0.3, "neutral": 0.4}
}
emission_probability = {
    "bull": {"up": 0.6, "down": 0.1, "stable": 0.3},
    "bear": {"up": 0.1, "down": 0.6, "stable": 0.3},
    "neutral": {"up": 0.3, "down": 0.3, "stable": 0.4}
}

def viterbi(obs, states, start_p, trans_p, emit_p):
    V = [{}]
    for st in states:
        V[0][st] = {"prob": start_p[st] * emit_p[st][obs[0]], "prev": None}
    for t in range(1, len(obs)):
        V.append({})
        for st in states:
            max_tr_prob = max(V[t-1][prev_st]["prob"]*trans_p[prev_st][st] for prev_st in states)
            for prev_st in states:
                if V[t-1][prev_st]["prob"] * trans_p[prev_st][st] == max_tr_prob:
                    max_prob = max_tr_prob * emit_p[st][obs[t]]
                    V[t][st] = {"prob": max_prob, "prev": prev_st}
                    break
    opt = []
    max_prob = max(value["prob"] for value in V[-1].values())
    previous = None
    for st, data in V[-1].items():
        if data["prob"] == max_prob:
            opt.append(st)
            previous = st
            break
    for t in range(len(V) - 2, -1, -1):
        opt.insert(0, V[t + 1][previous]["prev"])
        previous = V[t + 1][previous]["prev"]
    return opt

states = ('Rainy', 'Sunny')
observations = ('walk', 'shop', 'clean')
start_probability = {'Rainy': 0.6, 'Sunny': 0.4}
transition_probability = {
   'Rainy' : {'Rainy': 0.7, 'Sunny': 0.3},
   'Sunny' : {'Rainy': 0.4, 'Sunny': 0.6},
   }
emission_probability = {
   'Rainy' : {'walk': 0.1, 'shop': 0.4, 'clean': 0.5},
   'Sunny' : {'walk': 0.6, 'shop': 0.3, 'clean': 0.1},
   }

result = viterbi(observations, states, start_probability, transition_probability, emission_probability)
print(result)

# å‡è®¾ time_series_data æ˜¯åŒ…å«è‚¡ç¥¨ä»·æ ¼çš„åˆ—è¡¨
time_series_data = [
    100, 102, 101, 103, 105, 107, 106, 108, 107, 110, 111, 110, 109, 108, 107, 106,
    107, 108, 109, 110, 111, 113, 115, 116, 117, 118, 119, 120, 121, 119, 118, 117,
    115, 114, 113, 114, 115, 116, 117, 119, 120, 121, 123, 125, 127, 126, 125, 124,
    123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108,
    107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 97, 96, 95, 94, 93, 92,
    91, 90, 89, 88, 87, 86, 85, 84, 83, 82, 81, 80, 79, 78, 77, 76
]
hidden_states = process_time_series_data(time_series_data, states, start_probability, transition_probability, emission_probability)
print(hidden_states)

"""### To-Graph"""

import tensorflow_hub as hub
import numpy as np
import networkx as nx
import matplotlib.pyplot as plt

# åŠ è½½Universal Sentence Encoderæ¨¡å‹
model = hub.load("https://tfhub.dev/google/universal-sentence-encoder/4")

# ä½¿ç”¨æ¨¡å‹ç”Ÿæˆæ–‡æœ¬çš„åµŒå…¥å‘é‡
embeddings = model(texts)

# è®¡ç®—æ‰€æœ‰æ–‡æœ¬å¯¹ä¹‹é—´çš„ç›¸ä¼¼åº¦
similarity_matrix = np.inner(embeddings, embeddings)

# åˆ›å»ºä¸€ä¸ªæ— å‘å›¾
G = nx.Graph()

# æ·»åŠ èŠ‚ç‚¹
for text in texts:
    G.add_node(text)

# æ ¹æ®ç›¸ä¼¼åº¦æ·»åŠ è¾¹ï¼Œè¿™é‡Œæˆ‘ä»¬è®¾ç½®é˜ˆå€¼ä¸º0.6ï¼Œå³ç›¸ä¼¼åº¦é«˜äº0.6çš„æ–‡æœ¬ä¹‹é—´æ·»åŠ è¾¹
for i in range(len(texts)):
    for j in range(i + 1, len(texts)):
        if similarity_matrix[i][j] > 0.6:
            G.add_edge(texts[i], texts[j], weight=similarity_matrix[i][j])

# ç»˜åˆ¶å›¾å½¢
plt.figure(figsize=(10, 10))
pos = nx.spring_layout(G, seed=7)  # èŠ‚ç‚¹å¸ƒå±€
nx.draw(G, pos, with_labels=True, font_weight='bold', node_color='skyblue', edge_color='gray')
edge_labels = nx.get_edge_attributes(G, 'weight')
nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)
plt.title("Text Similarity Graph", size=15)
plt.show()

import networkx as nx
import matplotlib.pyplot as plt

# åˆ›å»ºä¸€ä¸ªç©ºçš„æ— å‘å›¾
G = nx.Graph()

# å‡è®¾æˆ‘ä»¬æœ‰ä¸€ç»„æƒ…ç»ªç‰¹å¾å’Œå®ƒä»¬ä¹‹é—´çš„ç›¸å…³æ€§åˆ†æ•°
features = ['Happiness', 'Sadness', 'Anger', 'Fear', 'Surprise']
correlations = [('Happiness', 'Sadness', -0.5), ('Anger', 'Fear', 0.4), ('Surprise', 'Happiness', 0.3)]

# æ·»åŠ èŠ‚ç‚¹
for feature in features:
    G.add_node(feature)

# æ·»åŠ è¾¹ï¼ŒåŸºäºç›¸å…³æ€§åˆ†æ•°
for src, dst, weight in correlations:
    G.add_edge(src, dst, weight=weight)

# ç»˜åˆ¶å›¾
pos = nx.spring_layout(G)  # ä¸ºå›¾å¸ƒå±€
nx.draw(G, pos, with_labels=True, node_color='lightblue', edge_color='gray')
edge_labels = nx.get_edge_attributes(G, 'weight')
nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)
plt.show()

import networkx as nx
from numpy import dot
from numpy.linalg import norm
import numpy as np
import matplotlib.pyplot as plt

# å‡è®¾features_dictå·²ç»æ˜¯æ•°å€¼å‹ç‰¹å¾å‘é‡
features_dict = {
    "image1": np.array([1, 0]),  # å‡è®¾çš„æ•°å€¼å‹ç‰¹å¾å‘é‡ï¼Œæ¯”å¦‚one-hotç¼–ç 
    "image2": np.array([0, 1]),
    # æ›´å¤šå›¾åƒåŠå…¶æ•°å€¼å‹ç‰¹å¾å‘é‡
}

G = nx.Graph()

def calculate_similarity(feature_vec1, feature_vec2):
    """
    è®¡ç®—ä¸¤ä¸ªç‰¹å¾å‘é‡ä¹‹é—´çš„ä½™å¼¦ç›¸ä¼¼åº¦ã€‚
    """
    if norm(feature_vec1) * norm(feature_vec2) == 0:
        return 0  # é¿å…é™¤ä»¥é›¶
    cosine_similarity = dot(feature_vec1, feature_vec2) / (norm(feature_vec1) * norm(feature_vec2))
    return cosine_similarity

# æ·»åŠ èŠ‚ç‚¹
for image_id, features in features_dict.items():
    G.add_node(image_id, feature=features)

threshold = 0.5  # å®šä¹‰ç›¸ä¼¼åº¦é˜ˆå€¼

# æ·»åŠ è¾¹
for id1, feature_vec1 in features_dict.items():
    for id2, feature_vec2 in features_dict.items():
        if id1 != id2:
            similarity = calculate_similarity(feature_vec1, feature_vec2)
            if similarity > threshold:
                G.add_edge(id1, id2, weight=similarity)

# æ³¨æ„ï¼šå®é™…ä¸­ï¼Œç‰¹å¾å‘é‡çš„è½¬æ¢å’Œç›¸ä¼¼åº¦è®¡ç®—æ–¹å¼éœ€è¦æ ¹æ®å…·ä½“çš„ç‰¹å¾å’Œä»»åŠ¡æ¥ç¡®å®šã€‚

# è®¡ç®—èŠ‚ç‚¹çš„ä½ç½®ï¼Œè¿™é‡Œä½¿ç”¨spring_layoutç®—æ³•æ¥è‡ªåŠ¨å¸ƒå±€
pos = nx.spring_layout(G)

# ç»˜åˆ¶ç½‘ç»œå›¾
plt.figure(figsize=(8, 6))  # è®¾ç½®å›¾å½¢çš„å¤§å°

# ç»˜åˆ¶èŠ‚ç‚¹
nx.draw_networkx_nodes(G, pos, node_size=700, node_color='skyblue', alpha=0.6)

# ç»˜åˆ¶è¾¹ï¼Œè¾¹çš„å®½åº¦æ ¹æ®æƒé‡æ¥è°ƒæ•´
edges = G.edges(data=True)
weights = [edge[2]['weight'] * 10 for edge in edges]  # è°ƒæ•´è¾¹çš„æƒé‡ï¼Œä»¥ä¾¿åœ¨å›¾ä¸­æ›´æ¸…æ¥šåœ°æ˜¾ç¤º
nx.draw_networkx_edges(G, pos, width=weights, edge_color='gray', alpha=0.5)

# ç»˜åˆ¶èŠ‚ç‚¹çš„æ ‡ç­¾
nx.draw_networkx_labels(G, pos, font_size=12)

plt.title('Graph Visualization')
plt.axis('off')  # ä¸æ˜¾ç¤ºåæ ‡è½´
plt.show()

"""### To-Time"""

import re
import nltk
import pandas as pd
!pip install snownlp
from snownlp import SnowNLP
from textblob import TextBlob
from datetime import datetime

# å‡è®¾diary_textæ˜¯æ‚¨çš„æ—¥è®°æ–‡æœ¬
diary_text = """
2.14
æ‰¾åˆ°äº†é’ˆå¯¹æŸäº›exeå»æŒ–æ˜ä»·å€¼çš„ä¸œè¥¿
æ˜¯åå¹´å‰çš„å…‰å§, è€é«˜å¹²è¿‡çš„
äºè´¼

2.13
å……ç”µå®å¼¹å‡ºæ¥çš„ä¸€ç¬é—´, éå¸¸çš„å¥½
æ­»äº¡å¾ªç¯ éšå¿ƒéšç¼˜
è¯·é—®è°å¯ä»¥åšåˆ°, åœ¨æ²¡æœ‰ä»»ä½•æ–°ä¿¡æ¯è¿›æ¥çš„æƒ…å†µä¸‹, å¯¹ä¸€ä¸ªäººæˆ–è€…ä¸€ä»¶äº‹çš„åˆ¤æ–­èƒ½å¤Ÿç¬é—´è½¬å‘ï¼Ÿ
ä¹Ÿè®¸æ˜¯æˆ‘çš„ç”¨è¯å¤ªåŸå¸‚åŒ–äº†ã€‚åº”è¯¥ä¸ä¼šæ²¡æœ‰æ–°çš„ä¿¡æ¯, ä½†å¦‚æ­¤å°æ ·æœ¬çš„å­¦ä¹ å°±èƒ½è®©è€Œåˆ†ç±»ç»“æœç›´æ¥åå‘, åº”è¯¥æ˜¯ç”¨äº†æŸç§relu
å‡†å¤‡çœ ä¸€ä¼šå„¿, ä½†ä¸æ˜¯é•¿çœ ã€‚

2.12
æ˜¯å§
æ˜¯çš„
ä¸¥æ ¼æ¥è¯´
æ¯ä¸ªè½¬å‘æ–‡ç« æ ‡é¢˜ä¹Ÿæ˜¯è¦çš„
å°±æ˜¯è¿™æ–‡å­—èƒ½åæ˜ çŠ¶æ€ ä¸ç„¶ä¹Ÿæ²¡å¿…è¦å­˜åœ¨äº†çš„

2.11
æœç„¶

2.10
å¤©å…ƒ
æ€ä¹ˆè¿™ä¹ˆæ‡‚å‘¢
å€’åœ¨ä½ é¢å‰äº† æ»¡æ„äº†å§
è¯´å§ è¯´çš„è¶Šå¤š ä½ çš„æœ¬è´¨å°±åªä¼šæ„ˆåŠ çš„æš´éœ²
ã€Œã“ã®ä¼èª¬ã®çµ‚ã‚ã‚Šã¯ã€æ€¥é€Ÿã«æ¥ã‚‹ã€‚ã€
"""

# åˆ†å‰²æ—¥è®°æ–‡æœ¬ä¸ºæ¡ç›®ï¼Œæå–æ—¥æœŸ
entries = re.split(r'\n\d{1,2}\.\d{1,2}\n', diary_text)
dates = re.findall(r'\n(\d{1,2}\.\d{1,2})\n', diary_text)
formatted_dates = [datetime.strptime('2024.' + date, '%Y.%m.%d').date() for date in dates]

# å»é™¤å¤šä½™æ ‡ç‚¹ç¬¦å·çš„å‡½æ•°
def remove_punctuation(text):
    return re.sub(r'[^\w\s]', '', text)

# æƒ…æ„Ÿåˆ†æå‡½æ•°
def analyze_sentiment(text):
    if re.search(r'[\u4e00-\u9fff]', text):
        return SnowNLP(text).sentiments
    else:
        return TextBlob(text).sentiment.polarity

# åº”ç”¨æ•°æ®æ¸…æ´—å’Œæƒ…æ„Ÿåˆ†æ
cleaned_entries = [remove_punctuation(entry) for entry in entries[1:]]
sentiments = [analyze_sentiment(entry) for entry in cleaned_entries]

# åˆ›å»ºDataFrame
diary_df = pd.DataFrame({
    'Content': cleaned_entries,
    'Sentiment': sentiments
}, index=pd.to_datetime(formatted_dates))

# æŸ¥çœ‹DataFrame
print(diary_df)

"""## Image (Computer Vision)"""

import os
import cv2
import pandas as pd
from google.colab import drive

# å‡è®¾æ‚¨çš„å›¾ç‰‡å­˜å‚¨åœ¨"photos"ç›®å½•ä¸‹ï¼Œå¹¶ä¸”æ¯å¼ å›¾ç‰‡çš„æ–‡ä»¶ååŒ…å«äº†æ‹æ‘„æ—¶é—´
photos_path = "path_to_your_photos_directory"

# åˆ›å»ºä¸€ä¸ªç©ºçš„DataFrameæ¥å­˜å‚¨æ—¶åºæ•°æ®å’Œå›¾åƒè·¯å¾„
df = pd.DataFrame(columns=["timestamp", "image_path"])

# éå†å›¾ç‰‡ç›®å½•ï¼Œè¯»å–å›¾ç‰‡æ–‡ä»¶åå’Œè·¯å¾„
for filename in os.listdir(photos_path):
    if filename.endswith(".jpg"):  # å‡è®¾æ‰€æœ‰å›¾ç‰‡éƒ½æ˜¯jpgæ ¼å¼
        # ä»æ–‡ä»¶åè§£ææ—¶é—´æˆ³ï¼Œè¿™é‡Œå‡è®¾æ–‡ä»¶åæ ¼å¼åŒ…å«æ—¥æœŸæ—¶é—´ä¿¡æ¯
        timestamp = pd.to_datetime(filename.split('.')[0], format="%Y%m%d%H%M%S")
        image_path = os.path.join(photos_path, filename)

        # å°†æ—¶é—´æˆ³å’Œå›¾åƒè·¯å¾„æ·»åŠ åˆ°DataFrame
        df = df.append({"timestamp": timestamp, "image_path": image_path}, ignore_index=True)

# æ ¹æ®æ—¶é—´æˆ³å¯¹æ•°æ®è¿›è¡Œæ’åºï¼Œç¡®ä¿æ—¶åºå¯¹é½
df.sort_values(by="timestamp", inplace=True)

# ç°åœ¨ï¼ŒdfåŒ…å«äº†æŒ‰æ—¶é—´æ’åºçš„å›¾åƒè·¯å¾„
print(df)

# ä½ å¯ä»¥æ ¹æ®éœ€è¦å¯¹dfè¿›è¡Œè¿›ä¸€æ­¥çš„å¤„ç†æˆ–åˆ†æ
# ä¾‹å¦‚ï¼Œä½¿ç”¨OpenCVè¯»å–å¹¶æ˜¾ç¤ºç¬¬ä¸€å¼ å›¾ç‰‡
first_image_path = df.iloc[0]["image_path"]
image = cv2.imread(first_image_path)
cv2.imshow("First Image", image)
cv2.waitKey(0)
cv2.destroyAllWindows()

"""### Pre-processing (*A Non-Linear Classifier)"""



"""### Pre-processing (Simulation)"""

import sympy as sp

# å®šä¹‰å˜é‡å’Œå‡½æ•°
x = sp.Symbol('x')
f = sp.exp(x)
g = x**2

# è®¡ç®—å‡½æ•°çš„å¯¼æ•°
f_prime = f.diff(x)
g_prime = g.diff(x)

# æ„é€  Wronskian çŸ©é˜µ
wronskian_matrix = sp.Matrix([[f, g], [f_prime, g_prime]])

# è®¡ç®—çŸ©é˜µçš„è¡Œåˆ—å¼
wronskian_determinant = wronskian_matrix.det()

# æ‰“å°ç»“æœ
print("Wronskian çŸ©é˜µï¼š")
print(wronskian_matrix)
print("Wronskian è¡Œåˆ—å¼çš„å€¼ï¼š")
print(wronskian_determinant)

import numpy as np
import matplotlib.pyplot as plt

N = 100 # number of points per class
D = 2 # dimensionality
K = 3 # number of classes
X = np.zeros((N*K,D)) # data matrix (each row = single example)
y = np.zeros(N*K, dtype='uint8') # class labels

for j in range(K):
  ix = range(N*j,N*(j+1))
  r = np.linspace(0.0,1,N) # radius
  t = np.linspace(j*4,(j+1)*4,N) + np.random.randn(N)*0.2 # theta
  X[ix] = np.c_[r*np.sin(t), r*np.cos(t)]
  y[ix] = j

# lets visualize the data:
plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.Spectral)
plt.show()

# initialize parameters randomly
W = 0.01 * np.random.randn(D,K)
b = np.zeros((1,K))

# compute class scores for a linear classifier
scores = np.dot(X, W) + b

# obtain the shape of the examples
num_examples = X.shape[0]
# get unnormalized probabilities
exp_scores = np.exp(scores)
# normalize them for each example
probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)

# normalize the probabilistic output
correct_logprobs = -np.log(probs[range(num_examples),y])

# compute the loss: average cross-entropy loss and regularization
data_loss = np.sum(correct_logprobs)/num_examples
reg_loss = 0.5*reg*np.sum(W*W)
loss = data_loss + reg_loss

# perform a parameter update
dscores = probs
dscores[range(num_examples),y] -= 1
dscores /= num_examples

dW = np.dot(X.T, dscores)
db = np.sum(dscores, axis=0, keepdims=True)
dW += reg*W # don't forget the regularization gradient

W += -step_size * dW
b += -step_size * db

"""### ORB + ?"""

from google.colab import drive
drive.mount("/content/data")

!pip install fiftyone
import fiftyone.zoo as foz

# List available zoo datasets
print(foz.list_zoo_datasets())

import cv2

# Create a video capture object, in this case we are reading the video from a file
vid_capture = cv2.VideoCapture('<file_path.mp4>') # For webcam change <file_path.mp4> to 0. Eg. vid_capture = cv2.VideoCapture(0)

if (vid_capture.isOpened() == False):
  print("Error opening the video file")
# Read fps and frame count
else:
  # Get frame rate information
  # You can replace 5 with CAP_PROP_FPS as well, they are enumerations
  fps = vid_capture.get(5)
  print('Frames per second : ', fps,'FPS')
  # Get frame count
  # You can replace 7 with CAP_PROP_FRAME_COUNT as well, they are enumerations
  frame_count = vid_capture.get(7)
  print('Frame count : ', frame_count)

while(vid_capture.isOpened()):
  # vid_capture.read() methods returns a tuple, first
  # element is a bool and the second is frame
  ret, frame = vid_capture.read()
  if ret == True:
    cv2.imshow('Frame',frame)
    # 20 is in milliseconds
    key = cv2.waitKey(20) # try to increase the value, say 50 and observe
    if key == ord('q'): # q for quit
      break
  else:
    break

# Release the video capture object
vid_capture.release()
cv2.destroyAllWindows()

import numpy as np
import cv2
from matplotlib import pyplot as plt

img = cv2.imread('1.png', 0)
# print('img')

# Initiate STAR detector
orb = cv2.ORB_create()
print('orb')

# find the keypoints with ORB
kp = orb.detect(img, None)
print('kp')

# compute the descriptors with ORB
kp, des = orb.compute(img, kp)

# draw only keypoints location,not size and orientation
img2 = cv2.drawKeypoints(img, kp, None, color=(0, 255, 0), flags=0)
print('img2')

plt.imshow(img2)
plt.show()

"""### Bag of Words (BoW)"""



"""### CNNs

#### General-Classifier-Wise
"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator
import os

def load_and_preprocess_data(directory, img_width, img_height, batch_size):
    # ä½¿ç”¨Kerasçš„ImageDataGeneratoræ¥ç”Ÿæˆæ›´å¤šçš„å›¾åƒæ•°æ®
    datagen = ImageDataGenerator(rescale=1./255,
                                 rotation_range=40,
                                 width_shift_range=0.2,
                                 height_shift_range=0.2,
                                 shear_range=0.2,
                                 zoom_range=0.2,
                                 horizontal_flip=True,
                                 fill_mode='nearest',
                                 validation_split=0.2)  # ä½¿ç”¨20%çš„æ•°æ®ä½œä¸ºéªŒè¯é›†

    train_generator = datagen.flow_from_directory(
        directory,
        target_size=(img_width, img_height),
        batch_size=batch_size,
        class_mode='categorical',
        subset='training')

    validation_generator = datagen.flow_from_directory(
        directory,
        target_size=(img_width, img_height),
        batch_size=batch_size,
        class_mode='categorical',
        subset='validation')

    return train_generator, validation_generator

# æ•°æ®é›†è·¯å¾„
data_directory = 'path_to_your_dataset'
img_width, img_height = 48, 48
batch_size = 32

# è½½å…¥æ•°æ®é›†
train_generator, validation_generator = load_and_preprocess_data(data_directory, img_width, img_height, batch_size)

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization

def build_advanced_model(input_shape, num_classes):
    # æ„å»ºä¸€ä¸ªæ›´å¤æ‚çš„CNNæ¨¡å‹
    model = Sequential()

    # ç¬¬ä¸€å±‚å·ç§¯
    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=input_shape, padding='same'))
    model.add(BatchNormalization())
    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))
    model.add(BatchNormalization())
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(0.25))

    # ç¬¬äºŒå±‚å·ç§¯
    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))
    model.add(BatchNormalization())
    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))
    model.add(BatchNormalization())
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(0.25))

    # ç¬¬ä¸‰å±‚å·ç§¯
    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))
    model.add(BatchNormalization())
    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))
    model.add(BatchNormalization())
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(0.25))

    # æ‰å¹³åŒ–å’Œå…¨è¿æ¥å±‚
    model.add(Flatten())
    model.add(Dense(512, activation='relu'))
    model.add(BatchNormalization())
    model.add(Dropout(0.5))
    model.add(Dense(num_classes, activation='softmax'))

    # ç¼–è¯‘æ¨¡å‹
    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

    return model

# æ¨¡å‹å‚æ•°
input_shape = (48, 48, 3)  # å‡è®¾æˆ‘ä»¬ä½¿ç”¨48x48åƒç´ çš„å½©è‰²å›¾åƒ
num_classes = 5  # å‡è®¾æœ‰5ç§æƒ…æ„ŸçŠ¶æ€

# æ„å»ºæ¨¡å‹
advanced_emotion_model = build_advanced_model(input_shape, num_classes)

# æ˜¾ç¤ºæ¨¡å‹æ¦‚è¦
advanced_emotion_model.summary()

# è·å–æœ€ä½³è¶…å‚æ•°
best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]

# ä½¿ç”¨æœ€ä½³è¶…å‚æ•°æ„å»ºæ¨¡å‹
model = tuner.hypermodel.build(best_hps)

# è®­ç»ƒæ¨¡å‹
history = model.fit(train_generator, epochs=50, validation_data=validation_generator)

# æµ‹è¯•æ¨¡å‹
# è¿™é‡Œå‡è®¾æ‚¨æœ‰ä¸€ä¸ªå•ç‹¬çš„æµ‹è¯•æ•°æ®é›†
test_datagen = ImageDataGenerator(rescale=1./255)
test_generator = test_datagen.flow_from_directory(
        'path_to_your_test_dataset',
        target_size=(img_width, img_height),
        batch_size=batch_size,
        class_mode='categorical')

test_loss, test_acc = model.evaluate(test_generator)
print('Test accuracy:', test_acc)

# è·å–æœ€ä½³è¶…å‚æ•°
best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]

# ä½¿ç”¨æœ€ä½³è¶…å‚æ•°æ„å»ºæ¨¡å‹
model = tuner.hypermodel.build(best_hps)

# è®­ç»ƒæ¨¡å‹
history = model.fit(train_generator, epochs=50, validation_data=validation_generator)

# æµ‹è¯•æ¨¡å‹
# è¿™é‡Œå‡è®¾æ‚¨æœ‰ä¸€ä¸ªå•ç‹¬çš„æµ‹è¯•æ•°æ®é›†
test_datagen = ImageDataGenerator(rescale=1./255)
test_generator = test_datagen.flow_from_directory(
        'path_to_your_test_dataset',
        target_size=(img_width, img_height),
        batch_size=batch_size,
        class_mode='categorical')

test_loss, test_acc = model.evaluate(test_generator)
print('Test accuracy:', test_acc)

"""#### ResNet50"""

from tensorflow.keras.applications import ResNet50
from tensorflow.keras.optimizers import Adam

# åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
model = ResNet50(weights='imagenet', include_top=False)

# å¾®è°ƒå‚æ•°
learning_rate = 1e-4
batch_size = 32

# ç¼–è¯‘æ¨¡å‹
model.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])

# æ•°æ®å‡†å¤‡å’Œè®­ç»ƒ
# train_data = ...

model.fit(train_data, batch_size=batch_size)

...

"""#### YOLOs

##### v1
"""



"""##### v2"""



"""##### v3"""



"""##### v4"""

# ä½¿ç”¨é¢„è®­ç»ƒçš„ YOLO æ¨¡å‹
# æ³¨æ„ï¼šYOLO æ¨¡å‹çš„å®ç°é€šå¸¸æ¯”è¾ƒå¤æ‚ï¼Œéœ€è¦ä¾èµ–ç‰¹å®šåº“

detected_objects = yolo_model.predict(image)

"""##### v5"""



"""##### v6"""



"""##### v7"""



"""##### v8"""



"""#### VGG16"""

# train a Linear Classifier

# initialize parameters randomly
W = 0.01 * np.random.randn(D,K)
b = np.zeros((1,K))

# some hyperparameters
step_size = 1e-0
reg = 1e-3 # regularization strength

# gradient descent loop
num_examples = X.shape[0]
for i in range(200):

  # evaluate class scores, [N x K]
  scores = np.dot(X, W) + b

  # compute the class probabilities
  exp_scores = np.exp(scores)
  probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True) # [N x K]

  # compute the loss: average cross-entropy loss and regularization
  correct_logprobs = -np.log(probs[range(num_examples),y])
  data_loss = np.sum(correct_logprobs)/num_examples
  reg_loss = 0.5*reg*np.sum(W*W)
  loss = data_loss + reg_loss
  if i % 10 == 0:
    print "iteration %d: loss %f" % (i, loss)

  # compute the gradient on scores
  dscores = probs
  dscores[range(num_examples),y] -= 1
  dscores /= num_examples

  # backpropate the gradient to the parameters (W,b)
  dW = np.dot(X.T, dscores)
  db = np.sum(dscores, axis=0, keepdims=True)

  dW += reg*W # regularization gradient

  # perform a parameter update
  W += -step_size * dW
  b += -step_size * db



# evaluate training set accuracy
scores = np.dot(X, W) + b
predicted_class = np.argmax(scores, axis=1)
print 'training accuracy: %.2f' % (np.mean(predicted_class == y))

# initialize parameters randomly
h = 100 # size of hidden layer
W = 0.01 * np.random.randn(D,h)
b = np.zeros((1,h))
W2 = 0.01 * np.random.randn(h,K)
b2 = np.zeros((1,K))

# evaluate class scores with a 2-layer Neural Network
hidden_layer = np.maximum(0, np.dot(X, W) + b) # note, ReLU activation
scores = np.dot(hidden_layer, W2) + b2

# backpropate the gradient to the parameters
# first backprop into parameters W2 and b2
dW2 = np.dot(hidden_layer.T, dscores)
db2 = np.sum(dscores, axis=0, keepdims=True)

dhidden = np.dot(dscores, W2.T)

# finally into W,b
dW = np.dot(X.T, dhidden)
db = np.sum(dhidden, axis=0, keepdims=True)



# initialize parameters randomly
h = 100 # size of hidden layer
W = 0.01 * np.random.randn(D,h)
b = np.zeros((1,h))
W2 = 0.01 * np.random.randn(h,K)
b2 = np.zeros((1,K))

# some hyperparameters
step_size = 1e-0
reg = 1e-3 # regularization strength

# gradient descent loop
num_examples = X.shape[0]
for i in range(10000):

  # evaluate class scores, [N x K]
  hidden_layer = np.maximum(0, np.dot(X, W) + b) # note, ReLU activation
  scores = np.dot(hidden_layer, W2) + b2

  # compute the class probabilities
  exp_scores = np.exp(scores)
  probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True) # [N x K]

  # compute the loss: average cross-entropy loss and regularization
  correct_logprobs = -np.log(probs[range(num_examples),y])
  data_loss = np.sum(correct_logprobs)/num_examples
  reg_loss = 0.5*reg*np.sum(W*W) + 0.5*reg*np.sum(W2*W2)
  loss = data_loss + reg_loss
  if i % 1000 == 0:
    print "iteration %d: loss %f" % (i, loss)

  # compute the gradient on scores
  dscores = probs
  dscores[range(num_examples),y] -= 1
  dscores /= num_examples

  # backpropate the gradient to the parameters
  # first backprop into parameters W2 and b2
  dW2 = np.dot(hidden_layer.T, dscores)
  db2 = np.sum(dscores, axis=0, keepdims=True)
  # next backprop into hidden layer
  dhidden = np.dot(dscores, W2.T)
  # backprop the ReLU non-linearity
  dhidden[hidden_layer <= 0] = 0
  # finally into W,b
  dW = np.dot(X.T, dhidden)
  db = np.sum(dhidden, axis=0, keepdims=True)

  # add regularization gradient contribution
  dW2 += reg * W2
  dW += reg * W

  # perform a parameter update
  W += -step_size * dW
  b += -step_size * db
  W2 += -step_size * dW2
  b2 += -step_size * db2



# evaluate training set accuracy
hidden_layer = np.maximum(0, np.dot(X, W) + b)
scores = np.dot(hidden_layer, W2) + b2
predicted_class = np.argmax(scores, axis=1)
print 'training accuracy: %.2f' % (np.mean(predicted_class == y))

"""#### AlexNet

#### NiN (Network In Network)

#### VAE
"""

import tensorflow as tf
from tensorflow.keras import layers
import numpy as np

# ç®€å•çš„å˜åˆ†è‡ªç¼–ç å™¨æ¨¡å‹
class VAE(tf.keras.Model):
    def __init__(self, latent_dim):
        super(VAE, self).__init__()
        self.latent_dim = latent_dim
        self.encoder = tf.keras.Sequential([
            layers.InputLayer(input_shape=(784,)),
            layers.Dense(latent_dim + latent_dim),
        ])

        self.decoder = tf.keras.Sequential([
            layers.InputLayer(input_shape=(latent_dim,)),
            layers.Dense(units=28*28, activation=tf.nn.relu),
            layers.Reshape(target_shape=(784,))
        ])

    def encode(self, x):
        mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)
        return mean, logvar

    def reparameterize(self, mean, logvar):
        eps = tf.random.normal(shape=mean.shape)
        return eps * tf.exp(logvar * .5) + mean

    def decode(self, z, apply_sigmoid=False):
        logits = self.decoder(z)
        if apply_sigmoid:
            probs = tf.sigmoid(logits)
            return probs
        return logits

    def compute_loss(self, x):
        mean, logvar = self.encode(x)
        z = self.reparameterize(mean, logvar)
        x_logit = self.decode(z)

        cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)
        logpx_z = -tf.reduce_sum(cross_ent, axis=1)  # ä¿®æ”¹æ­¤å¤„
        logpz = -0.5 * tf.reduce_sum(z**2, axis=1)
        logqz_x = -0.5 * tf.reduce_sum(logvar + tf.exp(-logvar + 1e-10) + mean**2, axis=1)
        return -tf.reduce_mean(logpx_z + logpz - logqz_x)

    def generate_images(self, n_images=10):
        # ç”Ÿæˆéšæœºçš„æ½œåœ¨å˜é‡
        random_latent_vectors = tf.random.normal(shape=(n_images, self.latent_dim))

        # è§£ç æ½œåœ¨å˜é‡ä»¥ç”Ÿæˆå›¾åƒ
        predictions = self.decode(random_latent_vectors, apply_sigmoid=True)

        return predictions

import tensorflow as tf

class VAE(tf.keras.Model):
    def __init__(self, latent_dim, input_shape):
        super(VAE, self).__init__()
        self.latent_dim = latent_dim
        # è°ƒæ•´ç½‘ç»œç»“æ„ä»¥é€‚åº”ç‰¹å®šçš„è¾“å…¥å°ºå¯¸å’Œé¢œè‰²é€šé“
        self.encoder = tf.keras.Sequential([
            layers.InputLayer(input_shape=input_shape),
            layers.Conv2D(filters=32, kernel_size=3, activation='relu', strides=2, padding='same'),
            layers.Conv2D(filters=64, kernel_size=3, activation='relu', strides=2, padding='same'),
            layers.Flatten(),
            # äº§ç”Ÿæ½œåœ¨ç©ºé—´çš„å‡å€¼å’Œå¯¹æ•°æ–¹å·®
            layers.Dense(latent_dim + latent_dim),
        ])

        self.decoder = tf.keras.Sequential([
            layers.InputLayer(input_shape=(latent_dim,)),
            layers.Dense(units=7*7*32, activation='relu'),
            layers.Reshape(target_shape=(7, 7, 32)),
            layers.Conv2DTranspose(filters=64, kernel_size=3, activation='relu', strides=2, padding='same'),
            layers.Conv2DTranspose(filters=32, kernel_size=3, activation='relu', strides=2, padding='same'),
            # è°ƒæ•´æœ€åä¸€å±‚çš„è¿‡æ»¤å™¨æ•°é‡ä»¥åŒ¹é…å›¾åƒçš„é¢œè‰²é€šé“
            layers.Conv2DTranspose(filters=input_shape[-1], kernel_size=3, activation='sigmoid', padding='same'),
        ])

# æŒ‡å®šè¾“å…¥å›¾åƒçš„å°ºå¯¸å’Œé¢œè‰²é€šé“
input_shape = (28, 28, 1)  # ä¾‹å¦‚ï¼Œç°åº¦å›¾åƒçš„å°ºå¯¸ä¸º 28x28
latent_dim = 2
model = VAE(latent_dim, input_shape)

# ç¤ºä¾‹æ•°æ®
(x_train, _), _ = tf.keras.datasets.mnist.load_data()
x_train = x_train.astype("float32") / 255
x_train = x_train.reshape(x_train.shape[0], -1)  # å°† 28x28 å›¾åƒå±•å¹³ä¸º 784 ç»´å‘é‡

# åˆ›å»ºå’Œè®­ç»ƒ VAE æ¨¡å‹
latent_dim = 2
model = VAE(latent_dim)
optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)

# åˆ›å»ºæ•°æ®é›†
train_dataset = tf.data.Dataset.from_tensor_slices(x_train).batch(32)  # ä½¿ç”¨æ‰¹å¤§å°ä¸º32



# è®­ç»ƒå¾ªç¯
for epoch in range(10):
    total_loss = 0
    for x_batch in train_dataset:
        with tf.GradientTape() as tape:
            loss = model.compute_loss(x_batch)  # ä½¿ç”¨æ‰¹æ•°æ®
            total_loss += loss
        gradients = tape.gradient(loss, model.trainable_variables)
        optimizer.apply_gradients(zip(gradients, model.trainable_variables))
    print(f"Epoch {epoch + 1}, Loss: {total_loss / len(x_train)}")

# ç”Ÿæˆæ–°å›¾åƒ
generated_images = model.generate_images(n_images=10)

# é‡å¡‘ç”Ÿæˆçš„å›¾åƒä»¥ä¾¿æ˜¾ç¤º
reshaped_images = generated_images.numpy().reshape(-1, 28, 28)

# æ˜¾ç¤ºç”Ÿæˆçš„å›¾åƒ
import matplotlib.pyplot as plt

for i in range(reshaped_images.shape[0]):
    plt.subplot(2, 5, i + 1)
    plt.imshow(reshaped_images[i], cmap='gray')
    plt.axis('off')

plt.show()



"""### GANs

#### DCGAN
"""

import tensorflow as tf
from tensorflow.keras import layers

def make_generator_model():
    model = tf.keras.Sequential()
    model.add(layers.Dense(8*8*256, use_bias=False, input_shape=(100,)))
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    model.add(layers.Reshape((8, 8, 256)))
    assert model.output_shape == (None, 8, 8, 256)  # æ³¨æ„ï¼šNone æ˜¯æ‰¹é‡å¤§å°

    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))
    assert model.output_shape == (None, 8, 8, 128)
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))
    assert model.output_shape == (None, 16, 16, 64)
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(4, 4), padding='same', use_bias=False, activation='tanh'))
    assert model.output_shape == (None, 64, 64, 1)

    return model

generator = make_generator_model()

cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)

def discriminator_loss(real_output, fake_output):
    real_loss = cross_entropy(tf.ones_like(real_output), real_output)
    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)
    total_loss = real_loss + fake_loss
    return total_loss

def generator_loss(fake_output):
    return cross_entropy(tf.ones_like(fake_output), fake_output)

generator_optimizer = tf.keras.optimizers.Adam(1e-4)
discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)

import numpy as np

EPOCHS = 50
noise_dim = 100
num_examples_to_generate = 16

# ç”¨äºç”Ÿæˆå›¾åƒçš„éšæœºç§å­
seed = tf.random.normal([num_examples_to_generate, noise_dim])

@tf.function
def train_step(images):
    noise = tf.random.normal([BATCH_SIZE, noise_dim])

    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:
        generated_images = generator(noise, training=True)
        real_output = discriminator(images, training=True)
        fake_output = discriminator(generated_images, training=True)

        gen_loss = generator_loss(fake_output)
        disc_loss = discriminator_loss(real_output, fake_output)

    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)
    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)

    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))
    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))

def train(dataset, epochs):
    for epoch in range(epochs):
        for image_batch in dataset:
            train_step(image_batch)

# å‡è®¾ `train_dataset` æ˜¯é¢„å¤„ç†çš„å›¾åƒæ•°æ®é›†
train(train_dataset, EPOCHS)

"""### RNNs

#### RNN1
"""

def generate_images(generator, num_images):
    noise = tf.random.normal([num_images, noise_dim])
    generated_images = generator(noise, training=False)
    return generated_images

# å‡è®¾ noise_dim æ˜¯ä½ çš„å™ªå£°ç»´åº¦
noise_dim = 100
num_images = 100  # è¦ç”Ÿæˆçš„å›¾åƒæ•°é‡
generated_images = generate_images(generator, num_images)



# å‡è®¾ generated_images æ˜¯æ­¥éª¤ 1 ä¸­ç”Ÿæˆçš„å›¾åƒ
# è¿™é‡Œæˆ‘ä»¬ç®€å•åœ°å°†å›¾åƒæœ¬èº«ä½œä¸ºç‰¹å¾
image_features = generated_images.numpy().reshape(num_images, -1)



def create_dataset(image_features, sequence_length):
    x_train = []
    y_train = []
    for i in range(len(image_features) - sequence_length):
        x_train.append(image_features[i:i + sequence_length])
        y_train.append(image_features[i + sequence_length])
    return np.array(x_train), np.array(y_train)

# å®šä¹‰åºåˆ—é•¿åº¦
sequence_length = 5  # ä¾‹å¦‚ï¼Œä½¿ç”¨5ä¸ªè¿ç»­å›¾åƒçš„ç‰¹å¾ä½œä¸ºä¸€ä¸ªåºåˆ—

# ç”Ÿæˆè®­ç»ƒæ•°æ®
x_train, y_train = create_dataset(image_features, sequence_length)



# å®šä¹‰ RNN æ¨¡å‹
model = tf.keras.Sequential([
    tf.keras.layers.SimpleRNN(128, input_shape=(None, image_features.shape[-1])),
    tf.keras.layers.Dense(image_features.shape[-1])
])

# ç¼–è¯‘æ¨¡å‹
model.compile(optimizer='adam', loss='mean_squared_error')

# è®­ç»ƒæ¨¡å‹
# è¿™é‡Œéœ€è¦æ ¹æ®ä½ çš„å…·ä½“æƒ…å†µè°ƒæ•´è¾“å…¥æ•°æ®çš„å½¢çŠ¶å’Œç»„ç»‡æ–¹å¼
model.fit(x_train, y_train, epochs=10)



def neuron_tick(inputs):
  """
  assume input and we
  """

import AutoConfig, AutoModel
from transformers import DistilBertModel, DistilBertConfig

"""#### LSTM"""

import torch
from torch.utils.data import Dataset, DataLoader
import random

class VideoDataset(Dataset):
    def __init__(self, num_samples=100, num_frames=30, image_size=(3, 64, 64)):
        self.num_samples = num_samples
        self.num_frames = num_frames
        self.image_size = image_size
        self.data = torch.randn(num_samples, num_frames, *image_size)
        self.labels = torch.randint(0, 10, (num_samples,))

    def __len__(self):
        return self.num_samples

    def __getitem__(self, idx):
        return self.data[idx], self.labels[idx]

dataset = VideoDataset()
data_loader = DataLoader(dataset, batch_size=4, shuffle=True)



import torch.nn as nn
import torchvision.models as models

class VideoAnalysisModel(nn.Module):
    def __init__(self, num_frames, num_classes):
        super(VideoAnalysisModel, self).__init__()
        self.resnet = models.resnet18(pretrained=True)
        self.resnet.fc = nn.Identity()

        self.lstm = nn.LSTM(input_size=512, hidden_size=256, batch_first=True)
        self.fc = nn.Linear(256, num_classes)

    def forward(self, x):
        batch_size, num_frames, C, H, W = x.shape
        x = x.view(batch_size * num_frames, C, H, W)
        x = self.resnet(x)
        x = x.view(batch_size, num_frames, -1)
        x, _ = self.lstm(x)
        x = self.fc(x[:, -1, :])
        return x

model = VideoAnalysisModel(num_frames=30, num_classes=10)



device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

num_epochs = 5
for epoch in range(num_epochs):
    for frames, labels in data_loader:
        frames, labels = frames.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(frames)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}")

"""### OpenPose (Pose Detection)"""



"""### Image to Graph"""



"""## Graph

### GNNs

#### SAGE
"""



"""### GCN"""



# Commented out IPython magic to ensure Python compatibility.
"""
!pip install nocd
import nocd
"""

import matplotlib.pyplot as plt
import numpy as np
import scipy.sparse as sp
import torch
import torch.nn as nn
import torch.nn.functional as F

from sklearn.preprocessing import normalize

# %matplotlib inline

torch.set_default_tensor_type(torch.cuda.FloatTensor)

loader = nocd.data.load_dataset('data/mag_cs.npz')
A, X, Z_gt = loader['A'], loader['X'], loader['Z']
N, K = Z_gt.shape

hidden_sizes = [128]    # hidden sizes of the GNN
weight_decay = 1e-2     # strength of L2 regularization on GNN weights
dropout = 0.5           # whether to use dropout
batch_norm = True       # whether to use batch norm
lr = 1e-3               # learning rate
max_epochs = 500        # number of epochs to train
display_step = 25       # how often to compute validation loss
balance_loss = True     # whether to use balanced loss
stochastic_loss = True  # whether to use stochastic or full-batch training
batch_size = 20000      # batch size (only for stochastic training)

x_norm = normalize(X)  # node features
# x_norm = normalize(A)  # adjacency matrix
# x_norm = sp.hstack([normalize(X), normalize(A)])  # concatenate A and X
x_norm = nocd.utils.to_sparse_tensor(x_norm).cuda()

sampler = nocd.sampler.get_edge_sampler(A, batch_size, batch_size, num_workers=5)
gnn = nocd.nn.GCN(x_norm.shape[1], hidden_sizes, K, batch_norm=batch_norm, dropout=dropout).cuda()
adj_norm = gnn.normalize_adj(A)
decoder = nocd.nn.BerpoDecoder(N, A.nnz, balance_loss=balance_loss)
opt = torch.optim.Adam(gnn.parameters(), lr=lr)

def get_nmi(thresh=0.5):
    """Compute Overlapping NMI of the communities predicted by the GNN."""
    gnn.eval()
    Z = F.relu(gnn(x_norm, adj_norm))
    Z_pred = Z.cpu().detach().numpy() > thresh
    nmi = nocd.metrics.overlapping_nmi(Z_pred, Z_gt)
    return nmi

val_loss = np.inf
validation_fn = lambda: val_loss
early_stopping = nocd.train.NoImprovementStopping(validation_fn, patience=10)
model_saver = nocd.train.ModelSaver(gnn)

for epoch, batch in enumerate(sampler):
    if epoch > max_epochs:
        break
    if epoch % 25 == 0:
        with torch.no_grad():
            gnn.eval()
            # Compute validation loss
            Z = F.relu(gnn(x_norm, adj_norm))
            val_loss = decoder.loss_full(Z, A)
            print(f'Epoch {epoch:4d}, loss.full = {val_loss:.4f}, nmi = {get_nmi():.2f}')

            # Check if it's time for early stopping / to save the model
            early_stopping.next_step()
            if early_stopping.should_save():
                model_saver.save()
            if early_stopping.should_stop():
                print(f'Breaking due to early stopping at epoch {epoch}')
                break

    # Training step
    gnn.train()
    opt.zero_grad()
    Z = F.relu(gnn(x_norm, adj_norm))
    ones_idx, zeros_idx = batch
    if stochastic_loss:
        loss = decoder.loss_batch(Z, ones_idx, zeros_idx)
    else:
        loss = decoder.loss_full(Z, A)
    loss += nocd.utils.l2_reg_loss(gnn, scale=weight_decay)
    loss.backward()
    opt.step()

plt.hist(Z[Z > 0].cpu().detach().numpy(), 100);

thresh = 0.5

Z = F.relu(gnn(x_norm, adj_norm))
Z_pred = Z.cpu().detach().numpy() > thresh
model_saver.restore()
print(f'Final nmi = {get_nmi(thresh):.3f}')

plt.figure(figsize=[10, 10])
z = np.argmax(Z_pred, 1)
o = np.argsort(z)
nocd.utils.plot_sparse_clustered_adjacency(A, K, z, o, markersize=0.05)

# Sizes of detected communities
print(Z_pred.sum(0))

density_baseline = A.nnz / (N**2 - N)
num_triangles = (A @ A @ A).diagonal().sum() / 6
num_possible_triangles = (N - 2) * (N - 1) * N / 6
clust_coef_baseline = num_triangles / num_possible_triangles
print(f'Background (over the entire graph):\n'
      f' - density    = {density_baseline:.3e}\n'
      f' - clust_coef = {clust_coef_baseline:.3e}')

metrics = nocd.metrics.evaluate_unsupervised(Z_gt, A)
print(f"Ground truth communities:\n"
      f" - coverage    = {metrics['coverage']:.4f}\n"
      f" - conductance = {metrics['conductance']:.4f}\n"
      f" - density     = {metrics['density']:.3e}\n"
      f" - clust_coef  = {metrics['clustering_coef']:.3e}")

metrics = nocd.metrics.evaluate_unsupervised(Z_pred, A)
print(f"Predicted communities:\n"
      f" - coverage    = {metrics['coverage']:.4f}\n"
      f" - conductance = {metrics['conductance']:.4f}\n"
      f" - density     = {metrics['density']:.3e}\n"
      f" - clust_coef  = {metrics['clustering_coef']:.3e}")

"""#### Node2Vec"""



"""#### GAT"""

# å‡è®¾ä½¿ç”¨ PyTorch å’Œ PyTorch Geometric
import torch
!pip install torch_geometric
from torch_geometric.nn import GATConv  # å›¾æ³¨æ„åŠ›å±‚

class TextVisionGNN(torch.nn.Module):
    def __init__(self):
        super(TextVisionGNN, self).__init__()
        self.conv1 = GATConv(è¾“å…¥ç‰¹å¾ç»´åº¦, è¾“å‡ºç‰¹å¾ç»´åº¦)

    def forward(self, data):
        x, edge_index = data.x, data.edge_index
        x = self.conv1(x, edge_index)
        return torch.nn.functional.log_softmax(x, dim=1)

# ä½¿ç”¨æ¨¡å‹
model = TextVisionGNN()
# å‡è®¾ data æ˜¯åŒ…å«èŠ‚ç‚¹å’Œè¾¹çš„å›¾æ•°æ®
output = model(data)

"""#### HIN"""



"""#### HGNN"""



"""#### HetSANN"""



"""### Louvain"""

import networkx as nx
import community as community_louvain
import matplotlib.pyplot as plt

# åˆ›å»ºä¸€ä¸ªç¤ºä¾‹ç½‘ç»œ
G = nx.erdos_renyi_graph(30, 0.05)

# ä½¿ç”¨ Louvain ç®—æ³•è¿›è¡Œç¤¾åŒºæ£€æµ‹
partition = community_louvain.best_partition(G)

# ç»˜åˆ¶ç½‘ç»œå’Œç¤¾åŒº
pos = nx.spring_layout(G)
cmap = plt.cm.jet
plt.figure(figsize=(8, 8))
nx.draw_networkx_nodes(G, pos, partition.keys(), node_size=40,
                       cmap=cmap, node_color=list(partition.values()))
nx.draw_networkx_edges(G, pos, alpha=0.5)
plt.show()

# æ‰“å°ç¤¾åŒºæˆå‘˜
for i, comm in enumerate(set(partition.values())):
    print(f"ç¤¾åŒº {i}: {[nodes for nodes in partition.keys() if partition[nodes] == comm]}")

import networkx as nx
import numpy as np
import pandas as pd

G = nx.Graph()
G.add_node(1, pop=1000, pos=(0, 0))
G.add_node(2, pop=1500, pos=(1, 1))
G.add_node(3, pop=2000, pos=(2, 0))
G.add_edge(1, 2, weight=0.5, length=10)
G.add_edge(2, 3, weight=0.7, length=15)

...

"""## Time-Series

### RNNs

#### LSTM
"""

import pandas as pd

# å‡è®¾ df æ˜¯ä¸€ä¸ªä»¥æ—¶é—´ä¸ºç´¢å¼•çš„ DataFrame
df.resample('1H').mean()  # ä»¥1å°æ—¶ä¸ºå•ä½é‡é‡‡æ ·ï¼Œä½¿ç”¨å‡å€¼å¡«å……
df.interpolate(method='time')  # æ—¶é—´æ’å€¼

import numpy as np

# ç¤ºä¾‹ï¼šçº¿æ€§æ’å€¼
x = np.array([æ—¶é—´ç‚¹æ•°ç»„])
y = np.array([å¯¹åº”çš„å€¼æ•°ç»„])
new_x = np.array([æ–°çš„æ—¶é—´ç‚¹æ•°ç»„])
new_y = np.interp(new_x, x, y)

from scipy import interpolate

x = np.array([æ—¶é—´ç‚¹æ•°ç»„])
y = np.array([å¯¹åº”çš„å€¼æ•°ç»„])
f = interpolate.interp1d(x, y, kind='cubic')
new_y = f(new_x)

import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import yfinance as yf

# ä¸‹è½½è‚¡ç¥¨æ•°æ®
data = yf.download('AAPL', start='2020-01-01', end='2021-01-01')
prices = data['Close'].values.astype(float)

# æ•°æ®é¢„å¤„ç†ï¼šæ ‡å‡†åŒ–
prices = (prices - np.mean(prices)) / np.std(prices)
prices = prices.reshape(-1, 1)

# å°†æ•°æ®è½¬æ¢æˆæ•°æ®é›†
def create_dataset(data, time_step=1):
    dataX, dataY = [], []
    for i in range(len(data) - time_step - 1):
        a = data[i:(i + time_step), 0]
        dataX.append(a)
        dataY.append(data[i + time_step, 0])
    return np.array(dataX), np.array(dataY)

time_step = 10
X, y = create_dataset(prices, time_step)
train_size = int(len(X) * 0.7)
test_size = len(X) - train_size
trainX, testX = X[:train_size], X[train_size:]
trainY, testY = y[:train_size], y[train_size:]

# è½¬æ¢ä¸ºtorchå¼ é‡
trainX = torch.from_numpy(trainX).type(torch.Tensor)
trainY = torch.from_numpy(trainY).type(torch.Tensor)
testX = torch.from_numpy(testX).type(torch.Tensor)
testY = torch.from_numpy(testY).type(torch.Tensor)

# å®šä¹‰LSTMæ¨¡å‹
class LSTM(nn.Module):
    def __init__(self, input_size=1, hidden_layer_size=100, output_size=1):
        super().__init__()
        self.hidden_layer_size = hidden_layer_size
        self.lstm = nn.LSTM(input_size, hidden_layer_size)
        self.linear = nn.Linear(hidden_layer_size, output_size)
        self.hidden_cell = (torch.zeros(1, 1, self.hidden_layer_size),
                            torch.zeros(1, 1, self.hidden_layer_size))

    def forward(self, input_seq):
        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq) ,1, -1), self.hidden_cell)
        predictions = self.linear(lstm_out.view(len(input_seq), -1))
        return predictions[-1]

model = LSTM()
loss_function = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# è®­ç»ƒæ¨¡å‹
epochs = 150
for i in range(epochs):
    for seq, labels in zip(trainX, trainY):
        optimizer.zero_grad()
        model.hidden_cell = (torch.zeros(1, 1, model.hidden_layer_size),
                             torch.zeros(1, 1, model.hidden_layer_size))
        y_pred = model(seq)
        single_loss = loss_function(y_pred, labels)
        single_loss.backward()
        optimizer.step()
    if i%25 == 1:
        print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')

# é¢„æµ‹
with torch.no_grad():
    test_predictions = model(testX)
    test_predictions = test_predictions.view(-1).numpy()

plt.plot(testY, label='True')
plt.plot(test_predictions, label='Predictions')
plt.legend()
plt.show()

"""## Reinforcement Learning

### MDP
"""



"""### PO

#### DDPO
"""



"""#### PPO"""



"""### Q-Learning

#### DQN-wise
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
import torchvision.models as models
import random
import numpy as np

# å®šä¹‰ä¸€ä¸ªç®€å•çš„å›¾åƒ-æ–‡æœ¬èåˆç½‘ç»œ
class TextImageFusionModel(nn.Module):
    def __init__(self, text_input_dim, image_input_dim, output_dim):
        super(TextImageFusionModel, self).__init__()
        self.text_fc = nn.Linear(text_input_dim, 128)  # æ–‡æœ¬å¤„ç†å±‚
        self.image_fc = nn.Linear(image_input_dim, 128)  # å›¾åƒå¤„ç†å±‚
        self.output_fc = nn.Linear(256, output_dim)  # èåˆåçš„è¾“å‡ºå±‚

    def forward(self, text, image):
        text_features = torch.relu(self.text_fc(text))
        image_features = torch.relu(self.image_fc(image))
        combined_features = torch.cat((text_features, image_features), dim=1)
        output = self.output_fc(combined_features)
        return output

# DQN ä»£ç†
class DQNAgent:
    def __init__(self, text_input_dim, image_input_dim, output_dim):
        self.model = TextImageFusionModel(text_input_dim, image_input_dim, output_dim)
        self.optimizer = optim.Adam(self.model.parameters(), lr=0.001)

    def generate(self, text, image):
        # ç”ŸæˆåŠ¨ä½œï¼ˆåœ¨è¿™ä¸ªä¾‹å­ä¸­æ˜¯ä¸€äº›è¾“å‡ºå€¼ï¼‰
        output = self.model(text, image)
        return output

    def update(self, batch):
        # æ›´æ–°æ¨¡å‹ï¼ˆæ ¹æ®æ‚¨çš„å…·ä½“ä»»åŠ¡æ¥å®ç°ï¼‰
        pass

# å‡è®¾ç¯å¢ƒ
class FusionEnvironment:
    def reset(self):
        # åˆå§‹åŒ–ç¯å¢ƒå¹¶è¿”å›åˆå§‹çŠ¶æ€
        return torch.randn(10), torch.randn(512)  # å‡è®¾çš„æ–‡æœ¬å’Œå›¾åƒç‰¹å¾

    def step(self, action):
        # æ‰§è¡ŒåŠ¨ä½œå¹¶è¿”å›æ–°çŠ¶æ€å’Œå¥–åŠ±ï¼ˆéœ€è¦æ ¹æ®æ‚¨çš„å…·ä½“ä»»åŠ¡æ¥å®ç°ï¼‰
        new_state = torch.randn(10), torch.randn(512)  # æ–°çš„éšæœºçŠ¶æ€
        reward = random.random()  # éšæœºå¥–åŠ±
        return new_state, reward

# è®­ç»ƒå¾ªç¯
def train(env, agent, num_episodes):
    for episode in range(num_episodes):
        state = env.reset()
        total_reward = 0

        for t in range(100):
            text, image = state
            action = agent.generate(text, image)
            state, reward = env.step(action)
            total_reward += reward
            # å­˜å‚¨ç»éªŒã€æ›´æ–°æ¨¡å‹ç­‰

        print(f"Episode: {episode}, Total Reward: {total_reward}")

# å®ä¾‹åŒ–ç¯å¢ƒå’Œä»£ç†ï¼Œå¹¶å¼€å§‹è®­ç»ƒ
env = FusionEnvironment()
agent = DQNAgent(10, 512, 10)  # å‡è®¾çš„è¾“å…¥å’Œè¾“å‡ºç»´åº¦
train(env, agent, num_episodes=50)

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
import torchvision.models as models
import random
import numpy as np

# å®šä¹‰ä¸€ä¸ªç®€å•çš„å›¾åƒ-æ–‡æœ¬èåˆç½‘ç»œ
class TextImageFusionModel(nn.Module):
    def __init__(self, text_input_dim, image_input_dim, output_dim):
        super(TextImageFusionModel, self).__init__()
        self.text_fc = nn.Linear(text_input_dim, 128)  # æ–‡æœ¬å¤„ç†å±‚
        self.image_fc = nn.Linear(image_input_dim, 128)  # å›¾åƒå¤„ç†å±‚
        self.output_fc = nn.Linear(256, output_dim)  # èåˆåçš„è¾“å‡ºå±‚

    def forward(self, text, image):
        text_features = torch.relu(self.text_fc(text))
        image_features = torch.relu(self.image_fc(image))
        combined_features = torch.cat((text_features, image_features), dim=1)
        output = self.output_fc(combined_features)
        return output

# DQN ä»£ç†
class DQNAgent:
    def __init__(self, text_input_dim, image_input_dim, output_dim):
        self.model = TextImageFusionModel(text_input_dim, image_input_dim, output_dim)
        self.optimizer = optim.Adam(self.model.parameters(), lr=0.001)

    def generate(self, text, image):
        # ç”ŸæˆåŠ¨ä½œï¼ˆåœ¨è¿™ä¸ªä¾‹å­ä¸­æ˜¯ä¸€äº›è¾“å‡ºå€¼ï¼‰
        output = self.model(text, image)
        return output

    def update(self, batch):
        # æ›´æ–°æ¨¡å‹ï¼ˆæ ¹æ®æ‚¨çš„å…·ä½“ä»»åŠ¡æ¥å®ç°ï¼‰
        pass

# å‡è®¾ç¯å¢ƒ
class FusionEnvironment:
    def reset(self):
        # åˆå§‹åŒ–ç¯å¢ƒå¹¶è¿”å›åˆå§‹çŠ¶æ€
        return torch.randn(10), torch.randn(512)  # å‡è®¾çš„æ–‡æœ¬å’Œå›¾åƒç‰¹å¾

    def step(self, action):
        # æ‰§è¡ŒåŠ¨ä½œå¹¶è¿”å›æ–°çŠ¶æ€å’Œå¥–åŠ±ï¼ˆéœ€è¦æ ¹æ®æ‚¨çš„å…·ä½“ä»»åŠ¡æ¥å®ç°ï¼‰
        new_state = torch.randn(10), torch.randn(512)  # æ–°çš„éšæœºçŠ¶æ€
        reward = random.random()  # éšæœºå¥–åŠ±
        return new_state, reward

# è®­ç»ƒå¾ªç¯
def train(env, agent, num_episodes):
    for episode in range(num_episodes):
        state = env.reset()
        total_reward = 0

        for t in range(100):
            text, image = state
            action = agent.generate(text, image)
            state, reward = env.step(action)
            total_reward += reward
            # å­˜å‚¨ç»éªŒã€æ›´æ–°æ¨¡å‹ç­‰

        print(f"Episode: {episode}, Total Reward: {total_reward}")

# å®ä¾‹åŒ–ç¯å¢ƒå’Œä»£ç†ï¼Œå¹¶å¼€å§‹è®­ç»ƒ
env = FusionEnvironment()
agent = DQNAgent(10, 512, 10)  # å‡è®¾çš„è¾“å…¥å’Œè¾“å‡ºç»´åº¦
train(env, agent, num_episodes=50)



import torch
import torch.nn as nn
import torch.optim as optim
import random
import numpy as np

# å‡è®¾ç¯å¢ƒæä¾›ä»¥ä¸‹æ¥å£
class Environment:
    def reset(self):
        # é‡ç½®ç¯å¢ƒåˆ°åˆå§‹çŠ¶æ€
        pass

    def step(self, action):
        # æ‰§è¡ŒåŠ¨ä½œï¼Œè¿”å›æ–°çŠ¶æ€ã€å¥–åŠ±å’Œå®Œæˆæ ‡å¿—
        pass

# å¤šæ¨¡æ€æ•°æ®å¤„ç†ç½‘ç»œï¼ˆCNN + LSTMï¼‰
class MultiModalNet(nn.Module):
    def __init__(self):
        super(MultiModalNet, self).__init__()
        # å®šä¹‰å¤„ç†å›¾åƒçš„ CNN éƒ¨åˆ†
        # å®šä¹‰å¤„ç†æ–‡æœ¬/æ—¶åºçš„ LSTM éƒ¨åˆ†
        # å®šä¹‰å…¶ä»–å¿…è¦çš„å±‚

    def forward(self, image, text):
        # å¤„ç†å›¾åƒæ•°æ®
        # å¤„ç†æ–‡æœ¬æ•°æ®
        # èåˆå¹¶è¿”å›å†³ç­–
        pass

# DQN ç®—æ³•
class DQN:
    def __init__(self):
        self.model = MultiModalNet()
        self.target_model = MultiModalNet()
        self.optimizer = optim.Adam(self.model.parameters(), lr=0.001)

    def select_action(self, state):
        # é€‰æ‹©åŠ¨ä½œ
        pass

    def update(self, batch):
        # æ›´æ–°æ¨¡å‹
        pass

# è®­ç»ƒå¾ªç¯
def train(env, agent, num_episodes):
    for episode in range(num_episodes):
        state = env.reset()
        total_reward = 0
        done = False

        while not done:
            action = agent.select_action(state)
            next_state, reward, done = env.step(action)

            # å­˜å‚¨ç»éªŒ
            # ...

            # æ›´æ–°æ¨¡å‹
            # ...

            state = next_state
            total_reward += reward

        print(f"Episode: {episode}, Total Reward: {total_reward}")

env = Environment()
agent = DQN()
train(env, agent, num_episodes=100)

import torch
import torch.nn as nn
import torch.optim as optim
import random

class TextImageGenerator(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim):
        super(TextImageGenerator, self).__init__()
        # ç½‘ç»œç»“æ„ï¼Œå¤„ç†è¾“å…¥å¹¶ç”Ÿæˆè¾“å‡º
        pass

class DQNGeneratorAgent:
    def __init__(self, input_dim, hidden_dim, output_dim):
        self.model = TextImageGenerator(input_dim, hidden_dim, output_dim)
        self.optimizer = optim.Adam(self.model.parameters(), lr=0.001)

    def generate(self, state):
        # æ ¹æ®çŠ¶æ€ç”Ÿæˆå†…å®¹
        pass

    def update(self, batch):
        # æ›´æ–°æ¨¡å‹
        pass

# å‡è®¾ç¯å¢ƒ
class TextImageEnvironment:
    def reset(self):
        # åˆå§‹åŒ–ç¯å¢ƒ
        pass

    def step(self, action):
        # æ ¹æ®åŠ¨ä½œç”Ÿæˆæ–°çš„çŠ¶æ€å’Œå¥–åŠ±
        pass

# è®­ç»ƒå¾ªç¯
def train_generator(env, agent, num_episodes):
    for episode in range(num_episodes):
        state = env.reset()
        total_reward = 0

        # åœ¨è¿™ä¸ªå¾ªç¯ä¸­ï¼Œagent éœ€è¦æ ¹æ®å½“å‰çŠ¶æ€ç”Ÿæˆå†…å®¹ï¼Œå¹¶ä»ç¯å¢ƒä¸­è·å–å¥–åŠ±
        for t in range(100):  # å‡è®¾æ¯ä¸ªepisodeæœ‰100ä¸ªæ—¶é—´æ­¥
            action = agent.generate(state)
            next_state, reward = env.step(action)
            state = next_state
            total_reward += reward
            # å­˜å‚¨ç»éªŒï¼Œæ›´æ–°æ¨¡å‹ç­‰

        print(f"Episode: {episode}, Total Reward: {total_reward}")

import gym
from gym import spaces
import spacy
import random

# åŠ è½½Spacyçš„è‹±æ–‡æ¨¡å‹
nlp = spacy.load('en_core_web_sm')

class SentimentAnalysisEnv(gym.Env):
    """ä¸€ä¸ªç®€åŒ–çš„æƒ…æ„Ÿåˆ†æç¯å¢ƒ"""
    metadata = {'render.modes': ['console']}

    def __init__(self):
        super(SentimentAnalysisEnv, self).__init__()
        # å®šä¹‰ä¸€ä¸ªåªæœ‰ä¸¤ä¸ªåŠ¨ä½œçš„åŠ¨ä½œç©ºé—´ï¼š0ï¼ˆè´Ÿé¢æƒ…æ„Ÿï¼‰ï¼Œ1ï¼ˆæ­£é¢æƒ…æ„Ÿï¼‰
        self.action_space = spaces.Discrete(2)
        # å‡è®¾çŠ¶æ€ç©ºé—´æ˜¯ä¸€ä¸ªå¥å­çš„å‘é‡è¡¨ç¤º
        self.observation_space = spaces.Box(low=-1, high=1, shape=(300,), dtype=float)
        # æ¨¡æ‹Ÿçš„æ–‡æœ¬æ•°æ®
        self.text_data = [
            ("I love this!", 1),
            ("I hate this!", 0),
            ("This is great!", 1),
            ("This is awful!", 0)
        ]

    def step(self, action):
        text, true_sentiment = self.current_text
        # å¦‚æœä»£ç†çš„åŠ¨ä½œå’Œå®é™…æƒ…æ„Ÿä¸€è‡´ï¼Œç»™äºˆæ­£å¥–åŠ±
        reward = 1 if action == true_sentiment else -1
        # è¿™é‡Œæ²¡æœ‰çœŸæ­£çš„çŠ¶æ€ï¼Œåªæ˜¯è¿”å›ä¸‹ä¸€ä¸ªæ–‡æœ¬
        done = True  # æ¯ä¸ªä¾‹å­åªåšä¸€æ¬¡åˆ¤æ–­
        return self._next_observation(), reward, done, {}

    def reset(self):
        # éšæœºé€‰æ‹©ä¸€ä¸ªæ–°æ–‡æœ¬
        self.current_text = random.choice(self.text_data)
        return self._next_observation()

    def render(self, mode='console'):
        if mode != 'console':
            raise NotImplementedError()
        text, sentiment = self.current_text
        print(f"Text: {text}, Sentiment: {'Positive' if sentiment else 'Negative'}")

    def _next_observation(self):
        # è¿™é‡Œåªæ˜¯ä¸€ä¸ªç¤ºä¾‹ï¼Œæˆ‘ä»¬è¿”å›ä¸€ä¸ªç©ºçš„å‘é‡ï¼Œå®é™…ä¸Šåº”è¯¥æ˜¯æ–‡æœ¬çš„å‘é‡è¡¨ç¤º
        return self.observation_space.sample()

# åˆ›å»ºå’Œä½¿ç”¨ç¯å¢ƒ
env = SentimentAnalysisEnv()
obs = env.reset()
env.render()

# å‡è®¾ä»£ç†æ€»æ˜¯é¢„æµ‹æ­£é¢æƒ…æ„Ÿ
action = 1
obs, reward, done, info = env.step(action)
print(f"Reward: {reward}")

"""# Experiments for the NLP Project

## Contrastive Learning

### Contrastive Tension
"""

# å¯¼å…¥ç›¸å…³çš„åŒ…
import numpy as np

# æ‰©å±•çš„åµŒå…¥è¡¨ç¤º
embedding_A = np.array([1, 2])
embedding_B = np.array([2, 1])
embedding_C = np.array([8, 9])
embedding_D = np.array([9, 8])
embedding_E = np.array([1, -2])
embedding_F = np.array([-2, 1])

# å®šä¹‰ä¸€ä¸ªå‡½æ•°æ¥è®¡ç®—ä¸¤ä¸ªåµŒå…¥ä¹‹é—´çš„æ¬§æ°è·ç¦»
def euclidean_distance(vec1, vec2):
    return np.sqrt(np.sum((np.array(vec1) - np.array(vec2))**2))

# è®¡ç®—æ‰©å±•æ•°æ®é›†ä¸­æ‰€æœ‰å¯èƒ½çš„æ­£æ ·æœ¬å¯¹å’Œè´Ÿæ ·æœ¬å¯¹ä¹‹é—´çš„è·ç¦»
distances = {
    "A-B": euclidean_distance(embedding_A, embedding_B),
    "C-D": euclidean_distance(embedding_C, embedding_D),
    "E-F": euclidean_distance(embedding_E, embedding_F),
    "A-C": euclidean_distance(embedding_A, embedding_C),
    "A-D": euclidean_distance(embedding_A, embedding_D),
    "A-E": euclidean_distance(embedding_A, embedding_E),
    "A-F": euclidean_distance(embedding_A, embedding_F),
    # å¯ä»¥ç»§ç»­æ·»åŠ æ›´å¤šçš„è·ç¦»è®¡ç®—
}

# æ‰“å°è®¡ç®—ç»“æœ
for pair, distance in distances.items():
    print(f"è·ç¦» {pair}: {distance}")

"""# Multi-Modal Data Mining Tasks

## Audio-Text

### Simple Fusion
"""

import torch
from torch.utils.data import Dataset, DataLoader
import numpy as np

class AudioTextDataset(Dataset):
    def __init__(self, num_samples=100, audio_size=1000, text_length=50, vocab_size=10000):
        self.num_samples = num_samples
        self.audio_data = torch.randn(num_samples, audio_size)  # éšæœºç”ŸæˆéŸ³é¢‘æ•°æ®
        self.text_data = torch.randint(low=0, high=vocab_size, size=(num_samples, text_length))  # éšæœºç”Ÿæˆæ–‡æœ¬æ•°æ®
        self.labels = torch.randint(0, 2, (num_samples,))  # å‡è®¾æ˜¯ä¸€ä¸ªäºŒåˆ†ç±»é—®é¢˜

    def __len__(self):
        return self.num_samples

    def __getitem__(self, idx):
        return self.audio_data[idx], self.text_data[idx], self.labels[idx]

# åˆ›å»ºæ•°æ®é›†å’Œæ•°æ®åŠ è½½å™¨
dataset = AudioTextDataset()
data_loader = DataLoader(dataset, batch_size=4, shuffle=True)

import torch.nn as nn

class AudioTextFusionModel(nn.Module):
    def __init__(self, audio_input_size, text_input_dim, hidden_size, output_dim, vocab_size):
        super(AudioTextFusionModel, self).__init__()
        self.audio_fc = nn.Linear(audio_input_size, hidden_size)  # éŸ³é¢‘æ•°æ®çš„å…¨è¿æ¥å±‚
        self.text_embedding = nn.Embedding(vocab_size, text_input_dim)  # æ–‡æœ¬æ•°æ®çš„åµŒå…¥å±‚
        self.text_lstm = nn.LSTM(text_input_dim, hidden_size, batch_first=True)  # æ–‡æœ¬æ•°æ®çš„ LSTM å±‚
        self.fc = nn.Linear(2 * hidden_size, output_dim)  # èåˆéŸ³é¢‘å’Œæ–‡æœ¬åçš„å…¨è¿æ¥å±‚

    def forward(self, audio, text):
        audio_output = torch.relu(self.audio_fc(audio))
        text_embedded = self.text_embedding(text)
        _, (text_output, _) = self.text_lstm(text_embedded)
        text_output = text_output[-1]
        combined = torch.cat((audio_output, text_output), dim=1)
        output = self.fc(combined)
        return output

# è®¾ç½®è®¾å¤‡
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# å®šä¹‰æ¨¡å‹å‚æ•°
audio_input_size = 1000
text_input_dim = 128
hidden_size = 128
output_dim = 2
vocab_size = 10000

# å®ä¾‹åŒ–æ¨¡å‹ã€æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
model = AudioTextFusionModel(audio_input_size, text_input_dim, hidden_size, output_dim, vocab_size).to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# è®­ç»ƒå¾ªç¯
num_epochs = 5
for epoch in range(num_epochs):
    for audio, text, labels in data_loader:
        audio, text, labels = audio.to(device), text.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(audio, text)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}")



"""## Audio-Image (Video)

### Simple Fusion
"""

import torch
from torch.utils.data import Dataset, DataLoader

class VideoDataset(Dataset):
    def __init__(self, num_samples=100, audio_size=1000, image_size=(3, 64, 64)):
        self.num_samples = num_samples
        self.audio_data = torch.randn(num_samples, audio_size)  # éšæœºç”ŸæˆéŸ³é¢‘æ•°æ®
        self.image_data = torch.randn(num_samples, *image_size)  # éšæœºç”Ÿæˆå›¾åƒæ•°æ®
        self.labels = torch.randint(0, 10, (num_samples,))  # å‡è®¾æœ‰10ä¸ªç±»åˆ«

    def __len__(self):
        return self.num_samples

    def __getitem__(self, idx):
        return self.audio_data[idx], self.image_data[idx], self.labels[idx]

# å®ä¾‹åŒ–æ•°æ®é›†å’Œæ•°æ®åŠ è½½å™¨
dataset = VideoDataset()
data_loader = DataLoader(dataset, batch_size=4, shuffle=True)

import torch.nn as nn
import torchvision.models as models

class AudioImageFusionModel(nn.Module):
    def __init__(self, audio_input_size, image_input_dim, hidden_size, num_classes):
        super(AudioImageFusionModel, self).__init__()
        self.audio_fc = nn.Linear(audio_input_size, hidden_size)
        self.image_cnn = models.resnet18(pretrained=True)
        self.image_cnn.fc = nn.Linear(self.image_cnn.fc.in_features, hidden_size)
        self.fc = nn.Linear(2 * hidden_size, num_classes)

    def forward(self, audio, image):
        audio_features = torch.relu(self.audio_fc(audio))
        image_features = torch.relu(self.image_cnn(image))
        combined_features = torch.cat([audio_features, image_features], dim=1)
        output = self.fc(combined_features)
        return output

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

model = AudioImageFusionModel(audio_input_size=1000, image_input_dim=512, hidden_size=128, num_classes=10).to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

num_epochs = 5
for epoch in range(num_epochs):
    for audio, image, labels in data_loader:
        audio, image, labels = audio.to(device), image.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(audio, image)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}")

"""## Audio-Graph

### Simple Fusion
"""



"""## Audio-Time

### Simple Fusion
"""

import torch
from torch.utils.data import Dataset, DataLoader
import numpy as np

class AudioTimeSeriesDataset(Dataset):
    def __init__(self, num_samples=100, audio_size=1000, time_series_length=100):
        self.num_samples = num_samples
        self.audio_data = torch.randn(num_samples, audio_size)  # éšæœºç”ŸæˆéŸ³é¢‘æ•°æ®
        self.time_series_data = torch.randn(num_samples, time_series_length)  # éšæœºç”Ÿæˆæ—¶é—´åºåˆ—æ•°æ®
        self.labels = torch.randint(0, 2, (num_samples,))  # å‡è®¾æ˜¯ä¸€ä¸ªäºŒåˆ†ç±»é—®é¢˜

    def __len__(self):
        return self.num_samples

    def __getitem__(self, idx):
        return self.audio_data[idx], self.time_series_data[idx], self.labels[idx]

# å®ä¾‹åŒ–æ•°æ®é›†å’Œæ•°æ®åŠ è½½å™¨
dataset = AudioTimeSeriesDataset()
data_loader = DataLoader(dataset, batch_size=4, shuffle=True)

import torch.nn as nn

class AudioTimeSeriesFusionModel(nn.Module):
    def __init__(self, audio_input_size, time_series_input_size, hidden_size, output_dim):
        super(AudioTimeSeriesFusionModel, self).__init__()
        self.audio_fc = nn.Linear(audio_input_size, hidden_size)  # éŸ³é¢‘æ•°æ®çš„å…¨è¿æ¥å±‚
        self.time_series_fc = nn.Linear(time_series_input_size, hidden_size)  # æ—¶é—´åºåˆ—æ•°æ®çš„å…¨è¿æ¥å±‚
        self.fc = nn.Linear(2 * hidden_size, output_dim)  # èåˆåçš„å…¨è¿æ¥å±‚

    def forward(self, audio, time_series):
        audio_output = torch.relu(self.audio_fc(audio))
        time_series_output = torch.relu(self.time_series_fc(time_series))
        combined = torch.cat((audio_output, time_series_output), dim=1)
        output = self.fc(combined)
        return output

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

model = AudioTimeSeriesFusionModel(audio_input_size=1000, time_series_input_size=100, hidden_size=128, output_dim=2).to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

num_epochs = 5
for epoch in range(num_epochs):
    for audio, time_series, labels in data_loader:
        audio, time_series, labels = audio.to(device), time_series.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(audio, time_series)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}")

"""## Text-Image

### Simple Fusion
"""

import torch
import torch.nn as nn
import torchvision.models as models

class TextImageFusionModel(nn.Module):
    def __init__(self, text_embedding_dim, hidden_dim, vocab_size, num_classes):
        super(TextImageFusionModel, self).__init__()

        # æ–‡æœ¬éƒ¨åˆ† - LSTM
        self.embedding = nn.Embedding(vocab_size, text_embedding_dim)
        self.lstm = nn.LSTM(text_embedding_dim, hidden_dim, batch_first=True)

        # å›¾åƒéƒ¨åˆ† - CNN (ä½¿ç”¨é¢„è®­ç»ƒçš„ResNet)
        self.cnn = models.resnet18(pretrained=True)
        self.cnn.fc = nn.Identity()  # ç§»é™¤æœ€åçš„å…¨è¿æ¥å±‚

        # åˆ†ç±»å™¨
        self.fc = nn.Linear(hidden_dim + 512, num_classes)  # LSTMçš„è¾“å‡ºå’ŒCNNçš„è¾“å‡ºæ‹¼æ¥

    def forward(self, text, text_lengths, images):
        # æ–‡æœ¬å¤„ç†
        text_embedded = self.embedding(text)
        packed_input = nn.utils.rnn.pack_padded_sequence(text_embedded, text_lengths, batch_first=True, enforce_sorted=False)
        packed_output, (ht, ct) = self.lstm(packed_input)
        text_output = ht[-1]  # ä½¿ç”¨æœ€åä¸€ä¸ªéšè—çŠ¶æ€

        # å›¾åƒå¤„ç†
        image_output = self.cnn(images)

        # èåˆå¹¶åˆ†ç±»
        combined = torch.cat((text_output, image_output), dim=1)

        return self.fc(combined)  # ç¡®ä¿è¿™é‡Œè¿”å›çš„æ˜¯è¾“å‡ºå¼ é‡

def train(model, data_loader, criterion, optimizer, device, num_epochs):
    model.train()  # å°†æ¨¡å‹è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼
    for epoch in range(num_epochs):
        for text, text_lengths, images, labels in data_loader:
            text, images, labels = text.to(device), images.to(device), labels.to(device)

            optimizer.zero_grad()
            outputs = model(text, text_lengths, images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}")

def evaluate(model, data_loader, criterion, device):
    model.eval()  # å°†æ¨¡å‹è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    total_loss = 0
    correct = 0
    total = 0
    with torch.no_grad():
        for text, text_lengths, images, labels in data_loader:
            text, images, labels = text.to(device), images.to(device), labels.to(device)
            outputs = model(text, text_lengths, images)
            loss = criterion(outputs, labels)
            total_loss += loss.item()
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    avg_loss = total_loss / len(data_loader)
    accuracy = correct / total
    return avg_loss, accuracy

# æ¨¡å‹å‚æ•°
text_embedding_dim = 100
hidden_dim = 128
vocab_size = 10000  # å‡è®¾è¯æ±‡è¡¨å¤§å°ä¸º 10000
num_classes = 10  # å‡è®¾æœ‰ 10 ä¸ªç±»åˆ«

# å®ä¾‹åŒ–æ¨¡å‹
model = TextImageFusionModel(text_embedding_dim, hidden_dim, vocab_size, num_classes)

# å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# è®¾å¤‡é…ç½®
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

from torch.utils.data import Dataset, DataLoader
import torch
import random

class TextImageData(Dataset):
    def __init__(self, num_samples=100, text_len=20, vocab_size=10000, image_size=(3, 64, 64)):
        self.num_samples = num_samples
        self.text_len = text_len
        self.vocab_size = vocab_size
        self.image_size = image_size

        # æ¨¡æ‹Ÿæ–‡æœ¬æ•°æ®ï¼šéšæœºç”Ÿæˆæ–‡æœ¬åºåˆ—
        self.texts = torch.randint(0, vocab_size, (num_samples, text_len))

        # æ¨¡æ‹Ÿå›¾åƒæ•°æ®ï¼šéšæœºç”Ÿæˆå›¾åƒ
        self.images = torch.randn(num_samples, *image_size)

        # æ¨¡æ‹Ÿæ ‡ç­¾æ•°æ®
        self.labels = torch.randint(0, 10, (num_samples,))

    def __len__(self):
        return self.num_samples

    def __getitem__(self, idx):
        text = self.texts[idx]
        image = self.images[idx]
        label = self.labels[idx]

        # ç”Ÿæˆæ–‡æœ¬é•¿åº¦ï¼ˆè¿™é‡Œç®€åŒ–ä¸ºå›ºå®šé•¿åº¦ï¼‰
        text_length = self.text_len

        return text, text_length, image, label

# åˆ›å»ºæ•°æ®é›†
train_dataset = TextImageData()
test_dataset = TextImageData()

# åˆ›å»º DataLoader
train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)

# å‡è®¾ train_loader å’Œ test_loader æ˜¯æ‚¨çš„è®­ç»ƒå’Œæµ‹è¯•æ•°æ®åŠ è½½å™¨
num_epochs = 5
train(model, train_loader, criterion, optimizer, device, num_epochs)
test_loss, test_accuracy = evaluate(model, test_loader, criterion, device)
print(f"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}")

"""### Transformers

#### ViLBERT
"""



"""#### LXMERT"""



"""#### ()

## Text-Time

### Simple Fusion
"""

import torch
from torch.utils.data import Dataset, DataLoader
from transformers import BertTokenizer
import random
import numpy as np

# å‡è®¾çš„æ–‡æœ¬æ•°æ®å’Œæ—¶é—´åºåˆ—æ•°æ®
text_data = ["è¿™æ˜¯ä¸€æ¡æ–°é—»æ–‡æœ¬" + str(i) for i in range(100)]
time_series_data = np.random.rand(100, 10, 5)  # å‡è®¾æœ‰100æ¡æ•°æ®ï¼Œæ¯æ¡æœ‰10ä¸ªæ—¶é—´æ­¥é•¿ï¼Œæ¯ä¸ªæ—¶é—´æ­¥é•¿æœ‰5ä¸ªç‰¹å¾

# BERT tokenizer
tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')

# è‡ªå®šä¹‰æ•°æ®é›†
class TextTimeSeriesDataset(Dataset):
    def __init__(self, texts, time_series):
        self.texts = texts
        self.time_series = time_series
        self.tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')

    def __len__(self):
        return len(self.texts)

    def __getitem__(self, idx):
        # è·å–æ–‡æœ¬æ•°æ®å¹¶è¿›è¡Œç¼–ç 
        text = self.texts[idx]
        encoded_text = self.tokenizer.encode_plus(
            text,
            add_special_tokens=True,
            max_length=64,
            padding='max_length',
            return_attention_mask=True,
            return_tensors='pt',
            truncation=True
        )
        # è·å–æ—¶é—´åºåˆ—æ•°æ®
        series = torch.tensor(self.time_series[idx], dtype=torch.float32)
        return {
            'input_ids': encoded_text['input_ids'].flatten(),
            'attention_mask': encoded_text['attention_mask'].flatten(),
            'time_series': series
        }

# åˆ›å»ºæ•°æ®é›†å’Œæ•°æ®åŠ è½½å™¨
dataset = TextTimeSeriesDataset(text_data, time_series_data)
loader = DataLoader(dataset, batch_size=8, shuffle=True)

import torch
import torch.nn as nn
from transformers import BertModel

class TextTimeSeriesFusionModel(nn.Module):
    def __init__(self, bert_model_name, time_series_feature_size, hidden_size, output_size):
        super(TextTimeSeriesFusionModel, self).__init__()
        # æ–‡æœ¬ç»„ä»¶ - ä½¿ç”¨BERT
        self.bert = BertModel.from_pretrained(bert_model_name)
        # æ—¶åºç»„ä»¶ - ä½¿ç”¨LSTM
        self.lstm = nn.LSTM(input_size=time_series_feature_size, hidden_size=hidden_size, batch_first=True)
        # èåˆå±‚
        self.fc = nn.Linear(hidden_size + self.bert.config.hidden_size, output_size)

    def forward(self, input_ids, attention_mask, time_series):
        # å¤„ç†æ–‡æœ¬æ•°æ®
        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)
        text_representation = outputs.pooler_output
        # å¤„ç†æ—¶åºæ•°æ®
        _, (hidden, _) = self.lstm(time_series)
        # å–LSTMæœ€åä¸€ä¸ªéšè—çŠ¶æ€
        time_series_representation = hidden[-1]
        # èåˆæ–‡æœ¬å’Œæ—¶åºç‰¹å¾
        combined_representation = torch.cat((text_representation, time_series_representation), dim=1)
        # è¿›è¡Œé¢„æµ‹
        output = self.fc(combined_representation)
        return output

# è¶…å‚æ•°
bert_model_name = 'bert-base-chinese' # 'bert-base-uncased' as an alternative
time_series_feature_size = 5  # å‡è®¾æ—¶é—´åºåˆ—æ•°æ®æœ‰5ä¸ªç‰¹å¾
hidden_size = 128
output_size = 1  # ä¾‹å¦‚ï¼Œé¢„æµ‹ä»·æ ¼å˜åŠ¨

# å®ä¾‹åŒ–æ¨¡å‹
model = TextTimeSeriesFusionModel(bert_model_name, time_series_feature_size, hidden_size, output_size)

def train_model(model, data_loader, loss_fn, optimizer, num_epochs):
    for epoch in range(num_epochs):
        for batch in data_loader:
            input_ids = batch['input_ids']
            attention_mask = batch['attention_mask']
            time_series = batch['time_series']

            # æ¨¡å‹é¢„æµ‹
            predictions = model(input_ids, attention_mask, time_series)

            # è®¡ç®—æŸå¤±
            labels = torch.rand(predictions.shape)  # è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨éšæœºç”Ÿæˆçš„æ ‡ç­¾æ¥æ¨¡æ‹ŸçœŸå®æ ‡ç­¾
            loss = loss_fn(predictions, labels)

            # åå‘ä¼ æ’­
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            print(f"Epoch {epoch}, Loss: {loss.item()}")

# è®¾ç½®æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
loss_fn = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)

# å¼€å§‹è®­ç»ƒ
train_model(model, loader, loss_fn, optimizer, num_epochs=3)

def evaluate_model(model, data_loader, loss_fn):
    model.eval()  # å°†æ¨¡å‹è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    total_loss = 0
    with torch.no_grad():  # åœ¨è¯„ä¼°è¿‡ç¨‹ä¸­ä¸è®¡ç®—æ¢¯åº¦
        for batch in data_loader:
            input_ids = batch['input_ids']
            attention_mask = batch['attention_mask']
            time_series = batch['time_series']
            labels = torch.rand(input_ids.shape[0])  # å‡è®¾çš„æ ‡ç­¾

            predictions = model(input_ids, attention_mask, time_series)
            loss = loss_fn(predictions, labels.unsqueeze(1))
            total_loss += loss.item()

    avg_loss = total_loss / len(data_loader)
    print(f"Average Loss: {avg_loss:.4f}")

# è¯„ä¼°æ¨¡å‹
evaluate_model(model, loader, loss_fn)

"""## Image-Time

### Simple Fusion (Video)
"""

import torch
import torch.nn as nn
import torchvision.models as models

class CNNLSTM(nn.Module):
    def __init__(self, num_classes, hidden_size, num_layers):
        super(CNNLSTM, self).__init__()
        # ä½¿ç”¨é¢„è®­ç»ƒçš„ ResNet18 ä½œä¸º CNN éƒ¨åˆ†
        self.cnn = models.resnet18(pretrained=True)
        self.cnn.fc = nn.Identity()  # ç§»é™¤æœ€åçš„å…¨è¿æ¥å±‚

        # LSTM éƒ¨åˆ†
        self.lstm = nn.LSTM(input_size=512, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)

        # å…¨è¿æ¥å±‚ï¼Œç”¨äºåˆ†ç±»
        self.fc = nn.Linear(hidden_size, num_classes)

    def forward(self, images, sequences):
        batch_size, seq_len, c, h, w = images.shape
        cnn_out = torch.zeros(batch_size, seq_len, 512).to(images.device)

        for t in range(seq_len):
            # å¤„ç†æ¯ä¸€ä¸ªæ—¶é—´æ­¥çš„å›¾åƒ
            x = self.cnn(images[:, t, :, :, :])
            cnn_out[:, t, :] = x

        # LSTM éƒ¨åˆ†
        lstm_out, _ = self.lstm(cnn_out)

        # åˆ†ç±»
        out = self.fc(lstm_out[:, -1, :])
        return out

num_classes = 10  # å‡è®¾æˆ‘ä»¬æœ‰10ä¸ªç±»åˆ«
hidden_size = 128  # LSTMçš„éšè—å±‚å¤§å°
num_layers = 2  # LSTMçš„å±‚æ•°

model = CNNLSTM(num_classes, hidden_size, num_layers)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

import torch
from torch.utils.data import Dataset, DataLoader
import numpy as np

class MyDataset(Dataset):
    def __init__(self, num_samples=100, image_size=(3, 64, 64), sequence_length=30):
        self.num_samples = num_samples
        self.image_size = image_size
        self.sequence_length = sequence_length

        # æ¨¡æ‹Ÿæ•°æ®
        self.images = torch.randn(num_samples, *image_size)
        self.sequences = torch.randn(num_samples, sequence_length)
        self.labels = torch.randint(0, 10, (num_samples,))  # å‡è®¾æœ‰10ä¸ªç±»åˆ«

    def __len__(self):
        return self.num_samples

    def __getitem__(self, idx):
        return self.images[idx], self.sequences[idx], self.labels[idx]

# å®ä¾‹åŒ–æ•°æ®é›†
dataset = MyDataset()
data_loader = DataLoader(dataset, batch_size=4, shuffle=True)

# ç¤ºä¾‹ï¼šä» DataLoader ä¸­è·å–ä¸€æ‰¹æ•°æ®
for images, sequences, labels in data_loader:
    print(f"Images shape: {images.shape}")
    print(f"Sequences shape: {sequences.shape}")
    print(f"Labels: {labels}")
    break  # åªå±•ç¤ºç¬¬ä¸€æ‰¹æ•°æ®

def train(model, data_loader, criterion, optimizer, num_epochs):
    model.train()
    for epoch in range(num_epochs):
        for images, sequences, labels in data_loader:
            # å‡è®¾ images, sequences, labels æ˜¯ä» DataLoader ä¸­è·å–çš„
            images = images.unsqueeze(1)
            optimizer.zero_grad()
            outputs = model(images, sequences)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}")

# è®­ç»ƒæ¨¡å‹
train(model, data_loader, criterion, optimizer, num_epochs=5)

def evaluate(model, data_loader, criterion):
    model.eval()  # å°†æ¨¡å‹è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    total_loss = 0
    correct = 0
    total = 0

    with torch.no_grad():  # åœ¨è¯„ä¼°è¿‡ç¨‹ä¸­ä¸è®¡ç®—æ¢¯åº¦
        for images, sequences, labels in data_loader:
            images = images.unsqueeze(1)
            outputs = model(images, sequences)
            loss = criterion(outputs, labels)
            total_loss += loss.item()

            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    avg_loss = total_loss / len(data_loader)
    accuracy = correct / total
    return avg_loss, accuracy

test_loss, test_accuracy = evaluate(model, data_loader, criterion)
print(f"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}")

"""## Health Data (XML: Text, Image, Graph, Time-Series)

### Step Analysis

#### 0. Parsing
"""

import xml.etree.ElementTree as ET
import pandas as pd
from google.colab import drive
from datetime import datetime

# åŠ è½½google drive
drive.mount("/content/drive")

# ç”¨æ‚¨çš„ XML æ–‡ä»¶è·¯å¾„æ›¿æ¢è¿™é‡Œ
file_path = '/content/drive/MyDrive/output.xml'

# è§£æ XML æ–‡ä»¶
tree = ET.parse(file_path)
root = tree.getroot()

# æå–æ­¥æ•°æ•°æ®
steps_data = []
for record in root.findall('Record'):
    if record.get('type') == 'HKQuantityTypeIdentifierStepCount':
        date = record.get('creationDate')
        value = record.get('value')
        steps_data.append({'date': date, 'steps': int(value)})

# è½¬æ¢ä¸º DataFrame
df = pd.DataFrame(steps_data)

# å°†æ—¥æœŸå­—ç¬¦ä¸²è½¬æ¢ä¸º datetime å¯¹è±¡
df['date'] = pd.to_datetime(df['date'])

# å¯¹æ­¥æ•°è¿›è¡Œç®€å•ç»Ÿè®¡åˆ†æ
print("æ­¥æ•°ç»Ÿè®¡åˆ†æ:")
print(df.groupby(df['date'].dt.date)['steps'].sum().describe())

# å¯ä»¥æ ¹æ®éœ€è¦è¿›è¡Œæ›´å¤šå¤æ‚çš„åˆ†æ

"""#### 1. Plotting on Statistics"""

import matplotlib.pyplot as plt

# è®¾ç½®å›¾è¡¨å¤§å°
plt.figure(figsize=(10, 6))

# ç»˜åˆ¶æ¯å¤©çš„æ­¥æ•°
df.groupby(df['date'].dt.date)['steps'].sum().plot(kind='line')

plt.title('Daily Step Count Over Time')
plt.xlabel('Date')
plt.ylabel('Steps')
plt.show()

# æ·»åŠ æ˜ŸæœŸåˆ—
df['weekday'] = df['date'].dt.day_name()

# è®¡ç®—æ¯ä¸ªæ˜ŸæœŸçš„å¹³å‡æ­¥æ•°
weekday_steps = df.groupby('weekday')['steps'].mean().reindex(['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])

# ç»˜åˆ¶å›¾è¡¨
weekday_steps.plot(kind='bar')
plt.title('Average Steps by Day of Week')
plt.xlabel('Day of Week')
plt.ylabel('Average Steps')
plt.show()

# å®šä¹‰æ­¥æ•°æ°´å¹³çš„åˆ†ç±»
def categorize_steps(steps):
    if steps < 5000:
        return 'Low'
    elif 5000 <= steps < 10000:
        return 'Moderate'
    else:
        return 'High'

df['activity_level'] = df['steps'].apply(categorize_steps)

# è®¡ç®—æ¯ä¸ªç±»åˆ«çš„é¢‘ç‡
activity_levels = df['activity_level'].value_counts(normalize=True) * 100

# ç»˜åˆ¶å›¾è¡¨
activity_levels.plot(kind='bar')
plt.title('Activity Level Distribution')
plt.xlabel('Activity Level')
plt.ylabel('Percentage')
plt.show()

# è®¡ç®—æ—¥æ­¥æ•°æ€»å’Œ
daily_steps = df.groupby(df['date'].dt.date)['steps'].sum()

# è®¡ç®—å‡å€¼å’Œæ ‡å‡†å·®
mean_steps = daily_steps.mean()
std_steps = daily_steps.std()

# å¯»æ‰¾å¼‚å¸¸å€¼
outliers = daily_steps[(daily_steps < mean_steps - 2 * std_steps) | (daily_steps > mean_steps + 2 * std_steps)]
print("å¼‚å¸¸æ´»åŠ¨æ—¥ï¼š")
print(outliers)

"""#### 2. Time-Series

##### XML to CSV
"""

import xml.etree.ElementTree as ET
import pandas as pd

def parse_xml_to_csv(xml_file, csv_file):
    tree = ET.parse(xml_file)
    root = tree.getroot()

    health_data = []
    for record in root.findall('Record'):
        record_type = record.get('type')
        if record_type in ['HKQuantityTypeIdentifierStepCount', 'HKQuantityTypeIdentifierHeartRate']:
            date = record.get('creationDate')
            value = record.get('value')
            health_data.append({'date': date, 'type': record_type, 'value': value})

    df = pd.DataFrame(health_data)
    df.to_csv(csv_file, index=False)

# ä½¿ç”¨æ‚¨çš„ XML æ–‡ä»¶è·¯å¾„å’ŒæœŸæœ›çš„ CSV æ–‡ä»¶è·¯å¾„æ›¿æ¢è¿™é‡Œ
xml_file_path = '/content/drive/MyDrive/output.xml'
csv_file_path = '/content/drive/MyDrive/output.csv'

parse_xml_to_csv(xml_file_path, csv_file_path)

"""##### Visualization"""

import pandas as pd
from prophet import Prophet
import matplotlib.pyplot as plt

# è¯»å–CSVæ–‡ä»¶
csv_file_path = '/content/drive/MyDrive/output.csv'
df = pd.read_csv(csv_file_path)

# å°†æ—¥æœŸåˆ—è½¬æ¢ä¸ºdatetimeç±»å‹ï¼Œå¹¶ç­›é€‰æ­¥æ•°æ•°æ®
df['date'] = pd.to_datetime(df['date'])
steps_data = df[df['type'] == 'HKQuantityTypeIdentifierStepCount']

# å°†æ•°æ®èšåˆä¸ºæ¯æ—¥æ­¥æ•°æ€»å’Œ
daily_steps = steps_data.groupby(steps_data['date'].dt.date)['value'].sum().reset_index()
daily_steps.columns = ['ds', 'y']  # Prophetéœ€è¦åˆ—åä¸º'ds'ï¼ˆæ—¥æœŸï¼‰å’Œ'y'ï¼ˆé¢„æµ‹å€¼ï¼‰

# åˆ›å»ºProphetæ¨¡å‹
model = Prophet()
model.fit(daily_steps)

# æ„å»ºæœªæ¥æ—¥æœŸçš„æ•°æ®å¸§
future = model.make_future_dataframe(periods=30)  # é¢„æµ‹æ¥ä¸‹æ¥30å¤©çš„è¶‹åŠ¿

# è¿›è¡Œé¢„æµ‹
forecast = model.predict(future)

# ç»˜åˆ¶é¢„æµ‹ç»“æœ
fig1 = model.plot(forecast)
plt.title('Step Count Forecast')
plt.ylabel('Total Steps')
plt.xlabel('Date')

# æ˜¾ç¤ºå›¾å½¢
plt.show()

"""#### 3. Graph to Image"""

!pip install spacy
python -m spacy download en_core_web_sm



from google.colab import drive
import xml.etree.ElementTree as ET
import pandas as pd

drive.mount('/content/drive')

def parse_health_data(xml_file):
    tree = ET.parse(xml_file)
    root = tree.getroot()

    health_data = []
    for record in root.findall('.//Record'):
        health_record = {
            'type': record.get('type'),
            'value': record.get('value'),
            'date': record.get('startDate')  # æˆ– 'endDate'
        }
        health_data.append(health_record)

    return health_data

# ä½¿ç”¨å‡½æ•°è§£ææ•°æ®
xml_file = '/content/drive/MyDrive/output.xml'
health_data = parse_health_data(xml_file)

import networkx as nx

def build_health_graph(health_data):
    G = nx.Graph()

    for record in health_data:
        # å°†æ—¥æœŸä½œä¸ºèŠ‚ç‚¹
        date_node = record['date']
        G.add_node(date_node, type='date')

        # å°†å¥åº·æŒ‡æ ‡ä½œä¸ºèŠ‚ç‚¹ï¼Œå¹¶æ·»åŠ è¾¹è¿æ¥åˆ°æ—¥æœŸ
        health_node = f"{record['type']}_{record['date']}"
        G.add_node(health_node, type=record['type'], value=record['value'])
        G.add_edge(date_node, health_node)

    return G

health_graph = build_health_graph(health_data)

import networkx as nx

def build_large_health_graph(health_data):
    G = nx.Graph()

    for record in health_data:
        # ä¸ºäº†å¤„ç†å¤§å‹æ•°æ®ï¼Œå¯èƒ½éœ€è¦ç®€åŒ–èŠ‚ç‚¹å’Œè¾¹çš„å±æ€§
        date_node = record['date']
        health_node = f"{record['type']}_{record['date']}"

        # å¯èƒ½éœ€è¦æ ¹æ®æ•°æ®çš„æ€§è´¨æ¥è°ƒæ•´èŠ‚ç‚¹å’Œè¾¹çš„æ„å»ºæ–¹å¼
        if not G.has_node(date_node):
            G.add_node(date_node)
        if not G.has_node(health_node):
            G.add_node(health_node)

        G.add_edge(date_node, health_node)

    return G

# å‡è®¾ health_data æ˜¯å¤§å‹æ•°æ®é›†
large_health_graph = build_large_health_graph(large_health_data)

import matplotlib.pyplot as plt

# å¯è§†åŒ–æ•°æ®å›¾
plt.figure(figsize=(12, 8))
nx.draw(health_graph, with_labels=True, font_weight='bold')
plt.show()

import matplotlib.pyplot as plt

plt.figure(figsize=(12, 8))
nx.draw(health_graph, with_labels=True, font_weight='bold')
plt.show()

"""##### To Graph"""



"""##### To Image"""



"""### Heart Beat Analysis"""

from google.colab import drive
import xml.etree.ElementTree as ET

# é€’å½’å‡½æ•°æ‰“å°èŠ‚ç‚¹çš„å±æ€§
def print_attributes(element, indent=0):
    for child in element:
        attributes = child.attrib  # è·å–èŠ‚ç‚¹çš„æ‰€æœ‰å±æ€§
        if attributes:
            print("  " * indent + child.tag + ": " + str(attributes))
        print_attributes(child, indent+1)  # é€’å½’å¤„ç†å­èŠ‚ç‚¹

# åŠ è½½å¹¶è§£æXMLæ–‡ä»¶
drive.mount("/content/drive")
tree = ET.parse('drive/MyDrive/output.xml')
root = tree.getroot()

# æ‰“å°æ ¹èŠ‚ç‚¹çš„å±æ€§
print(root.tag + ": " + str(root.attrib))

# ä»æ ¹èŠ‚ç‚¹å¼€å§‹é€’å½’æ‰“å°æ‰€æœ‰å±æ€§
print_attributes(root)

import xml.etree.ElementTree as ET
import json

# è§£æXMLæ–‡ä»¶
tree = ET.parse('drive/MyDrive/output.xml')
root = tree.getroot()

# å‡è®¾æ¯ä¸ªRecordèŠ‚ç‚¹éƒ½åŒ…å«ä¸€ä¸ªJSONå­—ç¬¦ä¸²
for record in root.findall('.//Record'):
    # è·å–èŠ‚ç‚¹æ–‡æœ¬ï¼Œå®ƒæ˜¯ä¸€ä¸ªJSONå­—ç¬¦ä¸²
    json_text = record.text
    # è§£æJSON
    data = json.loads(json_text)

    # æå–'type'å­—æ®µ
    record_type = data['type']
    print(f"Original type: {record_type}")

    # è¿™é‡Œå¯ä»¥æ ¹æ®éœ€è¦ä¿®æ”¹'type'å­—æ®µ
    data['type'] = 'YourNewTypeValue'

    # æŠŠä¿®æ”¹åçš„æ•°æ®è½¬æ¢å›JSONå­—ç¬¦ä¸²å¹¶æ›´æ–°XMLèŠ‚ç‚¹æ–‡æœ¬
    record.text = json.dumps(data)

# å¦‚æœéœ€è¦ï¼Œå¯ä»¥å°†ä¿®æ”¹åçš„XMLæ ‘å†™å›æ–‡ä»¶
tree.write('modified_example.xml')

import xml.etree.ElementTree as ET

def parse_health_data(xml_file):
    """
    è§£æè‹¹æœå¥åº·æ•°æ®çš„XMLæ–‡ä»¶ã€‚
    """
    # è§£æXMLæ–‡ä»¶
    tree = ET.parse(xml_file)
    root = tree.getroot()

    # éå†XMLæ–‡ä»¶ä¸­çš„è®°å½•
    for record in root.findall('Record'):
        # æå–æ„Ÿå…´è¶£çš„æ•°æ®ï¼Œä¾‹å¦‚ç±»å‹ã€æ—¥æœŸå’Œå€¼
        record_type = record.get('type')
        record_date = record.get('startDate')
        record_value = record.get('value')

        # æ‰“å°æˆ–å¤„ç†è®°å½•æ•°æ®
        print(f"Type: {record_type}, Date: {record_date}, Value: {record_value}")

# ä½¿ç”¨ç¤ºä¾‹
xml_file_path = '.xml'  # æ›¿æ¢ä¸ºä½ çš„æ–‡ä»¶è·¯å¾„
parse_health_data(xml_file_path)

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

# å‡è®¾df_heart_rateså’Œdf_hrvå·²ç»åŒ…å«äº†æ­£ç¡®çš„ç‰¹å¾å’Œæ ‡ç­¾ï¼ˆ'label'ï¼‰
# 'label'å¯ä»¥æ˜¯åŸºäºå¿ƒç†è¯„ä¼°çš„æƒ…ç»ªæˆ–å‹åŠ›æ ‡ç­¾ï¼Œä¾‹å¦‚ï¼š0 = 'ä½å‹åŠ›', 1 = 'é«˜å‹åŠ›'

# ç¤ºä¾‹ï¼šç®€å•çš„éšæœºæ£®æ—åˆ†ç±»å™¨
X = df_heart_rates[['heart_rate', 'hrv']]  # ç‰¹å¾
y = df_heart_rates['label']  # æ ‡ç­¾

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

clf = RandomForestClassifier()
clf.fit(X_train, y_train)

# è¯„ä¼°æ¨¡å‹
accuracy = clf.score(X_test, y_test)
print(f"æ¨¡å‹å‡†ç¡®ç‡ï¼š{accuracy:.2f}")



"""### Sleep Time Analysis"""



"""### Harvard Clinical-NLP

#### Depression Analysis: Step, Heart Beat, and Sleep Time
"""



"""#### Anxiety Analysis: Traces, Eye Motion, and Captions"""



"""#### Microbiology: Genomics, Immunology, and

### Tertiary-Modal Learning
"""

import librosa

# å‡è®¾ audio_file æ˜¯éŸ³é¢‘æ–‡ä»¶è·¯å¾„
y, sr = librosa.load(audio_file)
mfccs = librosa.feature.mfcc(y=y, sr=sr)

from transformers import BertTokenizer, BertModel

tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
model = BertModel.from_pretrained('bert-base-uncased')

# å‡è®¾ text æ˜¯è¦åˆ†æçš„æ–‡æœ¬
inputs = tokenizer(text, return_tensors="pt", max_length=512, truncation=True)
outputs = model(**inputs)

import cv2
import dlib

# å‡è®¾ image_file æ˜¯å›¾åƒæ–‡ä»¶è·¯å¾„
image = cv2.imread(image_file)
face_detector = dlib.get_frontal_face_detector()
faces = face_detector(image, 1)
# å¯¹äºæ¯ä¸ªæ£€æµ‹åˆ°çš„è„¸éƒ¨ï¼Œæå–ç‰¹å¾

"""## Federated Learning

### åŒæ€åŠ å¯†
"""

!pip install pycryptodome numpy

from Crypto.PublicKey import RSA
from Crypto.Cipher import PKCS1_OAEP
import numpy as np

def generate_key_pair(key_size=2048):
    key = RSA.generate(key_size)
    private_key = key.export_key()
    public_key = key.publickey().export_key()
    return private_key, public_key

def encrypt_message(message, public_key):
    rsa_key = RSA.import_key(public_key)
    rsa_cipher = PKCS1_OAEP.new(rsa_key)
    encrypted_message = rsa_cipher.encrypt(message)
    return encrypted_message

def decrypt_message(encrypted_message, private_key):
    rsa_key = RSA.import_key(private_key)
    rsa_cipher = PKCS1_OAEP.new(rsa_key)
    decrypted_message = rsa_cipher.decrypt(encrypted_message)
    return decrypted_message

# ç”Ÿæˆå¯†é’¥å¯¹
private_key, public_key = generate_key_pair()

# åŠ å¯†ä¸€ä¸ªç®€å•çš„æ¶ˆæ¯
original_message = b"Hello, World!"
encrypted_message = encrypt_message(original_message, public_key)
print(f"Encrypted: {encrypted_message}")

# è§£å¯†æ¶ˆæ¯
decrypted_message = decrypt_message(encrypted_message, private_key)
print(f"Decrypted: {decrypted_message}")

"""### å¤šæ–¹å®‰å…¨è®¡ç®—"""

import random

def generate_shares(secret, n, threshold):
    """ åˆ†å‰²ç§˜å¯†ä¸ºnä»½ï¼Œå…¶ä¸­ä»»æ„thresholdä»½å¯ä»¥é‡å»ºç§˜å¯† """
    coeffs = [random.randint(0, 10**5) for _ in range(threshold - 1)] + [secret]
    shares = [(i, sum([coeff * (i ** power) for power, coeff in enumerate(coeffs)])) for i in range(1, n + 1)]
    return shares

def reconstruct_secret(shares, threshold):
    """ ä»sharesä¸­é‡å»ºç§˜å¯† """
    sum = 0
    for j, share_j in shares:
        product = share_j
        for i, _ in shares:
            if i != j:
                product *= i / (i - j)
        sum += product
    return round(sum)

# å®šä¹‰ç§˜å¯†å’Œå‚ä¸è€…æ•°é‡
secret = 12345
num_participants = 5
threshold = 3

# ç”Ÿæˆç§˜å¯†ä»½é¢
shares = generate_shares(secret, num_participants, threshold)

# é€‰å–ä»»æ„thresholdä»½è¿›è¡Œç§˜å¯†é‡å»º
selected_shares = random.sample(shares, threshold)
reconstructed_secret = reconstruct_secret(selected_shares, threshold)

print("åŸå§‹ç§˜å¯†:", secret)
print("é‡å»ºç§˜å¯†:", reconstructed_secret)

"""### å·®åˆ†éšç§"""

!pip install --upgrade opacus

import torch
from torch import nn, optim
from torchvision import datasets, transforms
from opacus import PrivacyEngine

# åŠ è½½æ•°æ®é›†
transform = transforms.Compose([transforms.ToTensor()])
train_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)
train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)

# å®šä¹‰ä¸€ä¸ªç®€å•çš„æ¨¡å‹
model = nn.Sequential(
    nn.Flatten(),
    nn.Linear(28 * 28, 128),
    nn.ReLU(),
    nn.Linear(128, 10)
)

# å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.05)

# åº”ç”¨å·®åˆ†éšç§
privacy_engine = PrivacyEngine()
model, optimizer, train_loader = privacy_engine.make_private(
    module=model,
    optimizer=optimizer,
    data_loader=train_loader,
    noise_multiplier=1.0,  # æ·»åŠ çš„å™ªå£°é‡
    max_grad_norm=1.0,     # æ¢¯åº¦çš„è£å‰ªé˜ˆå€¼
)

# è®­ç»ƒæ¨¡å‹
num_epochs = 3
for epoch in range(num_epochs):
    for inputs, targets in train_loader:
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, targets)
        loss.backward()
        optimizer.step()
    print(f"Epoch {epoch+1}/{num_epochs} completed.")

# è·å–å’Œæ‰“å°éšç§é¢„ç®—
target_delta = 1e-5  # ä¸€ä¸ªå¸¸è§çš„é€‰æ‹©ï¼Œå…·ä½“å€¼å–å†³äºæ•°æ®é›†çš„å¤§å°å’Œéšç§è¦æ±‚
epsilon = privacy_engine.get_epsilon(delta=target_delta)
print(f"Spent privacy budget: Îµ = {epsilon}, Î´ = {target_delta}")