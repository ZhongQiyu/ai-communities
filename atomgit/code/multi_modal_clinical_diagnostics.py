# -*- coding: utf-8 -*-
"""multi_modal_clinical_diagnostics.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Chg9mavivZANZ8FxPs-M76hl-2aOm_3S

# Single-Modal Learning Tasks
- Audio
- Text
- Image
- Graph
- Time-Series

## Preprocessing
"""

from google.colab import drive

drive.mount("/content/drive")

"""## Audio (Audio Processing)"""

# 1. 音频转文本
transcribed_text = asr_system.transcribe("audio_file.wav")

# 2. 文本分析
entities, relations = nlp_process(transcribed_text)

# 3. 构建知识图谱
graph = build_knowledge_graph(entities, relations)

# 4. 知识图谱分析
analysis_results = analyze_graph(graph)

"""### Load the Audio File"""

audio_file = "drive/MyDrive/哞き呼び声の彼方へ.wav"

"""### Simulation:
- Random Forest
- Support Vector Machine
"""

import librosa
import numpy as np
import soundfile as sf
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# 生成模拟音频数据的函数
def generate_sine_wave(freq, sample_rate, duration):
    x = np.linspace(0, duration, sample_rate * duration, endpoint=False)
    frequencies = x * freq
    y = np.sin((2 * np.pi) * frequencies)
    return y

# 加载音频文件并提取特征
def extract_features(audio, sample_rate):
    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)
    mfccs_processed = np.mean(mfccs.T, axis=0)
    return mfccs_processed

# 设置样本率和持续时间
sample_rate = 22050
duration = 5

# 生成三个不同频率的音频
audio1 = generate_sine_wave(440, sample_rate, duration)  # A4
audio2 = generate_sine_wave(880, sample_rate, duration)  # A5
audio3 = generate_sine_wave(1760, sample_rate, duration) # A6

# 提取特征
features = []
for audio in [audio1, audio2, audio3]:
    features.append(extract_features(audio, sample_rate))

features = np.array(features)
labels = np.array([0, 1, 0])  # 假设标签

# 划分训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)

# 训练 SVM 模型
svm_model = SVC(kernel='linear')
svm_model.fit(X_train, y_train)

# 训练随机森林模型
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# 预测并评估 SVM 模型
svm_predictions = svm_model.predict(X_test)
svm_accuracy = accuracy_score(y_test, svm_predictions)
print(f"SVM Model Accuracy: {svm_accuracy}")

# 预测并评估随机森林模型
rf_predictions = rf_model.predict(X_test)
rf_accuracy = accuracy_score(y_test, rf_predictions)
print(f"Random Forest Model Accuracy: {rf_accuracy}")

"""### Pre-processing"""

def extract_features_from_signal(audio_signal, sample_rate):
    # 提取MFCC特征
    mfccs = librosa.feature.mfcc(y=audio_signal, sr=sample_rate, n_mfcc=13)

    # 计算MFCC特征的统计数据
    mfccs_mean = np.mean(mfccs, axis=1)
    mfccs_std = np.std(mfccs, axis=1)

    # 提取音谱质心特征
    spectral_centroid = librosa.feature.spectral_centroid(y=audio_signal, sr=sample_rate)
    spectral_centroid_mean = np.mean(spectral_centroid)
    spectral_centroid_std = np.std(spectral_centroid)

    # 提取色度频率特征
    chroma_stft = librosa.feature.chroma_stft(y=audio_signal, sr=sample_rate)
    chroma_stft_mean = np.mean(chroma_stft, axis=1)
    chroma_stft_std = np.std(chroma_stft, axis=1)

    # 提取声谱滚降点特征
    spectral_rolloff = librosa.feature.spectral_rolloff(y=audio_signal, sr=sample_rate)
    spectral_rolloff_mean = np.mean(spectral_rolloff)
    spectral_rolloff_std = np.std(spectral_rolloff)

    # 提取零交叉率特征
    zero_crossing_rate = librosa.feature.zero_crossing_rate(y=audio_signal)
    zero_crossing_rate_mean = np.mean(zero_crossing_rate)
    zero_crossing_rate_std = np.std(zero_crossing_rate)

    # 提取声谱带宽特征
    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=audio_signal, sr=sample_rate)
    spectral_bandwidth_mean = np.mean(spectral_bandwidth)
    spectral_bandwidth_std = np.std(spectral_bandwidth)

    # 提取声谱对比度特征
    spectral_contrast = librosa.feature.spectral_contrast(y=audio_signal, sr=sample_rate)
    spectral_contrast_mean = np.mean(spectral_contrast, axis=1)
    spectral_contrast_std = np.std(spectral_contrast, axis=1)

    # 将所有特征合并成一个特征向量
    features = np.hstack((
        mfccs_mean, mfccs_std,
        spectral_centroid_mean, spectral_centroid_std,
        chroma_stft_mean, chroma_stft_std,
        spectral_rolloff_mean, spectral_rolloff_std,
        zero_crossing_rate_mean, zero_crossing_rate_std,
        spectral_bandwidth_mean, spectral_bandwidth_std,
        spectral_contrast_mean, spectral_contrast_std
    ))

    return features

"""### Emotion Analysis

#### Analytics
"""

def analyze_music_emotion_timeseries(audio_signal, sample_rate, window_size=5):
    # 窗口大小以秒为单位
    hop_length = int(window_size * sample_rate)

    # 分割成窗口
    num_windows = len(audio_signal) // hop_length
    emotions_timeseries = []

    for i in range(num_windows):
        start = i * hop_length
        end = start + hop_length
        window_signal = audio_signal[start:end]

        # 提取窗口信号的特征
        features = extract_features_from_signal(window_signal, sample_rate)
        # 分析情感
        emotion = analyze_music_emotion(features)
        emotions_timeseries.append(emotion)

    return emotions_timeseries

# 其他函数定义保持不变，只展示主程序部分
audio_signal, sample_rate = librosa.load(audio_file, sr=None)

# 时间序列情感分析
emotions_timeseries = analyze_music_emotion_timeseries(audio_signal, sample_rate, 2.5)

"""#### Visualization"""

# 绘制情感时间序列图
def plot_emotion_timeseries(emotions_timeseries):
    # 将情感转换为数字以便绘图
    emotions_to_num = {'Happy': 1, 'Excited': 2, 'Calm': 3, 'Sad': 4}
    numeric_emotions = [emotions_to_num[e] for e in emotions_timeseries]

    # 绘图
    plt.figure(figsize=(14, 5))
    plt.plot(numeric_emotions, marker='o', linestyle='-')
    plt.yticks([1, 2, 3, 4], ['Happy', 'Excited', 'Calm', 'Sad'])
    plt.title("Music Emotion Timeseries")
    plt.xlabel("Time Window")
    plt.ylabel("Emotion")
    plt.show()

plot_emotion_timeseries(emotions_timeseries)

"""#### Prediction: SVM"""

有没有

"""#### Prediction: Random Forest"""



"""#### Prediction: RNN"""

import librosa
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, GRU, Dense, Flatten, Conv2D, MaxPooling2D, GlobalAveragePooling2D
from tensorflow.keras.applications import MobileNetV2  # 用于MusiCNN示例

num_classes = 2  # 根据你的情感分类数目进行设置

# 提取音频特征
def extract_audio_features(audio_file):
    signal, rate = librosa.load(audio_file)

    # 提取MFCC特征
    mfccs = librosa.feature.mfcc(y=signal, sr=rate, n_mfcc=13)
    mfccs_mean = np.mean(mfccs, axis=1)

    # 提取音谱质心特征
    spectral_centroid = librosa.feature.spectral_centroid(y=signal, sr=rate)
    spectral_centroid_mean = np.mean(spectral_centroid)

    return mfccs_mean, spectral_centroid_mean

# 进行音乐情感分析
def analyze_music_emotion(audio_file, model):
    mfccs, spectral_centroid = extract_audio_features(audio_file)

    # 在这里，你可以使用适合的模型进行情感分类
    # 注意：这里的模型示例是随机初始化的，你需要加载预训练的权重来获得更好的性能

    # 示例：使用LSTM模型进行情感分类
    input_shape = (mfccs.shape[0], 1, mfccs.shape[1])
    mfccs = np.expand_dims(mfccs, axis=2)  # 添加一个维度以匹配输入形状
    emotion = model.predict(np.expand_dims(mfccs, axis=0))

    return emotion

"""#### Prediction: LSTM"""

def build_lstm_model(input_shape, num_classes):
    model = Sequential()
    model.add(LSTM(128, input_shape=input_shape, return_sequences=True))
    model.add(LSTM(128, return_sequences=True))
    model.add(LSTM(128))
    model.add(Dense(num_classes, activation='softmax'))
    return model

# 构建和编译LSTM模型
lstm_model = build_lstm_model(input_shape=(None, num_classes), num_classes=num_classes)
lstm_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

"""#### Prediction: GRU"""

def build_gru_model(input_shape, num_classes):
    model = Sequential()
    model.add(GRU(128, input_shape=input_shape, return_sequences=True))
    model.add(GRU(128, return_sequences=True))
    model.add(GRU(128))
    model.add(Dense(num_classes, activation='softmax'))
    return model

# 构建和编译GRU模型
    gru_model = build_gru_model(input_shape=(None, num_classes), num_classes=num_classes)
    gru_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

"""#### Prediction: MusiCNN"""

import librosa
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import matplotlib.pyplot as plt

class AudioCNN(nn.Module):
    def __init__(self, input_size, num_classes):
        super(AudioCNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)
        self.pool = nn.MaxPool2d(2, 2, padding=1)  # 增加 padding
        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)
        self.fc1 = nn.Linear(32 * (input_size[1] // 4) * (input_size[2] // 4), 128)  # 增加全连接层单元数
        self.fc2 = nn.Linear(128, num_classes)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(-1, 32 * (x.size()[2] // 4) * (x.size()[3] // 4))
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x

def build_musicnn_model(input_shape, num_classes):
    model = AudioCNN(input_shape, num_classes)  # 使用自定义的音频CNN模型
    return model

# 构建和编译MusiCNN模型
musicnn_model = build_musicnn_model(input_shape=(224, 224, 3), num_classes=2)
musicnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

"""#### Prediction: MusiCOG"""

# 构建MusiCOG模型
def build_musicog_model(input_shape, num_classes):
    model = Sequential()
    model.add(Conv2D(64, (3, 3), activation='relu', input_shape=input_shape))
    model.add(MaxPooling2D((2, 2)))
    model.add(Conv2D(128, (3, 3), activation='relu'))
    model.add(MaxPooling2D((2, 2)))
    model.add(Flatten())
    model.add(Dense(128, activation='relu'))
    model.add(Dense(num_classes, activation='softmax'))
    return model

# 构建和编译MusiCOG模型
musicog_model = build_musicog_model(input_shape=(mfccs.shape[0], mfccs.shape[1], 1), num_classes=num_classes)
musicog_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# 主程序

# 分析音乐情感并输出结果
lstm_emotion = analyze_music_emotion(audio_file, lstm_model)
gru_emotion = analyze_music_emotion(audio_file, gru_model)
musicnn_emotion = analyze_music_emotion(audio_file, musicnn_model)
musicog_emotion = analyze_music_emotion(audio_file, musicog_model)

print(f"LSTM 模型的情感分析结果：{lstm_emotion}")
print(f"GRU 模型的情感分析结果：{gru_emotion}")
print(f"MusiCNN 模型的情感分析结果：{musicnn_emotion}")
print(f"MusiCOG 模型的情感分析结果：{musicog_emotion}")

"""#### Prediction: MusicBERT"""



"""#### RAG"""

!pip install google-cloud-speech transformers datasets

from google.cloud import speech

def audio_to_text(audio_file_path):
    client = speech.SpeechClient()

    with open(audio_file_path, "rb") as audio_file:
        content = audio_file.read()

    audio = speech.RecognitionAudio(content=content)
    config = speech.RecognitionConfig(
        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
        sample_rate_hertz=16000,
        language_code="en-US",
    )

    response = client.recognize(config=config, audio=audio)

    transcript = " ".join([result.alternatives[0].transcript for result in response.results])
    return transcript

from transformers import RagTokenizer, RagTokenForGeneration

tokenizer = RagTokenizer.from_pretrained("facebook/rag-token-nq")
model = RagTokenForGeneration.from_pretrained("facebook/rag-token-nq")

def generate_response(text_input):
    inputs = tokenizer(text_input, return_tensors="pt")
    output_ids = model.generate(**inputs)
    response_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)
    return response_text

import networkx as nx

def build_graph(text_input, response_text):
    G = nx.Graph()
    G.add_node("input", text=text_input)
    G.add_node("response", text=response_text)
    G.add_edge("input", "response", relation="generates")
    return G

# 示例流程
audio_file_path = "path/to/your/audio.wav"
text_input = audio_to_text(audio_file_path)
response_text = generate_response(text_input)
G = build_graph(text_input, response_text)

# 在这个例子中，G是一个包含输入文本和RAG生成的响应文本的简单图

"""#### Prediction:

## Text (Natural Language Processing)
"""

import torch
import numpy as np
from sklearn.pipeline import make_pipeline
from sklearn.metrics import accuracy_score
from sklearn.naive_bayes import MultinomialNB
from sklearn.datasets import fetch_20newsgroups
from torch.utils.data import DataLoader, TensorDataset
from sklearn.feature_extraction.text import CountVectorizer

# 加载数据集
data = fetch_20newsgroups(subset='train', categories=['sci.space', 'rec.autos'])
X_train, y_train = data.data, data.target

data_test = fetch_20newsgroups(subset='test', categories=['sci.space', 'rec.autos'])
X_test, y_test = data_test.data, data_test.target

"""### Naive Bayes (NB)"""

# 创建一个管道，包括文本向量化和朴素贝叶斯分类器
model = make_pipeline(CountVectorizer(), MultinomialNB())

# 训练模型
model.fit(X_train, y_train)

# 预测和评估
predicted = model.predict(X_test)
print("Accuracy:", accuracy_score(y_test, predicted))

"""### Logistic Regression (LR)"""

from sklearn.linear_model import LogisticRegression

# 使用同样的数据集和向量化方法
model_lr = make_pipeline(CountVectorizer(), LogisticRegression())

# 训练模型
model_lr.fit(X_train, y_train)

# 预测和评估
predicted_lr = model_lr.predict(X_test)
print("Accuracy:", accuracy_score(y_test, predicted_lr))

"""### Multi-Layer Perceptron (MLP)"""

from sklearn.feature_extraction.text import CountVectorizer
import torch

# 将数据保证为字符串
X_train = [str(text) for text in X_train]
X_test = [str(text) for text in X_test]

# 使用 CountVectorizer 转换文本数据
vectorizer = CountVectorizer(max_features=5000, stop_words='english')
X_train_vec = vectorizer.fit_transform(X_train).toarray()
X_test_vec = vectorizer.transform(X_test).toarray()

# 将数据转换为 torch 张量
X_train_torch = torch.tensor(X_train_vec, dtype=torch.float32)
y_train_torch = torch.tensor(y_train, dtype=torch.long)
X_test_torch = torch.tensor(X_test_vec, dtype=torch.float32)
y_test_torch = torch.tensor(y_test, dtype=torch.long)

# 创建 DataLoader
train_dataset = TensorDataset(X_train_torch, y_train_torch)
train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)

import torch
import torch.nn as nn
import torch.optim as optim

class MLP(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim):
        super(MLP, self).__init__()
        self.fc1 = nn.Linear(input_dim, hidden_dim)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(hidden_dim, output_dim)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        return x

# 实例化模型
model_mlp = MLP(input_dim, hidden_dim, 2)

# 定义优化器和损失函数
optimizer = optim.Adam(model_mlp.parameters(), lr=0.001)
criterion = nn.CrossEntropyLoss()

# 训练循环
for epoch in range(num_epochs):
    for inputs, labels in train_loader:
        optimizer.zero_grad()
        outputs = model_mlp(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
    print(f"Epoch {epoch+1}/{num_epochs} completed.")

# 测试模型
model_mlp.eval()
with torch.no_grad():
    outputs = model_mlp(X_test_torch)
    _, predicted = torch.max(outputs, 1)
    accuracy = (predicted == y_test_torch).float().mean()
    print(f"Accuracy: {accuracy.item() * 100:.2f}%")

"""### Word2Vec + NB"""

import gensim
from sklearn.datasets import fetch_20newsgroups
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import classification_report
import numpy as np

# 加载数据集
data = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))
texts = data.data
labels = data.target

# 预处理和分词
def preprocess(text):
    return gensim.utils.simple_preprocess(text)

texts = [preprocess(text) for text in texts]

# 训练 Word2Vec 模型
model_w2v = gensim.models.Word2Vec(sentences=texts, vector_size=100, window=5, min_count=2, workers=4)

# 将文档转换为词向量的平均值
def document_vector(doc):
    # 移除不在词汇表中的词
    doc = [word for word in doc if word in model_w2v.wv.index_to_key]
    return np.mean(model_w2v.wv[doc], axis=0) if doc else np.zeros(model_w2v.vector_size)

vectors = np.array([document_vector(doc) for doc in texts])

# 划分训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(vectors, labels, test_size=0.25, random_state=42)

# 训练朴素贝叶斯分类器
classifier = GaussianNB()
classifier.fit(X_train, y_train)

# 预测和评估
y_pred = classifier.predict(X_test)
print(classification_report(y_test, y_pred))

"""### Word2Vec + LR"""

from sklearn.datasets import fetch_20newsgroups
from gensim.models import Word2Vec
from gensim.utils import simple_preprocess
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report
import numpy as np

# 加载数据集
data_train = fetch_20newsgroups(subset='train', categories=['sci.space', 'rec.autos'])
data_test = fetch_20newsgroups(subset='test', categories=['sci.space', 'rec.autos'])

# 文本预处理和分词
texts_train = [simple_preprocess(doc) for doc in data_train.data]
texts_test = [simple_preprocess(doc) for doc in data_test.data]

# 训练 Word2Vec 模型
model_w2v = Word2Vec(sentences=texts_train, vector_size=100, window=5, min_count=1, workers=4)

# 定义一个函数来获取文档的平均向量
def document_vector(doc):
    # 移除不在词汇表中的单词
    doc = [word for word in doc if word in model_w2v.wv]
    if len(doc) == 0:
        return np.zeros(model_w2v.vector_size)
    return np.mean(model_w2v.wv[doc], axis=0)

# 向量化训练和测试数据
X_train = np.array([document_vector(text) for text in texts_train])
X_test = np.array([document_vector(text) for text in texts_test])

# 训练 Logistic Regression 分类器
y_train = data_train.target
y_test = data_test.target

classifier = LogisticRegression(max_iter=1000)
classifier.fit(X_train, y_train)

# 预测和评估
predictions = classifier.predict(X_test)
print(classification_report(y_test, predictions, target_names=data_test.target_names))

"""### Word2Vec + MLP"""

from gensim.models import Word2Vec
from gensim.utils import simple_preprocess
from sklearn.datasets import fetch_20newsgroups
import numpy as np
import torch
from torch.utils.data import DataLoader, TensorDataset

# 加载数据集
data_train = fetch_20newsgroups(subset='train', categories=['sci.space', 'rec.autos'])
data_test = fetch_20newsgroups(subset='test', categories=['sci.space', 'rec.autos'])

# 文本预处理和分词
texts_train = [simple_preprocess(doc) for doc in data_train.data]
texts_test = [simple_preprocess(doc) for doc in data_test.data]

# 训练 Word2Vec 模型
model_w2v = Word2Vec(sentences=texts_train, vector_size=5000, window=5, min_count=1, workers=4)

# 定义函数来将文本转换为向量
def document_vector(model, doc):
    # 移除不在词汇表中的词
    doc = [word for word in doc if word in model.wv.key_to_index]
    return np.mean(model.wv[doc], axis=0) if len(doc) > 0 else np.zeros(model.vector_size)

# 向量化训练和测试数据
X_train = np.array([document_vector(model_w2v, doc) for doc in texts_train])
X_test = np.array([document_vector(model_w2v, doc) for doc in texts_test])

# 假设的目标变量 (这里用随机生成的数据作为示例)
y_train = np.random.rand(len(texts_train))
y_test = np.random.rand(len(texts_test))

# 转换数据为张量
X_train_tensor = torch.tensor(X_train, dtype=torch.float32)
X_test_tensor = torch.tensor(X_test, dtype=torch.float32)
y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)
y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)

# 数据加载器
train_data = TensorDataset(X_train_tensor, y_train_tensor)
train_loader = DataLoader(train_data, batch_size=4, shuffle=True)

def test_model(model, test_loader, criterion):
    model.eval()
    total_loss = 0
    with torch.no_grad():
        for inputs, labels in test_loader:
            outputs = model(inputs)
            loss = criterion(outputs.squeeze(), labels)
            total_loss += loss.item()
    return total_loss / len(test_loader)

# 创建测试数据的 DataLoader
test_data = TensorDataset(X_test_tensor, y_test_tensor)
test_loader = DataLoader(test_data, batch_size=4)

# 测试模型
test_loss = test_model(model_mlp, test_loader, criterion)
print(f"Test Loss: {test_loss:.4f}")

"""### Word2Vec + Average Bag of Words (ABoW) + NB"""

from gensim.models import Word2Vec
from gensim.utils import simple_preprocess
from sklearn.datasets import fetch_20newsgroups
from sklearn.naive_bayes import MultinomialNB
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import classification_report
import numpy as np

# 加载数据集
data_train = fetch_20newsgroups(subset='train', categories=['sci.space', 'rec.autos'])
data_test = fetch_20newsgroups(subset='test', categories=['sci.space', 'rec.autos'])

# 文本预处理和分词
texts_train = [simple_preprocess(doc) for doc in data_train.data]
texts_test = [simple_preprocess(doc) for doc in data_test.data]

# 训练 Word2Vec 模型
model_w2v = Word2Vec(sentences=texts_train, vector_size=100, window=5, min_count=1, workers=4)

# 定义函数，将文本转换为平均 Word2Vec 向量
def document_vector(doc):
    # 移除不在词汇表中的词
    doc = [word for word in doc if word in model_w2v.wv]
    if len(doc) == 0:
        return np.zeros(model_w2v.vector_size)
    # 计算文档的平均 Word2Vec 向量
    return np.mean(model_w2v.wv[doc], axis=0)

# 向量化训练和测试数据
X_train = np.array([document_vector(doc) for doc in texts_train])
X_test = np.array([document_vector(doc) for doc in texts_test])

# 将数据平移到非负范围
X_train_shifted = X_train - X_train.min()
X_test_shifted = X_test - X_test.min()

# 然后使用 MultinomialNB
clf = MultinomialNB()
clf.fit(X_train_shifted, data_train.target)

# 测试模型
y_pred = clf.predict(X_test)
print(classification_report(data_test.target, y_pred, target_names=data_test.target_names))

"""### Word2Vec + ABoW + LR"""

from gensim.models import Word2Vec
from gensim.utils import simple_preprocess
from sklearn.datasets import fetch_20newsgroups
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report
import numpy as np

# 文本预处理和分词
def preprocess_and_tokenize(data):
    return [simple_preprocess(doc) for doc in data]

# 加载数据集
data_train = fetch_20newsgroups(subset='train', categories=['sci.space', 'rec.autos'])
data_test = fetch_20newsgroups(subset='test', categories=['sci.space', 'rec.autos'])

texts_train = preprocess_and_tokenize(data_train.data)
texts_test = preprocess_and_tokenize(data_test.data)

# 使用 Word2Vec 训练词向量
model_w2v = Word2Vec(sentences=texts_train, vector_size=100, window=5, min_count=1, workers=4)

# 定义函数，将文本转换为基于 Word2Vec 的平均词向量
def get_average_word2vec(tokens_list, vector, generate_missing=False, k=100):
    if len(tokens_list) < 1:
        return np.zeros(k)
    if generate_missing:
        vectorized = [vector[word] if word in vector else np.random.rand(k) for word in tokens_list]
    else:
        vectorized = [vector[word] if word in vector else np.zeros(k) for word in tokens_list]
    length = len(vectorized)
    summed = np.sum(vectorized, axis=0)
    averaged = np.divide(summed, length)
    return averaged

def get_word2vec_embeddings(vectors, clean_comments, generate_missing=False):
    embeddings = clean_comments.apply(lambda x: get_average_word2vec(x, vectors, generate_missing=generate_missing))
    return list(embeddings)

# 获取训练和测试数据的嵌入
train_embeddings = get_word2vec_embeddings(model_w2v.wv, pd.Series(texts_train))
test_embeddings = get_word2vec_embeddings(model_w2v.wv, pd.Series(texts_test))

# 使用逻辑回归模型进行分类
model_lr = LogisticRegression(max_iter=1000)
model_lr.fit(train_embeddings, data_train.target)

# 预测和评估模型
predictions = model_lr.predict(test_embeddings)
print(classification_report(data_test.target, predictions))

"""### Word2Vec + ABoW + MLP"""

# 加载数据集
data_train = fetch_20newsgroups(subset='train', categories=['sci.space', 'rec.autos'])
data_test = fetch_20newsgroups(subset='test', categories=['sci.space', 'rec.autos'])

# 文本预处理和分词
texts_train = [simple_preprocess(doc) for doc in data_train.data]
texts_test = [simple_preprocess(doc) for doc in data_test.data]

# 训练 Word2Vec 模型
model_w2v = Word2Vec(sentences=texts_train, vector_size=5000, window=5, min_count=2, workers=4)

# 获取词向量
def get_vector(text):
    vectors = [model_w2v.wv[word] for word in text if word in model_w2v.wv]
    if len(vectors) == 0:
        return np.zeros(model_w2v.vector_size)
    else:
        return np.mean(vectors, axis=0)

# 将文本转换为向量
vectors_train = [get_vector(text) for text in texts_train]
vectors_test = [get_vector(text) for text in texts_test]

# 准备测试数据
X_test = torch.tensor(vectors_test, dtype=torch.float32)
y_test = torch.tensor(data_test.target, dtype=torch.long)

# 评估模型
model_mlp.eval()
with torch.no_grad():
    outputs = model_mlp(X_test)
    _, predicted = torch.max(outputs.data, 1)
    total = y_test.size(0)
    correct = (predicted == y_test).sum().item()
    print(f'Accuracy of the model_mlp on the test data: {100 * correct / total}%')

"""### RNNs

#### LSTM
"""

import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.datasets import fetch_20newsgroups
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from torch.utils.data import Dataset, DataLoader
import numpy as np

# 加载数据集
data = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))
texts = data.data
targets = [len(text.split()) for text in texts]  # 简单的回归目标：文本长度

# 划分训练集和测试集
texts_train, texts_test, targets_train, targets_test = train_test_split(texts, targets, test_size=0.2, random_state=42)

# 使用CountVectorizer来构建词汇表
vectorizer = CountVectorizer(max_features=10000).fit(texts_train)
vocab_size = len(vectorizer.vocabulary_)

def create_random_embeddings(vocab_size, embed_size):
    return torch.randn(vocab_size, embed_size)

embedding_dim = 100  # 指定嵌入维度
embeddings = create_random_embeddings(vocab_size + 1, embedding_dim)

class RNNRegressor(nn.Module):
    def __init__(self, vocab_size, embed_size, hidden_size, embedding_weights):
        super(RNNRegressor, self).__init__()
        self.embedding = nn.Embedding(vocab_size, embed_size)
        self.embedding.weight = nn.Parameter(embedding_weights, requires_grad=False)
        self.rnn = nn.LSTM(embed_size, hidden_size, batch_first=True)
        self.fc = nn.Linear(hidden_size, 1)

    def forward(self, x):
        x = self.embedding(x)
        x, _ = self.rnn(x)
        x = self.fc(x[:, -1, :])
        return x

model = RNNRegressor(vocab_size + 1, embedding_dim, 128, embeddings)

from torch.utils.data import TensorDataset, DataLoader

# 数据转换函数
def text_to_sequence(texts, word_index, max_len=500):
    sequences = np.zeros((len(texts), max_len))
    for i, text in enumerate(texts):
        words = text.split()
        for j, word in enumerate(words[:max_len]):
            if word in word_index:
                sequences[i, j] = word_index[word]
    return torch.tensor(sequences, dtype=torch.long)

# 训练数据准备
train_sequences = text_to_sequence(texts_train, vectorizer.vocabulary_)
train_targets = torch.tensor(targets_train, dtype=torch.float32)

# 将数据和目标封装到 TensorDataset
train_dataset = TensorDataset(train_sequences, train_targets)

# 使用 DataLoader 来迭代数据
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

# 模型训练
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

num_epochs = 5

for epoch in range(num_epochs):
    model.train()
    for inputs, targets in train_loader:
        inputs, targets = inputs.to(device), targets.to(device)

        optimizer.zero_grad()
        outputs = model(inputs).squeeze()
        loss = criterion(outputs, targets)
        loss.backward()
        optimizer.step()
    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')

# 测试数据准备
test_sequences = text_to_sequence(texts_test, vectorizer.vocabulary_)
test_targets = torch.tensor(targets_test, dtype=torch.float32)

# 测试 DataLoader
test_data = TensorDataset(test_sequences, test_targets)
test_loader = DataLoader(test_data, batch_size=32)

def evaluate_model(model, data_loader, criterion, device):
    model.eval()  # 设置模型为评估模式
    total_loss = 0
    with torch.no_grad():  # 不计算梯度
        for inputs, targets in data_loader:
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = model(inputs).squeeze()
            loss = criterion(outputs, targets)
            total_loss += loss.item()
    return total_loss / len(data_loader)

best_loss = float('inf')
best_model = None

for epoch in range(num_epochs):
    model.train()
    for inputs, targets in train_loader:
        inputs, targets = inputs.to(device), targets.to(device)
        optimizer.zero_grad()
        outputs = model(inputs).squeeze()
        loss = criterion(outputs, targets)
        loss.backward()
        optimizer.step()

    val_loss = evaluate_model(model, test_loader, criterion, device)
    print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {loss.item()}, Validation Loss: {val_loss}')

    # 检查是否是最佳模型
    if val_loss < best_loss:
        best_loss = val_loss
        best_model = model.state_dict()

# 示例：尝试不同的学习率
learning_rates = [0.001, 0.0005, 0.0001]
best_lr = learning_rates[0]

for lr in learning_rates:
    model = RNNRegressor(vocab_size + 1, embedding_dim, 128, embeddings).to(device)
    optimizer = optim.Adam(model.parameters(), lr=lr)
    # ... 重复训练和评估过程 ...

    # 如果新的学习率表现更好，则更新最佳学习率
    if val_loss < best_loss:
        best_loss = val_loss
        best_lr = lr
        best_model = model.state_dict()

print(f'Best Learning Rate: {best_lr}')

"""#### Single-Layer"""

import torch
import torch.nn as nn

class SingleLayerRNN(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(SingleLayerRNN, self).__init__()
        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        out, _ = self.rnn(x)
        out = self.fc(out[:, -1, :])
        return out

# 实例化模型
# 假设输入大小为10，隐藏层大小为20，输出大小为2（二分类问题）
single_layer_model = SingleLayerRNN(10, 20, 2)

def train_epoch(self):
        self.model.train()
        for x, y in self.train_loader:
            x, y = x.to(self.device), y.to(self.device).squeeze()  # 确保y是一维的
            self.optimizer.zero_grad()
            outputs = self.model(x)
            loss = self.criterion(outputs, y)
            loss.backward()
            self.optimizer.step()

    def validate(self):
        self.model.eval()
        total_loss = 0
        with torch.no_grad():
            for x, y in self.val_loader:
                x, y = x.to(self.device), y.to(self.device).squeeze()  # 确保y是一维的
                outputs = self.model(x)
                loss = self.criterion(outputs, y)
                total_loss += loss.item()
        return total_loss / len(self.val_loader)

class ModelTrainer:
    def __init__(self, model, train_loader, val_loader, test_loader, criterion, optimizer, device):
        self.model = model
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.test_loader = test_loader
        self.criterion = criterion
        self.optimizer = optimizer
        self.device = device

    def train_epoch(self):
        self.model.train()
        for x, y in self.train_loader:
            x, y = x.to(self.device), y.to(self.device)
            self.optimizer.zero_grad()
            outputs = self.model(x)
            loss = self.criterion(outputs, y)
            loss.backward()
            self.optimizer.step()

    def validate(self):
        self.model.eval()
        total_loss = 0
        with torch.no_grad():
            for x, y in self.val_loader:
                x, y = x.to(self.device), y.to(self.device)
                outputs = self.model(x)
                loss = self.criterion(outputs, y)
                total_loss += loss.item()
        return total_loss / len(self.val_loader)

    def test(self):
        self.model.eval()
        total_loss = 0
        with torch.no_grad():
            for x, y in self.test_loader:
                x, y = x.to(self.device), y.to(self.device)
                outputs = self.model(x)
                loss = self.criterion(outputs, y)
                total_loss += loss.item()
        return total_loss / len(self.test_loader)

    def train(self, num_epochs):
        for epoch in range(num_epochs):
            self.train_epoch()
            val_loss = self.validate()
            print(f"Epoch {epoch}, Validation Loss: {val_loss}")
        test_loss = self.test()
        print(f"Test Loss: {test_loss}")

"""#### Double-Layer"""

class DoubleLayerRNN(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(DoubleLayerRNN, self).__init__()
        self.rnn = nn.RNN(input_size, hidden_size, num_layers=2, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        out, _ = self.rnn(x)
        out = self.fc(out[:, -1, :])
        return out

model = DoubleLayerRNN(10, 20, 2)

# 或者，以双层RNN为例
trainer = ModelTrainer(double_layer_model, train_loader, val_loader, test_loader, criterion, optimizer, device)
trainer.train(num_epochs)

"""#### Multi-Layer"""

import torch
import torch.nn as nn

class MultiLayerRNN(nn.Module):
    def __init__(self, input_size, hidden_size, output_size, num_layers):
        super(MultiLayerRNN, self).__init__()
        self.rnn = nn.RNN(input_size, hidden_size, num_layers=num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        out, _ = self.rnn(x)
        out = self.fc(out[:, -1, :])
        return out

class ModelTrainer:
    def __init__(self, model, train_loader, val_loader, test_loader, criterion, optimizer, device):
        self.model = model
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.test_loader = test_loader
        self.criterion = criterion
        self.optimizer = optimizer
        self.device = device

    def train_epoch(self):
        self.model.train()
        for x, y in self.train_loader:
            x, y = x.to(self.device), y.to(self.device)
            self.optimizer.zero_grad()
            outputs = self.model(x)
            loss = self.criterion(outputs, y)
            loss.backward()
            self.optimizer.step()

    def validate(self):
        self.model.eval()
        total_loss = 0
        with torch.no_grad():
            for x, y in self.val_loader:
                x, y = x.to(self.device), y.to(self.device)
                outputs = self.model(x)
                loss = self.criterion(outputs, y)
                total_loss += loss.item()
        return total_loss / len(self.val_loader)

    def test(self):
        self.model.eval()
        total_loss = 0
        with torch.no_grad():
            for x, y in self.test_loader:
                x, y = x.to(self.device), y.to(self.device)
                outputs = self.model(x)
                loss = self.criterion(outputs, y)
                total_loss += loss.item()
        return total_loss / len(self.test_loader)

    def train(self, num_epochs):
        for epoch in range(num_epochs):
            self.train_epoch()
            val_loss = self.validate()
            print(f"Epoch {epoch}, Validation Loss: {val_loss}")
        test_loss = self.test()
        print(f"Test Loss: {test_loss}")

# 假设的输入参数
input_size = 10
hidden_size = 20
output_size = 2
num_layers = 3
num_epochs = 5

# 创建模型、损失函数、优化器
model = MultiLayerRNN(input_size, hidden_size, output_size, num_layers).to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# 假设的数据加载器（需要替换为真实的DataLoader）
train_loader, val_loader, test_loader = None, None, None

# 训练模型
trainer = ModelTrainer(model, train_loader, val_loader, test_loader, criterion, optimizer, device)
trainer.train(num_epochs)

"""#### LSTM"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.preprocessing import LabelEncoder
from tqdm import tqdm
import numpy as np

# 假设我们有一个CSV文件，包含两列：评论文本和情感标签（正面/负面）
class IMDBDataset(Dataset):
    def __init__(self, reviews, labels):
        self.reviews = reviews
        self.labels = labels

    def __len__(self):
        return len(self.reviews)

    def __getitem__(self, idx):
        return torch.tensor(self.reviews[idx], dtype=torch.float32), torch.tensor(self.labels[idx], dtype=torch.long)

# 加载数据
df = pd.read_csv('/content/drive/MyDrive/IMDB Dataset.csv')
reviews = df['review']
labels = LabelEncoder().fit_transform(df['sentiment'])

# 将文本转换为固定长度的数字向量
vectorizer = CountVectorizer(max_features=5000)  # 选择最常见的5000个词
reviews = vectorizer.fit_transform(reviews).toarray()
reviews = np.array(reviews)

# 划分训练集和测试集
train_reviews, test_reviews, train_labels, test_labels = train_test_split(reviews, labels, test_size=0.2, random_state=42)

train_dataset = IMDBDataset(train_reviews, train_labels)
test_dataset = IMDBDataset(test_reviews, test_labels)

train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)

class LSTMClassifier(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):
        super(LSTMClassifier, self).__init__()
        self.hidden_dim = hidden_dim
        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_dim, output_dim)

    def forward(self, x):
        x = x.unsqueeze(1)  # 添加一个序列长度的维度
        lstm_out, _ = self.lstm(x)
        out = self.fc(lstm_out[:, -1, :])  # 只取最后一个时间步的输出
        return out

# 模型实例化
model = LSTMClassifier(input_dim=5000, hidden_dim=128, output_dim=2, num_layers=1)
optimizer = optim.Adam(model.parameters(), lr=0.001)
criterion = nn.CrossEntropyLoss()

# 训练循环
for epoch in range(5):  # 运行5个epoch
    for texts, labels in tqdm(train_loader):
        optimizer.zero_grad()
        outputs = model(texts.float())
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

# 评估模型性能
correct = 0
total = 0
with torch.no_grad():
    for texts, labels in tqdm(test_loader):
        outputs = model(texts.float())
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print('Accuracy: %d %%' % (100 * correct / total))

"""### BERT"""

class SentimentDataset(Dataset):
    def __init__(self, tokenizer, max_length=50, num_classes=3, subset='train'):
        data = fetch_20newsgroups(subset=subset, categories=['sci.space', 'rec.autos'])
        self.texts = data.data
        self.labels = torch.tensor(data.target)
        self.tokenizer = tokenizer
        self.max_length = max_length

    def __len__(self):
        return len(self.texts)

    def __getitem__(self, idx):
        text = self.texts[idx]
        # 使用BERT分词器处理文本
        encoded = self.tokenizer.encode_plus(
            text,
            max_length=self.max_length,
            padding='max_length',
            truncation=True,
            return_tensors='pt'
        )
        input_ids = encoded['input_ids'].squeeze(0)
        attention_mask = encoded['attention_mask'].squeeze(0)
        return input_ids, attention_mask, self.labels[idx]

# 初始化BERT分词器
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

# 实例化数据集和数据加载器
train_dataset = SentimentDataset(tokenizer=tokenizer, subset='train')
test_dataset = SentimentDataset(tokenizer=tokenizer, subset='test')

train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=4, shuffle=True)

from transformers import BertModel
import torch.nn as nn

class SentimentModel(nn.Module):
    def __init__(self, bert_model_name='bert-base-uncased', num_classes=3):
        super(SentimentModel, self).__init__()
        self.bert = BertModel.from_pretrained(bert_model_name)
        self.fc = nn.Linear(self.bert.config.hidden_size, num_classes)

    def forward(self, text, attention_mask):
        text_output = self.bert(text, attention_mask=attention_mask)[1]  # 取BERT的[CLS] token输出
        output = self.fc(text_output)
        return output

# 将模型加载到设备上
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = SentimentModel().to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# 训练循环
num_epochs = 5
for epoch in range(num_epochs):
    for input_ids, attention_mask, labels in train_loader:
        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(input_ids, attention_mask)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}")

import concurrent.futures
import torch
import torch.nn as nn
import torch.optim as optim
from transformers import BertModel, BertTokenizer
from torch.utils.data import DataLoader, TensorDataset

# 假设您已经定义了MLP和BERT模型类，以及相应的数据加载器
# model_mlp = ...
# model_bert = ...
# data_loader_mlp = ...
# data_loader_bert = ...

def train_mlp(model, data_loader):
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    for epoch in range(5):  # 5个epoch作为示例
        for inputs, labels in data_loader:
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            print(f"MLP Epoch [{epoch+1}/5], Loss: {loss.item():.4f}")

def train_bert(model, data_loader):
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    for epoch in range(3):  # 3个epoch作为示例
        for inputs, attention_masks, labels in data_loader:
            optimizer.zero_grad()
            outputs = model(inputs, attention_mask=attention_masks)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            print(f"BERT Epoch [{epoch+1}/3], Loss: {loss.item():.4f}")

# 使用ProcessPoolExecutor并行运行两个训练过程
with concurrent.futures.ProcessPoolExecutor() as executor:
    executor.submit(train_mlp, model_mlp, data_loader_mlp)
    executor.submit(train_bert, model_bert, data_loader_bert)

import torch
import torch.optim as optim
from torch.utils.data import DataLoader

# 将模型加载到设备上
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = SentimentModel().to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# 训练循环
num_epochs = 5
for epoch in range(num_epochs):
    for input_ids, attention_mask, labels in train_loader:
        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(input_ids, attention_mask)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}")

"""### LLAMA"""

import requests
import json

def call_llama_api(text, params=None):
    # URL of the LLaMA API
    api_url = "http://example.com/llama"  # 请替换成实际的API URL

    # 准备请求数据
    data = {
        "text": text,
        "params": params if params else {}  # Add additional parameters if required
    }

    # 发送请求
    response = requests.post(api_url, json=data)

    # 检查响应
    if response.status_code == 200:
        return response.json()  # 返回模型的响应
    else:
        print("Error:", response.status_code, response.text)
        return None

# 使用LLaMA模型
text = "Your input text here"
params = {"param1": "value1", "param2": "value2"}  # 示例参数，根据API实际情况进行调整
response = call_llama_api(text, params)

# 处理模型响应
if response:
    print("Model Response:", response)

"""### XLNet"""

import torch
from torch import nn
from transformers import XLNetModel, XLNetTokenizer

class XLNetSentimentModel(nn.Module):
    def __init__(self, n_classes=2):
        super(XLNetSentimentModel, self).__init__()
        self.xlnet = XLNetModel.from_pretrained('xlnet-base-cased')
        self.fc = nn.Linear(self.xlnet.config.hidden_size, n_classes)

    def forward(self, input_ids, attention_mask):
        output = self.xlnet(input_ids=input_ids, attention_mask=attention_mask)
        last_hidden_state = output.last_hidden_state
        out = self.fc(last_hidden_state[:, -1, :])
        return out

# 创建模型实例
model = XLNetSentimentModel()

# 检查是否有可用的 GPU，如果有，则将模型移动到 GPU
if torch.cuda.is_available():
    model = model.to('cuda')

# 示例：模型输入
tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')
text = "This is a great product!"
inputs = tokenizer(text, return_tensors="pt")
input_ids = inputs["input_ids"].to(model.device)
attention_mask = inputs["attention_mask"].to(model.device)

# 前向传递
with torch.no_grad():
    outputs = model(input_ids=input_ids, attention_mask=attention_mask)
    print(outputs)

from transformers import XLNetModel, XLNetTokenizer

class XLNetSentimentModel(nn.Module):
    def __init__(self):
        super(XLNetSentimentModel, self).__init__()
        self.xlnet = XLNetModel.from_pretrained('xlnet-base-cased')
        self.fc = nn.Linear(self.xlnet.config.hidden_size, 2)

    def forward(self, input_ids, attention_mask):
        output = self.xlnet(input_ids=input_ids, attention_mask=attention_mask)
        last_hidden_state = output.last_hidden_state
        out = self.fc(last_hidden_state[:, -1, :])
        return out

xlnet_model = XLNetSentimentModel()

"""### Emoji"""

!pip install emoji
import emoji

# 示例日记文本
diary_entries = [
    "8.1 棋总是慢一手 🫡",
    "7.29 かけがえのないの星 还会再回来的吧",
    "7.28 想请教一下有同学知道在美国上课的笔记除了用ebay还可以怎么转让吗？谢谢",
    "7.24 有点想自出一套jk",
    "7.16 收到了两本书中第一本改稿意见, 文字读来也是如沐春风。"
]

def replace_emojis(text):
    return emoji.demojize(text, language='alias')

# 模拟手动打标
sentiment_labels = ["中性", "正面", "中性", "中性", "正面"]

# 测试处理效果
for entry, label in zip(diary_entries, sentiment_labels):
    processed_entry = replace_emojis(entry)
    print(f"原文: {entry}")
    print(f"处理后: {processed_entry}")
    print(f"情感标签: {label}\n")

!pip install pdfplumber
import pdfplumber

def extractText(pdf_path):
    with pdfplumber.open(pdf_path) as pdf:
        all_text = ""
        for page in pdf.pages:
            text = page.extract_text()
            all_text += text
    return all_text

def extract_emojies(s):
   emoji_list = []
   for c in s:
       if c in emoji.EMOJI_DATA:
           emoji_list.append(c)
   return list(dict.fromkeys(emoji_list))

def get_en_senti(s_text):
   score = TextBlob(s_text).sentiment[0]
   if score > 0:
       return 1
   else:
       return 0

all_text = extractText('TheGreatGatsby')

"""### BERT-CHINESE"""



"""### TextBlob (Sentimental Analysis)"""



"""### Jieba"""



"""### HanLP"""



"""### SnowNLP"""

import spacy

# 加载英语模型
nlp = spacy.load("en_core_web_sm")

# 要处理的文本
text = "Apple is looking at buying U.K. startup for $1 billion"

# 处理文本
doc = nlp(text)

# 输出词性标注
for token in doc:
    print(token.text, token.pos_)



import nltk
from nltk.tokenize import word_tokenize

# 下载所需的数据和标注器模型
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')

# 要处理的文本
text = "Apple is looking at buying U.K. startup for $1 billion"

# 分词
tokens = word_tokenize(text)

# 输出词性标注
print(nltk.pos_tag(tokens))



from textblob import TextBlob

phrases = ["不，不是的", "是，是这样"]

for phrase in phrases:
    blob = TextBlob(phrase)
    sentiment = blob.sentiment
    print(f"Phrase: '{phrase}'")
    print(f"   Polarity: {sentiment.polarity}")
    print(f"   Subjectivity: {sentiment.subjectivity}\n")



import nltk
from nltk.tokenize import word_tokenize
from nltk.tag import pos_tag
from nltk.chunk import ne_chunk

# 下载所需的数据和模型
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')
nltk.download('maxent_ne_chunker')
nltk.download('words')

# 要处理的文本
text = "Apple is looking at buying U.K. startup for $1 billion"

# 分词和词性标注
tokens = word_tokenize(text)
tags = pos_tag(tokens)

# 命名实体识别
entities = ne_chunk(tags)
print(entities)



!pip install snownlp
from snownlp import SnowNLP

phrases = ["不，不是的", "是，是这样"]

for phrase in phrases:
    s = SnowNLP(phrase)
    sentiment = s.sentiments
    print(f"Phrase: '{phrase}'")
    print(f"   Sentiment: {sentiment}\n")

"""### ERNIE"""

import paddle
from paddle.io import Dataset, DataLoader
from paddlenlp.transformers import ErnieTokenizer, ErnieForSequenceClassification
import numpy as np

# 你的训练数据
train_texts = ["这是一个很好的产品。", "这是一个糟糕的产品。"]
train_labels = [1, 0]  # 假设1代表正面评价，0代表负面评价

# 初始化ERNIE的tokenizer
tokenizer = ErnieTokenizer.from_pretrained('ernie-1.0')

# 数据预处理
train_encodings = tokenizer(train_texts, padding=True, truncation=True, max_length=128, return_tensors="np")

# 定义自定义数据集
class CustomDataset(Dataset):
    def __init__(self, encodings, labels):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: paddle.to_tensor(val[idx]) for key, val in self.encodings.items()}
        item['labels'] = paddle.to_tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.labels)

# 创建数据集
train_dataset = CustomDataset(train_encodings, train_labels)

# 使用PaddlePaddle进行训练
def train(model, optimizer, train_loader, criterion):
    model.train()
    for batch in train_loader:
        input_ids = batch['input_ids']
        labels = batch['labels']
        logits = model(input_ids)
        loss = criterion(logits, labels)
        loss.backward()
        optimizer.step()
        optimizer.clear_grad()
    return loss

# 加载ERNIE模型
model = ErnieForSequenceClassification.from_pretrained('ernie-1.0', num_classes=2)
optimizer = paddle.optimizer.Adam(parameters=model.parameters(), learning_rate=5e-5)
criterion = paddle.nn.loss.CrossEntropyLoss()

# 创建数据加载器
train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)

# 训练模型
for epoch in range(3):  # 这里仅演示3个epoch
    loss = train(model, optimizer, train_loader, criterion)
    print(f"Epoch {epoch}, Loss: {loss.numpy().item()}")

# 准备测试文本
test_texts = [
    "这个产品非常好。",
    "这个产品不好。",
    "我对这个产品非常满意。",
    "这次购物体验很差。",
    "我喜欢这个。",
    "这真的很糟糕。",
    "非常推荐这个产品。",
    "我不推荐这个产品。"
]

# 使用Tokenizer处理文本
test_encodings = tokenizer(test_texts, max_seq_len=128, pad_to_max_seq_len=True, return_tensors="np")

# 转换为Paddle tensor
input_ids = paddle.to_tensor(test_encodings['input_ids'])
segment_ids = paddle.to_tensor(test_encodings['token_type_ids'])

# 预测
model.eval()  # 设置为评估模式
with paddle.no_grad():
    logits = model(input_ids, segment_ids)
    predictions = paddle.nn.functional.softmax(logits)

# 获取预测类别
pred_labels = paddle.argmax(predictions, axis=1).numpy()

# 输出预测结果
for text, label in zip(test_texts, pred_labels):
    print(f"Text: {text}, Predicted label: {label}")



!pip install paddlepaddle
!pip install paddlenlp

from paddlenlp.transformers import ErnieForSequenceClassification, ErnieTokenizer
import paddle

# 初始化ERNIE模型和分词器
model = ErnieForSequenceClassification.from_pretrained('ernie-1.0', num_classes=2)
tokenizer = ErnieTokenizer.from_pretrained('ernie-1.0')

# 数据准备
texts = ["这是一个很棒的产品", "这个产品不好用"]
labels = [1, 0]  # 1代表正面情感，0代表负面情感

# 数据预处理
inputs = tokenizer(texts, max_seq_len=128, pad_to_max_seq_len=True, return_attention_mask=True)
input_ids = paddle.to_tensor(inputs['input_ids'])
segment_ids = paddle.to_tensor(inputs['token_type_ids'])
attention_mask = paddle.to_tensor(inputs['attention_mask'])

# 模型预测
paddle.set_device('cpu')  # 如果使用gpu，改为'gpu'
model.eval()
with paddle.no_grad():
    logits = model(input_ids, segment_ids)
    probs = paddle.nn.functional.softmax(logits, axis=-1)
    predictions = paddle.argmax(probs, axis=1).numpy()

# 输出预测结果
for idx, text in enumerate(texts):
    print(f"Text: {text} - Sentiment: {'Positive' if predictions[idx] == 1 else 'Negative'}")

"""### Viterbi's Algorithm"""

"""
词性标注（Part-of-Speech Tagging）：
在词性标注任务中，Viterbi算法可以用来找出给定词序列的最可能的词性序列。
这通常在基于隐马尔可夫模型的词性标注系统中实现。
命名实体识别（Named Entity Recognition, NER）：
在一些NER系统中，特别是那些使用隐马尔可夫模型或条件随机场（Conditional Random Fields, CRFs）的系统中，
Viterbi算法用于推断最可能的实体标签序列。
"""

import random
import numpy as np

# Sigmoid 函数
def sigmoid(x):
    return 1 / (1 + np.exp(-x))

# 生成模拟的时序数据（例如股票价格）
def generate_time_series_data(num_points):
    return np.random.rand(num_points) * 100

# 数据归一化
def normalize_data(data):
    return (data - np.min(data)) / (np.max(data) - np.min(data))

# 初始化算法
def viterbi(obs, states, start_p, trans_p, emit_p):
    V = [{}]
    path = {}

    # 初始化基本情况 (t == 0)
    for y in states:
        V[0][y] = start_p[y] * emit_p[y][obs[0]]
        path[y] = [y]

    # 对 t > 0 的时刻运行 Viterbi
    for t in range(1, len(obs)):
        V.append({})
        newpath = {}

        for y in states:
            # 检查每个状态，并选择其中一个状态作为前一个状态
            (prob, state) = max((V[t-1][y0] * trans_p[y0][y] * emit_p[y][obs[t]], y0) for y0 in states)
            V[t][y] = prob
            newpath[y] = path[state] + [y]

        path = newpath

    # 返回最可能的序列
    n = 0           # 如果仅有一个观察值，只需要返回初始状态
    if len(obs) != 1:
        n = t
    (prob, state) = max((V[n][y], y) for y in states)
    return path[state]

# 维特比算法（简化版本）
def viterbi(obs, states, start_p, trans_p, emit_p):
    # ... 维特比算法的实现 ...
    return hidden_states

# 示例用法
time_series_data = generate_time_series_data(100)  # 生成数据
normalized_data = normalize_data(time_series_data)  # 归一化数据

# 假设的 HMM 参数
states = ['Up', 'Down']
start_probability = {'Up': 0.5, 'Down': 0.5}
transition_probability = {'Up': {'Up': 0.7, 'Down': 0.3}, 'Down': {'Up': 0.3, 'Down': 0.7}}
emission_probability = {'Up': {'rise': 0.6, 'fall': 0.4}, 'Down': {'rise': 0.4, 'fall': 0.6}}

# 应用维特比算法
hidden_states = viterbi(normalized_data, states, start_probability, transition_probability, emission_probability)

print(hidden_states)

def map_time_series_to_observations(time_series_data):
    observations = []
    for i in range(1, len(time_series_data)):
        change = (time_series_data[i] - time_series_data[i-1]) / time_series_data[i-1]
        if change > 0.01:  # 假设变化超过1%为上升
            observations.append("up")
        elif change < -0.01:  # 假设变化低于-1%为下降
            observations.append("down")
        else:
            observations.append("stable")
    return observations

states = ("bull", "bear", "neutral")  # 假设的市场状态：牛市、熊市、中性市场
start_probability = {"bull": 0.3, "bear": 0.3, "neutral": 0.4}
transition_probability = {
    "bull": {"bull": 0.7, "bear": 0.1, "neutral": 0.2},
    "bear": {"bull": 0.1, "bear": 0.7, "neutral": 0.2},
    "neutral": {"bull": 0.3, "bear": 0.3, "neutral": 0.4}
}
emission_probability = {
    "bull": {"up": 0.6, "down": 0.1, "stable": 0.3},
    "bear": {"up": 0.1, "down": 0.6, "stable": 0.3},
    "neutral": {"up": 0.3, "down": 0.3, "stable": 0.4}
}

def viterbi(obs, states, start_p, trans_p, emit_p):
    V = [{}]
    for st in states:
        V[0][st] = {"prob": start_p[st] * emit_p[st][obs[0]], "prev": None}
    for t in range(1, len(obs)):
        V.append({})
        for st in states:
            max_tr_prob = max(V[t-1][prev_st]["prob"]*trans_p[prev_st][st] for prev_st in states)
            for prev_st in states:
                if V[t-1][prev_st]["prob"] * trans_p[prev_st][st] == max_tr_prob:
                    max_prob = max_tr_prob * emit_p[st][obs[t]]
                    V[t][st] = {"prob": max_prob, "prev": prev_st}
                    break
    opt = []
    max_prob = max(value["prob"] for value in V[-1].values())
    previous = None
    for st, data in V[-1].items():
        if data["prob"] == max_prob:
            opt.append(st)
            previous = st
            break
    for t in range(len(V) - 2, -1, -1):
        opt.insert(0, V[t + 1][previous]["prev"])
        previous = V[t + 1][previous]["prev"]
    return opt

states = ('Rainy', 'Sunny')
observations = ('walk', 'shop', 'clean')
start_probability = {'Rainy': 0.6, 'Sunny': 0.4}
transition_probability = {
   'Rainy' : {'Rainy': 0.7, 'Sunny': 0.3},
   'Sunny' : {'Rainy': 0.4, 'Sunny': 0.6},
   }
emission_probability = {
   'Rainy' : {'walk': 0.1, 'shop': 0.4, 'clean': 0.5},
   'Sunny' : {'walk': 0.6, 'shop': 0.3, 'clean': 0.1},
   }

result = viterbi(observations, states, start_probability, transition_probability, emission_probability)
print(result)

# 假设 time_series_data 是包含股票价格的列表
time_series_data = [
    100, 102, 101, 103, 105, 107, 106, 108, 107, 110, 111, 110, 109, 108, 107, 106,
    107, 108, 109, 110, 111, 113, 115, 116, 117, 118, 119, 120, 121, 119, 118, 117,
    115, 114, 113, 114, 115, 116, 117, 119, 120, 121, 123, 125, 127, 126, 125, 124,
    123, 122, 121, 120, 119, 118, 117, 116, 115, 114, 113, 112, 111, 110, 109, 108,
    107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 97, 96, 95, 94, 93, 92,
    91, 90, 89, 88, 87, 86, 85, 84, 83, 82, 81, 80, 79, 78, 77, 76
]
hidden_states = process_time_series_data(time_series_data, states, start_probability, transition_probability, emission_probability)
print(hidden_states)

"""### To-Graph"""

import tensorflow_hub as hub
import numpy as np
import networkx as nx
import matplotlib.pyplot as plt

# 加载Universal Sentence Encoder模型
model = hub.load("https://tfhub.dev/google/universal-sentence-encoder/4")

# 使用模型生成文本的嵌入向量
embeddings = model(texts)

# 计算所有文本对之间的相似度
similarity_matrix = np.inner(embeddings, embeddings)

# 创建一个无向图
G = nx.Graph()

# 添加节点
for text in texts:
    G.add_node(text)

# 根据相似度添加边，这里我们设置阈值为0.6，即相似度高于0.6的文本之间添加边
for i in range(len(texts)):
    for j in range(i + 1, len(texts)):
        if similarity_matrix[i][j] > 0.6:
            G.add_edge(texts[i], texts[j], weight=similarity_matrix[i][j])

# 绘制图形
plt.figure(figsize=(10, 10))
pos = nx.spring_layout(G, seed=7)  # 节点布局
nx.draw(G, pos, with_labels=True, font_weight='bold', node_color='skyblue', edge_color='gray')
edge_labels = nx.get_edge_attributes(G, 'weight')
nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)
plt.title("Text Similarity Graph", size=15)
plt.show()

import networkx as nx
import matplotlib.pyplot as plt

# 创建一个空的无向图
G = nx.Graph()

# 假设我们有一组情绪特征和它们之间的相关性分数
features = ['Happiness', 'Sadness', 'Anger', 'Fear', 'Surprise']
correlations = [('Happiness', 'Sadness', -0.5), ('Anger', 'Fear', 0.4), ('Surprise', 'Happiness', 0.3)]

# 添加节点
for feature in features:
    G.add_node(feature)

# 添加边，基于相关性分数
for src, dst, weight in correlations:
    G.add_edge(src, dst, weight=weight)

# 绘制图
pos = nx.spring_layout(G)  # 为图布局
nx.draw(G, pos, with_labels=True, node_color='lightblue', edge_color='gray')
edge_labels = nx.get_edge_attributes(G, 'weight')
nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)
plt.show()

import networkx as nx
from numpy import dot
from numpy.linalg import norm
import numpy as np
import matplotlib.pyplot as plt

# 假设features_dict已经是数值型特征向量
features_dict = {
    "image1": np.array([1, 0]),  # 假设的数值型特征向量，比如one-hot编码
    "image2": np.array([0, 1]),
    # 更多图像及其数值型特征向量
}

G = nx.Graph()

def calculate_similarity(feature_vec1, feature_vec2):
    """
    计算两个特征向量之间的余弦相似度。
    """
    if norm(feature_vec1) * norm(feature_vec2) == 0:
        return 0  # 避免除以零
    cosine_similarity = dot(feature_vec1, feature_vec2) / (norm(feature_vec1) * norm(feature_vec2))
    return cosine_similarity

# 添加节点
for image_id, features in features_dict.items():
    G.add_node(image_id, feature=features)

threshold = 0.5  # 定义相似度阈值

# 添加边
for id1, feature_vec1 in features_dict.items():
    for id2, feature_vec2 in features_dict.items():
        if id1 != id2:
            similarity = calculate_similarity(feature_vec1, feature_vec2)
            if similarity > threshold:
                G.add_edge(id1, id2, weight=similarity)

# 注意：实际中，特征向量的转换和相似度计算方式需要根据具体的特征和任务来确定。

# 计算节点的位置，这里使用spring_layout算法来自动布局
pos = nx.spring_layout(G)

# 绘制网络图
plt.figure(figsize=(8, 6))  # 设置图形的大小

# 绘制节点
nx.draw_networkx_nodes(G, pos, node_size=700, node_color='skyblue', alpha=0.6)

# 绘制边，边的宽度根据权重来调整
edges = G.edges(data=True)
weights = [edge[2]['weight'] * 10 for edge in edges]  # 调整边的权重，以便在图中更清楚地显示
nx.draw_networkx_edges(G, pos, width=weights, edge_color='gray', alpha=0.5)

# 绘制节点的标签
nx.draw_networkx_labels(G, pos, font_size=12)

plt.title('Graph Visualization')
plt.axis('off')  # 不显示坐标轴
plt.show()

"""### To-Time"""

import re
import nltk
import pandas as pd
!pip install snownlp
from snownlp import SnowNLP
from textblob import TextBlob
from datetime import datetime

# 假设diary_text是您的日记文本
diary_text = """
2.14
找到了针对某些exe去挖掘价值的东西
是十年前的光吧, 老高干过的
亏贼

2.13
充电宝弹出来的一瞬间, 非常的好
死亡循环 随心随缘
请问谁可以做到, 在没有任何新信息进来的情况下, 对一个人或者一件事的判断能够瞬间转向？
也许是我的用词太城市化了。应该不会没有新的信息, 但如此小样本的学习就能让而分类结果直接反向, 应该是用了某种relu
准备眠一会儿, 但不是长眠。

2.12
是吧
是的
严格来说
每个转发文章标题也是要的
就是这文字能反映状态 不然也没必要存在了的

2.11
果然

2.10
天元
怎么这么懂呢
倒在你面前了 满意了吧
说吧 说的越多 你的本质就只会愈加的暴露
「この伝説の終わりは、急速に来る。」
"""

# 分割日记文本为条目，提取日期
entries = re.split(r'\n\d{1,2}\.\d{1,2}\n', diary_text)
dates = re.findall(r'\n(\d{1,2}\.\d{1,2})\n', diary_text)
formatted_dates = [datetime.strptime('2024.' + date, '%Y.%m.%d').date() for date in dates]

# 去除多余标点符号的函数
def remove_punctuation(text):
    return re.sub(r'[^\w\s]', '', text)

# 情感分析函数
def analyze_sentiment(text):
    if re.search(r'[\u4e00-\u9fff]', text):
        return SnowNLP(text).sentiments
    else:
        return TextBlob(text).sentiment.polarity

# 应用数据清洗和情感分析
cleaned_entries = [remove_punctuation(entry) for entry in entries[1:]]
sentiments = [analyze_sentiment(entry) for entry in cleaned_entries]

# 创建DataFrame
diary_df = pd.DataFrame({
    'Content': cleaned_entries,
    'Sentiment': sentiments
}, index=pd.to_datetime(formatted_dates))

# 查看DataFrame
print(diary_df)

"""## Image (Computer Vision)"""

import os
import cv2
import pandas as pd
from google.colab import drive

# 假设您的图片存储在"photos"目录下，并且每张图片的文件名包含了拍摄时间
photos_path = "path_to_your_photos_directory"

# 创建一个空的DataFrame来存储时序数据和图像路径
df = pd.DataFrame(columns=["timestamp", "image_path"])

# 遍历图片目录，读取图片文件名和路径
for filename in os.listdir(photos_path):
    if filename.endswith(".jpg"):  # 假设所有图片都是jpg格式
        # 从文件名解析时间戳，这里假设文件名格式包含日期时间信息
        timestamp = pd.to_datetime(filename.split('.')[0], format="%Y%m%d%H%M%S")
        image_path = os.path.join(photos_path, filename)

        # 将时间戳和图像路径添加到DataFrame
        df = df.append({"timestamp": timestamp, "image_path": image_path}, ignore_index=True)

# 根据时间戳对数据进行排序，确保时序对齐
df.sort_values(by="timestamp", inplace=True)

# 现在，df包含了按时间排序的图像路径
print(df)

# 你可以根据需要对df进行进一步的处理或分析
# 例如，使用OpenCV读取并显示第一张图片
first_image_path = df.iloc[0]["image_path"]
image = cv2.imread(first_image_path)
cv2.imshow("First Image", image)
cv2.waitKey(0)
cv2.destroyAllWindows()

"""### Pre-processing (*A Non-Linear Classifier)"""



"""### Pre-processing (Simulation)"""

import sympy as sp

# 定义变量和函数
x = sp.Symbol('x')
f = sp.exp(x)
g = x**2

# 计算函数的导数
f_prime = f.diff(x)
g_prime = g.diff(x)

# 构造 Wronskian 矩阵
wronskian_matrix = sp.Matrix([[f, g], [f_prime, g_prime]])

# 计算矩阵的行列式
wronskian_determinant = wronskian_matrix.det()

# 打印结果
print("Wronskian 矩阵：")
print(wronskian_matrix)
print("Wronskian 行列式的值：")
print(wronskian_determinant)

import numpy as np
import matplotlib.pyplot as plt

N = 100 # number of points per class
D = 2 # dimensionality
K = 3 # number of classes
X = np.zeros((N*K,D)) # data matrix (each row = single example)
y = np.zeros(N*K, dtype='uint8') # class labels

for j in range(K):
  ix = range(N*j,N*(j+1))
  r = np.linspace(0.0,1,N) # radius
  t = np.linspace(j*4,(j+1)*4,N) + np.random.randn(N)*0.2 # theta
  X[ix] = np.c_[r*np.sin(t), r*np.cos(t)]
  y[ix] = j

# lets visualize the data:
plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.Spectral)
plt.show()

# initialize parameters randomly
W = 0.01 * np.random.randn(D,K)
b = np.zeros((1,K))

# compute class scores for a linear classifier
scores = np.dot(X, W) + b

# obtain the shape of the examples
num_examples = X.shape[0]
# get unnormalized probabilities
exp_scores = np.exp(scores)
# normalize them for each example
probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)

# normalize the probabilistic output
correct_logprobs = -np.log(probs[range(num_examples),y])

# compute the loss: average cross-entropy loss and regularization
data_loss = np.sum(correct_logprobs)/num_examples
reg_loss = 0.5*reg*np.sum(W*W)
loss = data_loss + reg_loss

# perform a parameter update
dscores = probs
dscores[range(num_examples),y] -= 1
dscores /= num_examples

dW = np.dot(X.T, dscores)
db = np.sum(dscores, axis=0, keepdims=True)
dW += reg*W # don't forget the regularization gradient

W += -step_size * dW
b += -step_size * db

"""### ORB + ?"""

from google.colab import drive
drive.mount("/content/data")

!pip install fiftyone
import fiftyone.zoo as foz

# List available zoo datasets
print(foz.list_zoo_datasets())

import cv2

# Create a video capture object, in this case we are reading the video from a file
vid_capture = cv2.VideoCapture('<file_path.mp4>') # For webcam change <file_path.mp4> to 0. Eg. vid_capture = cv2.VideoCapture(0)

if (vid_capture.isOpened() == False):
  print("Error opening the video file")
# Read fps and frame count
else:
  # Get frame rate information
  # You can replace 5 with CAP_PROP_FPS as well, they are enumerations
  fps = vid_capture.get(5)
  print('Frames per second : ', fps,'FPS')
  # Get frame count
  # You can replace 7 with CAP_PROP_FRAME_COUNT as well, they are enumerations
  frame_count = vid_capture.get(7)
  print('Frame count : ', frame_count)

while(vid_capture.isOpened()):
  # vid_capture.read() methods returns a tuple, first
  # element is a bool and the second is frame
  ret, frame = vid_capture.read()
  if ret == True:
    cv2.imshow('Frame',frame)
    # 20 is in milliseconds
    key = cv2.waitKey(20) # try to increase the value, say 50 and observe
    if key == ord('q'): # q for quit
      break
  else:
    break

# Release the video capture object
vid_capture.release()
cv2.destroyAllWindows()

import numpy as np
import cv2
from matplotlib import pyplot as plt

img = cv2.imread('1.png', 0)
# print('img')

# Initiate STAR detector
orb = cv2.ORB_create()
print('orb')

# find the keypoints with ORB
kp = orb.detect(img, None)
print('kp')

# compute the descriptors with ORB
kp, des = orb.compute(img, kp)

# draw only keypoints location,not size and orientation
img2 = cv2.drawKeypoints(img, kp, None, color=(0, 255, 0), flags=0)
print('img2')

plt.imshow(img2)
plt.show()

"""### Bag of Words (BoW)"""



"""### CNNs

#### General-Classifier-Wise
"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator
import os

def load_and_preprocess_data(directory, img_width, img_height, batch_size):
    # 使用Keras的ImageDataGenerator来生成更多的图像数据
    datagen = ImageDataGenerator(rescale=1./255,
                                 rotation_range=40,
                                 width_shift_range=0.2,
                                 height_shift_range=0.2,
                                 shear_range=0.2,
                                 zoom_range=0.2,
                                 horizontal_flip=True,
                                 fill_mode='nearest',
                                 validation_split=0.2)  # 使用20%的数据作为验证集

    train_generator = datagen.flow_from_directory(
        directory,
        target_size=(img_width, img_height),
        batch_size=batch_size,
        class_mode='categorical',
        subset='training')

    validation_generator = datagen.flow_from_directory(
        directory,
        target_size=(img_width, img_height),
        batch_size=batch_size,
        class_mode='categorical',
        subset='validation')

    return train_generator, validation_generator

# 数据集路径
data_directory = 'path_to_your_dataset'
img_width, img_height = 48, 48
batch_size = 32

# 载入数据集
train_generator, validation_generator = load_and_preprocess_data(data_directory, img_width, img_height, batch_size)

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization

def build_advanced_model(input_shape, num_classes):
    # 构建一个更复杂的CNN模型
    model = Sequential()

    # 第一层卷积
    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=input_shape, padding='same'))
    model.add(BatchNormalization())
    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))
    model.add(BatchNormalization())
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(0.25))

    # 第二层卷积
    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))
    model.add(BatchNormalization())
    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))
    model.add(BatchNormalization())
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(0.25))

    # 第三层卷积
    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))
    model.add(BatchNormalization())
    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))
    model.add(BatchNormalization())
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(0.25))

    # 扁平化和全连接层
    model.add(Flatten())
    model.add(Dense(512, activation='relu'))
    model.add(BatchNormalization())
    model.add(Dropout(0.5))
    model.add(Dense(num_classes, activation='softmax'))

    # 编译模型
    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

    return model

# 模型参数
input_shape = (48, 48, 3)  # 假设我们使用48x48像素的彩色图像
num_classes = 5  # 假设有5种情感状态

# 构建模型
advanced_emotion_model = build_advanced_model(input_shape, num_classes)

# 显示模型概要
advanced_emotion_model.summary()

# 获取最佳超参数
best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]

# 使用最佳超参数构建模型
model = tuner.hypermodel.build(best_hps)

# 训练模型
history = model.fit(train_generator, epochs=50, validation_data=validation_generator)

# 测试模型
# 这里假设您有一个单独的测试数据集
test_datagen = ImageDataGenerator(rescale=1./255)
test_generator = test_datagen.flow_from_directory(
        'path_to_your_test_dataset',
        target_size=(img_width, img_height),
        batch_size=batch_size,
        class_mode='categorical')

test_loss, test_acc = model.evaluate(test_generator)
print('Test accuracy:', test_acc)

# 获取最佳超参数
best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]

# 使用最佳超参数构建模型
model = tuner.hypermodel.build(best_hps)

# 训练模型
history = model.fit(train_generator, epochs=50, validation_data=validation_generator)

# 测试模型
# 这里假设您有一个单独的测试数据集
test_datagen = ImageDataGenerator(rescale=1./255)
test_generator = test_datagen.flow_from_directory(
        'path_to_your_test_dataset',
        target_size=(img_width, img_height),
        batch_size=batch_size,
        class_mode='categorical')

test_loss, test_acc = model.evaluate(test_generator)
print('Test accuracy:', test_acc)

"""#### ResNet50"""

from tensorflow.keras.applications import ResNet50
from tensorflow.keras.optimizers import Adam

# 加载预训练模型
model = ResNet50(weights='imagenet', include_top=False)

# 微调参数
learning_rate = 1e-4
batch_size = 32

# 编译模型
model.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])

# 数据准备和训练
# train_data = ...

model.fit(train_data, batch_size=batch_size)

...

"""#### YOLOs

##### v1
"""



"""##### v2"""



"""##### v3"""



"""##### v4"""

# 使用预训练的 YOLO 模型
# 注意：YOLO 模型的实现通常比较复杂，需要依赖特定库

detected_objects = yolo_model.predict(image)

"""##### v5"""



"""##### v6"""



"""##### v7"""



"""##### v8"""



"""#### VGG16"""

# train a Linear Classifier

# initialize parameters randomly
W = 0.01 * np.random.randn(D,K)
b = np.zeros((1,K))

# some hyperparameters
step_size = 1e-0
reg = 1e-3 # regularization strength

# gradient descent loop
num_examples = X.shape[0]
for i in range(200):

  # evaluate class scores, [N x K]
  scores = np.dot(X, W) + b

  # compute the class probabilities
  exp_scores = np.exp(scores)
  probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True) # [N x K]

  # compute the loss: average cross-entropy loss and regularization
  correct_logprobs = -np.log(probs[range(num_examples),y])
  data_loss = np.sum(correct_logprobs)/num_examples
  reg_loss = 0.5*reg*np.sum(W*W)
  loss = data_loss + reg_loss
  if i % 10 == 0:
    print "iteration %d: loss %f" % (i, loss)

  # compute the gradient on scores
  dscores = probs
  dscores[range(num_examples),y] -= 1
  dscores /= num_examples

  # backpropate the gradient to the parameters (W,b)
  dW = np.dot(X.T, dscores)
  db = np.sum(dscores, axis=0, keepdims=True)

  dW += reg*W # regularization gradient

  # perform a parameter update
  W += -step_size * dW
  b += -step_size * db



# evaluate training set accuracy
scores = np.dot(X, W) + b
predicted_class = np.argmax(scores, axis=1)
print 'training accuracy: %.2f' % (np.mean(predicted_class == y))

# initialize parameters randomly
h = 100 # size of hidden layer
W = 0.01 * np.random.randn(D,h)
b = np.zeros((1,h))
W2 = 0.01 * np.random.randn(h,K)
b2 = np.zeros((1,K))

# evaluate class scores with a 2-layer Neural Network
hidden_layer = np.maximum(0, np.dot(X, W) + b) # note, ReLU activation
scores = np.dot(hidden_layer, W2) + b2

# backpropate the gradient to the parameters
# first backprop into parameters W2 and b2
dW2 = np.dot(hidden_layer.T, dscores)
db2 = np.sum(dscores, axis=0, keepdims=True)

dhidden = np.dot(dscores, W2.T)

# finally into W,b
dW = np.dot(X.T, dhidden)
db = np.sum(dhidden, axis=0, keepdims=True)



# initialize parameters randomly
h = 100 # size of hidden layer
W = 0.01 * np.random.randn(D,h)
b = np.zeros((1,h))
W2 = 0.01 * np.random.randn(h,K)
b2 = np.zeros((1,K))

# some hyperparameters
step_size = 1e-0
reg = 1e-3 # regularization strength

# gradient descent loop
num_examples = X.shape[0]
for i in range(10000):

  # evaluate class scores, [N x K]
  hidden_layer = np.maximum(0, np.dot(X, W) + b) # note, ReLU activation
  scores = np.dot(hidden_layer, W2) + b2

  # compute the class probabilities
  exp_scores = np.exp(scores)
  probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True) # [N x K]

  # compute the loss: average cross-entropy loss and regularization
  correct_logprobs = -np.log(probs[range(num_examples),y])
  data_loss = np.sum(correct_logprobs)/num_examples
  reg_loss = 0.5*reg*np.sum(W*W) + 0.5*reg*np.sum(W2*W2)
  loss = data_loss + reg_loss
  if i % 1000 == 0:
    print "iteration %d: loss %f" % (i, loss)

  # compute the gradient on scores
  dscores = probs
  dscores[range(num_examples),y] -= 1
  dscores /= num_examples

  # backpropate the gradient to the parameters
  # first backprop into parameters W2 and b2
  dW2 = np.dot(hidden_layer.T, dscores)
  db2 = np.sum(dscores, axis=0, keepdims=True)
  # next backprop into hidden layer
  dhidden = np.dot(dscores, W2.T)
  # backprop the ReLU non-linearity
  dhidden[hidden_layer <= 0] = 0
  # finally into W,b
  dW = np.dot(X.T, dhidden)
  db = np.sum(dhidden, axis=0, keepdims=True)

  # add regularization gradient contribution
  dW2 += reg * W2
  dW += reg * W

  # perform a parameter update
  W += -step_size * dW
  b += -step_size * db
  W2 += -step_size * dW2
  b2 += -step_size * db2



# evaluate training set accuracy
hidden_layer = np.maximum(0, np.dot(X, W) + b)
scores = np.dot(hidden_layer, W2) + b2
predicted_class = np.argmax(scores, axis=1)
print 'training accuracy: %.2f' % (np.mean(predicted_class == y))

"""#### AlexNet

#### NiN (Network In Network)

#### VAE
"""

import tensorflow as tf
from tensorflow.keras import layers
import numpy as np

# 简单的变分自编码器模型
class VAE(tf.keras.Model):
    def __init__(self, latent_dim):
        super(VAE, self).__init__()
        self.latent_dim = latent_dim
        self.encoder = tf.keras.Sequential([
            layers.InputLayer(input_shape=(784,)),
            layers.Dense(latent_dim + latent_dim),
        ])

        self.decoder = tf.keras.Sequential([
            layers.InputLayer(input_shape=(latent_dim,)),
            layers.Dense(units=28*28, activation=tf.nn.relu),
            layers.Reshape(target_shape=(784,))
        ])

    def encode(self, x):
        mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)
        return mean, logvar

    def reparameterize(self, mean, logvar):
        eps = tf.random.normal(shape=mean.shape)
        return eps * tf.exp(logvar * .5) + mean

    def decode(self, z, apply_sigmoid=False):
        logits = self.decoder(z)
        if apply_sigmoid:
            probs = tf.sigmoid(logits)
            return probs
        return logits

    def compute_loss(self, x):
        mean, logvar = self.encode(x)
        z = self.reparameterize(mean, logvar)
        x_logit = self.decode(z)

        cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)
        logpx_z = -tf.reduce_sum(cross_ent, axis=1)  # 修改此处
        logpz = -0.5 * tf.reduce_sum(z**2, axis=1)
        logqz_x = -0.5 * tf.reduce_sum(logvar + tf.exp(-logvar + 1e-10) + mean**2, axis=1)
        return -tf.reduce_mean(logpx_z + logpz - logqz_x)

    def generate_images(self, n_images=10):
        # 生成随机的潜在变量
        random_latent_vectors = tf.random.normal(shape=(n_images, self.latent_dim))

        # 解码潜在变量以生成图像
        predictions = self.decode(random_latent_vectors, apply_sigmoid=True)

        return predictions

import tensorflow as tf

class VAE(tf.keras.Model):
    def __init__(self, latent_dim, input_shape):
        super(VAE, self).__init__()
        self.latent_dim = latent_dim
        # 调整网络结构以适应特定的输入尺寸和颜色通道
        self.encoder = tf.keras.Sequential([
            layers.InputLayer(input_shape=input_shape),
            layers.Conv2D(filters=32, kernel_size=3, activation='relu', strides=2, padding='same'),
            layers.Conv2D(filters=64, kernel_size=3, activation='relu', strides=2, padding='same'),
            layers.Flatten(),
            # 产生潜在空间的均值和对数方差
            layers.Dense(latent_dim + latent_dim),
        ])

        self.decoder = tf.keras.Sequential([
            layers.InputLayer(input_shape=(latent_dim,)),
            layers.Dense(units=7*7*32, activation='relu'),
            layers.Reshape(target_shape=(7, 7, 32)),
            layers.Conv2DTranspose(filters=64, kernel_size=3, activation='relu', strides=2, padding='same'),
            layers.Conv2DTranspose(filters=32, kernel_size=3, activation='relu', strides=2, padding='same'),
            # 调整最后一层的过滤器数量以匹配图像的颜色通道
            layers.Conv2DTranspose(filters=input_shape[-1], kernel_size=3, activation='sigmoid', padding='same'),
        ])

# 指定输入图像的尺寸和颜色通道
input_shape = (28, 28, 1)  # 例如，灰度图像的尺寸为 28x28
latent_dim = 2
model = VAE(latent_dim, input_shape)

# 示例数据
(x_train, _), _ = tf.keras.datasets.mnist.load_data()
x_train = x_train.astype("float32") / 255
x_train = x_train.reshape(x_train.shape[0], -1)  # 将 28x28 图像展平为 784 维向量

# 创建和训练 VAE 模型
latent_dim = 2
model = VAE(latent_dim)
optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)

# 创建数据集
train_dataset = tf.data.Dataset.from_tensor_slices(x_train).batch(32)  # 使用批大小为32



# 训练循环
for epoch in range(10):
    total_loss = 0
    for x_batch in train_dataset:
        with tf.GradientTape() as tape:
            loss = model.compute_loss(x_batch)  # 使用批数据
            total_loss += loss
        gradients = tape.gradient(loss, model.trainable_variables)
        optimizer.apply_gradients(zip(gradients, model.trainable_variables))
    print(f"Epoch {epoch + 1}, Loss: {total_loss / len(x_train)}")

# 生成新图像
generated_images = model.generate_images(n_images=10)

# 重塑生成的图像以便显示
reshaped_images = generated_images.numpy().reshape(-1, 28, 28)

# 显示生成的图像
import matplotlib.pyplot as plt

for i in range(reshaped_images.shape[0]):
    plt.subplot(2, 5, i + 1)
    plt.imshow(reshaped_images[i], cmap='gray')
    plt.axis('off')

plt.show()



"""### GANs

#### DCGAN
"""

import tensorflow as tf
from tensorflow.keras import layers

def make_generator_model():
    model = tf.keras.Sequential()
    model.add(layers.Dense(8*8*256, use_bias=False, input_shape=(100,)))
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    model.add(layers.Reshape((8, 8, 256)))
    assert model.output_shape == (None, 8, 8, 256)  # 注意：None 是批量大小

    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))
    assert model.output_shape == (None, 8, 8, 128)
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))
    assert model.output_shape == (None, 16, 16, 64)
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())

    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(4, 4), padding='same', use_bias=False, activation='tanh'))
    assert model.output_shape == (None, 64, 64, 1)

    return model

generator = make_generator_model()

cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)

def discriminator_loss(real_output, fake_output):
    real_loss = cross_entropy(tf.ones_like(real_output), real_output)
    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)
    total_loss = real_loss + fake_loss
    return total_loss

def generator_loss(fake_output):
    return cross_entropy(tf.ones_like(fake_output), fake_output)

generator_optimizer = tf.keras.optimizers.Adam(1e-4)
discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)

import numpy as np

EPOCHS = 50
noise_dim = 100
num_examples_to_generate = 16

# 用于生成图像的随机种子
seed = tf.random.normal([num_examples_to_generate, noise_dim])

@tf.function
def train_step(images):
    noise = tf.random.normal([BATCH_SIZE, noise_dim])

    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:
        generated_images = generator(noise, training=True)
        real_output = discriminator(images, training=True)
        fake_output = discriminator(generated_images, training=True)

        gen_loss = generator_loss(fake_output)
        disc_loss = discriminator_loss(real_output, fake_output)

    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)
    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)

    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))
    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))

def train(dataset, epochs):
    for epoch in range(epochs):
        for image_batch in dataset:
            train_step(image_batch)

# 假设 `train_dataset` 是预处理的图像数据集
train(train_dataset, EPOCHS)

"""### RNNs

#### RNN1
"""

def generate_images(generator, num_images):
    noise = tf.random.normal([num_images, noise_dim])
    generated_images = generator(noise, training=False)
    return generated_images

# 假设 noise_dim 是你的噪声维度
noise_dim = 100
num_images = 100  # 要生成的图像数量
generated_images = generate_images(generator, num_images)



# 假设 generated_images 是步骤 1 中生成的图像
# 这里我们简单地将图像本身作为特征
image_features = generated_images.numpy().reshape(num_images, -1)



def create_dataset(image_features, sequence_length):
    x_train = []
    y_train = []
    for i in range(len(image_features) - sequence_length):
        x_train.append(image_features[i:i + sequence_length])
        y_train.append(image_features[i + sequence_length])
    return np.array(x_train), np.array(y_train)

# 定义序列长度
sequence_length = 5  # 例如，使用5个连续图像的特征作为一个序列

# 生成训练数据
x_train, y_train = create_dataset(image_features, sequence_length)



# 定义 RNN 模型
model = tf.keras.Sequential([
    tf.keras.layers.SimpleRNN(128, input_shape=(None, image_features.shape[-1])),
    tf.keras.layers.Dense(image_features.shape[-1])
])

# 编译模型
model.compile(optimizer='adam', loss='mean_squared_error')

# 训练模型
# 这里需要根据你的具体情况调整输入数据的形状和组织方式
model.fit(x_train, y_train, epochs=10)



def neuron_tick(inputs):
  """
  assume input and we
  """

import AutoConfig, AutoModel
from transformers import DistilBertModel, DistilBertConfig

"""#### LSTM"""

import torch
from torch.utils.data import Dataset, DataLoader
import random

class VideoDataset(Dataset):
    def __init__(self, num_samples=100, num_frames=30, image_size=(3, 64, 64)):
        self.num_samples = num_samples
        self.num_frames = num_frames
        self.image_size = image_size
        self.data = torch.randn(num_samples, num_frames, *image_size)
        self.labels = torch.randint(0, 10, (num_samples,))

    def __len__(self):
        return self.num_samples

    def __getitem__(self, idx):
        return self.data[idx], self.labels[idx]

dataset = VideoDataset()
data_loader = DataLoader(dataset, batch_size=4, shuffle=True)



import torch.nn as nn
import torchvision.models as models

class VideoAnalysisModel(nn.Module):
    def __init__(self, num_frames, num_classes):
        super(VideoAnalysisModel, self).__init__()
        self.resnet = models.resnet18(pretrained=True)
        self.resnet.fc = nn.Identity()

        self.lstm = nn.LSTM(input_size=512, hidden_size=256, batch_first=True)
        self.fc = nn.Linear(256, num_classes)

    def forward(self, x):
        batch_size, num_frames, C, H, W = x.shape
        x = x.view(batch_size * num_frames, C, H, W)
        x = self.resnet(x)
        x = x.view(batch_size, num_frames, -1)
        x, _ = self.lstm(x)
        x = self.fc(x[:, -1, :])
        return x

model = VideoAnalysisModel(num_frames=30, num_classes=10)



device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

num_epochs = 5
for epoch in range(num_epochs):
    for frames, labels in data_loader:
        frames, labels = frames.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(frames)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}")

"""### OpenPose (Pose Detection)"""



"""### Image to Graph"""



"""## Graph

### GNNs

#### SAGE
"""



"""### GCN"""



# Commented out IPython magic to ensure Python compatibility.
"""
!pip install nocd
import nocd
"""

import matplotlib.pyplot as plt
import numpy as np
import scipy.sparse as sp
import torch
import torch.nn as nn
import torch.nn.functional as F

from sklearn.preprocessing import normalize

# %matplotlib inline

torch.set_default_tensor_type(torch.cuda.FloatTensor)

loader = nocd.data.load_dataset('data/mag_cs.npz')
A, X, Z_gt = loader['A'], loader['X'], loader['Z']
N, K = Z_gt.shape

hidden_sizes = [128]    # hidden sizes of the GNN
weight_decay = 1e-2     # strength of L2 regularization on GNN weights
dropout = 0.5           # whether to use dropout
batch_norm = True       # whether to use batch norm
lr = 1e-3               # learning rate
max_epochs = 500        # number of epochs to train
display_step = 25       # how often to compute validation loss
balance_loss = True     # whether to use balanced loss
stochastic_loss = True  # whether to use stochastic or full-batch training
batch_size = 20000      # batch size (only for stochastic training)

x_norm = normalize(X)  # node features
# x_norm = normalize(A)  # adjacency matrix
# x_norm = sp.hstack([normalize(X), normalize(A)])  # concatenate A and X
x_norm = nocd.utils.to_sparse_tensor(x_norm).cuda()

sampler = nocd.sampler.get_edge_sampler(A, batch_size, batch_size, num_workers=5)
gnn = nocd.nn.GCN(x_norm.shape[1], hidden_sizes, K, batch_norm=batch_norm, dropout=dropout).cuda()
adj_norm = gnn.normalize_adj(A)
decoder = nocd.nn.BerpoDecoder(N, A.nnz, balance_loss=balance_loss)
opt = torch.optim.Adam(gnn.parameters(), lr=lr)

def get_nmi(thresh=0.5):
    """Compute Overlapping NMI of the communities predicted by the GNN."""
    gnn.eval()
    Z = F.relu(gnn(x_norm, adj_norm))
    Z_pred = Z.cpu().detach().numpy() > thresh
    nmi = nocd.metrics.overlapping_nmi(Z_pred, Z_gt)
    return nmi

val_loss = np.inf
validation_fn = lambda: val_loss
early_stopping = nocd.train.NoImprovementStopping(validation_fn, patience=10)
model_saver = nocd.train.ModelSaver(gnn)

for epoch, batch in enumerate(sampler):
    if epoch > max_epochs:
        break
    if epoch % 25 == 0:
        with torch.no_grad():
            gnn.eval()
            # Compute validation loss
            Z = F.relu(gnn(x_norm, adj_norm))
            val_loss = decoder.loss_full(Z, A)
            print(f'Epoch {epoch:4d}, loss.full = {val_loss:.4f}, nmi = {get_nmi():.2f}')

            # Check if it's time for early stopping / to save the model
            early_stopping.next_step()
            if early_stopping.should_save():
                model_saver.save()
            if early_stopping.should_stop():
                print(f'Breaking due to early stopping at epoch {epoch}')
                break

    # Training step
    gnn.train()
    opt.zero_grad()
    Z = F.relu(gnn(x_norm, adj_norm))
    ones_idx, zeros_idx = batch
    if stochastic_loss:
        loss = decoder.loss_batch(Z, ones_idx, zeros_idx)
    else:
        loss = decoder.loss_full(Z, A)
    loss += nocd.utils.l2_reg_loss(gnn, scale=weight_decay)
    loss.backward()
    opt.step()

plt.hist(Z[Z > 0].cpu().detach().numpy(), 100);

thresh = 0.5

Z = F.relu(gnn(x_norm, adj_norm))
Z_pred = Z.cpu().detach().numpy() > thresh
model_saver.restore()
print(f'Final nmi = {get_nmi(thresh):.3f}')

plt.figure(figsize=[10, 10])
z = np.argmax(Z_pred, 1)
o = np.argsort(z)
nocd.utils.plot_sparse_clustered_adjacency(A, K, z, o, markersize=0.05)

# Sizes of detected communities
print(Z_pred.sum(0))

density_baseline = A.nnz / (N**2 - N)
num_triangles = (A @ A @ A).diagonal().sum() / 6
num_possible_triangles = (N - 2) * (N - 1) * N / 6
clust_coef_baseline = num_triangles / num_possible_triangles
print(f'Background (over the entire graph):\n'
      f' - density    = {density_baseline:.3e}\n'
      f' - clust_coef = {clust_coef_baseline:.3e}')

metrics = nocd.metrics.evaluate_unsupervised(Z_gt, A)
print(f"Ground truth communities:\n"
      f" - coverage    = {metrics['coverage']:.4f}\n"
      f" - conductance = {metrics['conductance']:.4f}\n"
      f" - density     = {metrics['density']:.3e}\n"
      f" - clust_coef  = {metrics['clustering_coef']:.3e}")

metrics = nocd.metrics.evaluate_unsupervised(Z_pred, A)
print(f"Predicted communities:\n"
      f" - coverage    = {metrics['coverage']:.4f}\n"
      f" - conductance = {metrics['conductance']:.4f}\n"
      f" - density     = {metrics['density']:.3e}\n"
      f" - clust_coef  = {metrics['clustering_coef']:.3e}")

"""#### Node2Vec"""



"""#### GAT"""

# 假设使用 PyTorch 和 PyTorch Geometric
import torch
!pip install torch_geometric
from torch_geometric.nn import GATConv  # 图注意力层

class TextVisionGNN(torch.nn.Module):
    def __init__(self):
        super(TextVisionGNN, self).__init__()
        self.conv1 = GATConv(输入特征维度, 输出特征维度)

    def forward(self, data):
        x, edge_index = data.x, data.edge_index
        x = self.conv1(x, edge_index)
        return torch.nn.functional.log_softmax(x, dim=1)

# 使用模型
model = TextVisionGNN()
# 假设 data 是包含节点和边的图数据
output = model(data)

"""#### HIN"""



"""#### HGNN"""



"""#### HetSANN"""



"""### Louvain"""

import networkx as nx
import community as community_louvain
import matplotlib.pyplot as plt

# 创建一个示例网络
G = nx.erdos_renyi_graph(30, 0.05)

# 使用 Louvain 算法进行社区检测
partition = community_louvain.best_partition(G)

# 绘制网络和社区
pos = nx.spring_layout(G)
cmap = plt.cm.jet
plt.figure(figsize=(8, 8))
nx.draw_networkx_nodes(G, pos, partition.keys(), node_size=40,
                       cmap=cmap, node_color=list(partition.values()))
nx.draw_networkx_edges(G, pos, alpha=0.5)
plt.show()

# 打印社区成员
for i, comm in enumerate(set(partition.values())):
    print(f"社区 {i}: {[nodes for nodes in partition.keys() if partition[nodes] == comm]}")

import networkx as nx
import numpy as np
import pandas as pd

G = nx.Graph()
G.add_node(1, pop=1000, pos=(0, 0))
G.add_node(2, pop=1500, pos=(1, 1))
G.add_node(3, pop=2000, pos=(2, 0))
G.add_edge(1, 2, weight=0.5, length=10)
G.add_edge(2, 3, weight=0.7, length=15)

...

"""## Time-Series

### RNNs

#### LSTM
"""

import pandas as pd

# 假设 df 是一个以时间为索引的 DataFrame
df.resample('1H').mean()  # 以1小时为单位重采样，使用均值填充
df.interpolate(method='time')  # 时间插值

import numpy as np

# 示例：线性插值
x = np.array([时间点数组])
y = np.array([对应的值数组])
new_x = np.array([新的时间点数组])
new_y = np.interp(new_x, x, y)

from scipy import interpolate

x = np.array([时间点数组])
y = np.array([对应的值数组])
f = interpolate.interp1d(x, y, kind='cubic')
new_y = f(new_x)

import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import yfinance as yf

# 下载股票数据
data = yf.download('AAPL', start='2020-01-01', end='2021-01-01')
prices = data['Close'].values.astype(float)

# 数据预处理：标准化
prices = (prices - np.mean(prices)) / np.std(prices)
prices = prices.reshape(-1, 1)

# 将数据转换成数据集
def create_dataset(data, time_step=1):
    dataX, dataY = [], []
    for i in range(len(data) - time_step - 1):
        a = data[i:(i + time_step), 0]
        dataX.append(a)
        dataY.append(data[i + time_step, 0])
    return np.array(dataX), np.array(dataY)

time_step = 10
X, y = create_dataset(prices, time_step)
train_size = int(len(X) * 0.7)
test_size = len(X) - train_size
trainX, testX = X[:train_size], X[train_size:]
trainY, testY = y[:train_size], y[train_size:]

# 转换为torch张量
trainX = torch.from_numpy(trainX).type(torch.Tensor)
trainY = torch.from_numpy(trainY).type(torch.Tensor)
testX = torch.from_numpy(testX).type(torch.Tensor)
testY = torch.from_numpy(testY).type(torch.Tensor)

# 定义LSTM模型
class LSTM(nn.Module):
    def __init__(self, input_size=1, hidden_layer_size=100, output_size=1):
        super().__init__()
        self.hidden_layer_size = hidden_layer_size
        self.lstm = nn.LSTM(input_size, hidden_layer_size)
        self.linear = nn.Linear(hidden_layer_size, output_size)
        self.hidden_cell = (torch.zeros(1, 1, self.hidden_layer_size),
                            torch.zeros(1, 1, self.hidden_layer_size))

    def forward(self, input_seq):
        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq) ,1, -1), self.hidden_cell)
        predictions = self.linear(lstm_out.view(len(input_seq), -1))
        return predictions[-1]

model = LSTM()
loss_function = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# 训练模型
epochs = 150
for i in range(epochs):
    for seq, labels in zip(trainX, trainY):
        optimizer.zero_grad()
        model.hidden_cell = (torch.zeros(1, 1, model.hidden_layer_size),
                             torch.zeros(1, 1, model.hidden_layer_size))
        y_pred = model(seq)
        single_loss = loss_function(y_pred, labels)
        single_loss.backward()
        optimizer.step()
    if i%25 == 1:
        print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')

# 预测
with torch.no_grad():
    test_predictions = model(testX)
    test_predictions = test_predictions.view(-1).numpy()

plt.plot(testY, label='True')
plt.plot(test_predictions, label='Predictions')
plt.legend()
plt.show()

"""## Reinforcement Learning

### MDP
"""



"""### PO

#### DDPO
"""



"""#### PPO"""



"""### Q-Learning

#### DQN-wise
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
import torchvision.models as models
import random
import numpy as np

# 定义一个简单的图像-文本融合网络
class TextImageFusionModel(nn.Module):
    def __init__(self, text_input_dim, image_input_dim, output_dim):
        super(TextImageFusionModel, self).__init__()
        self.text_fc = nn.Linear(text_input_dim, 128)  # 文本处理层
        self.image_fc = nn.Linear(image_input_dim, 128)  # 图像处理层
        self.output_fc = nn.Linear(256, output_dim)  # 融合后的输出层

    def forward(self, text, image):
        text_features = torch.relu(self.text_fc(text))
        image_features = torch.relu(self.image_fc(image))
        combined_features = torch.cat((text_features, image_features), dim=1)
        output = self.output_fc(combined_features)
        return output

# DQN 代理
class DQNAgent:
    def __init__(self, text_input_dim, image_input_dim, output_dim):
        self.model = TextImageFusionModel(text_input_dim, image_input_dim, output_dim)
        self.optimizer = optim.Adam(self.model.parameters(), lr=0.001)

    def generate(self, text, image):
        # 生成动作（在这个例子中是一些输出值）
        output = self.model(text, image)
        return output

    def update(self, batch):
        # 更新模型（根据您的具体任务来实现）
        pass

# 假设环境
class FusionEnvironment:
    def reset(self):
        # 初始化环境并返回初始状态
        return torch.randn(10), torch.randn(512)  # 假设的文本和图像特征

    def step(self, action):
        # 执行动作并返回新状态和奖励（需要根据您的具体任务来实现）
        new_state = torch.randn(10), torch.randn(512)  # 新的随机状态
        reward = random.random()  # 随机奖励
        return new_state, reward

# 训练循环
def train(env, agent, num_episodes):
    for episode in range(num_episodes):
        state = env.reset()
        total_reward = 0

        for t in range(100):
            text, image = state
            action = agent.generate(text, image)
            state, reward = env.step(action)
            total_reward += reward
            # 存储经验、更新模型等

        print(f"Episode: {episode}, Total Reward: {total_reward}")

# 实例化环境和代理，并开始训练
env = FusionEnvironment()
agent = DQNAgent(10, 512, 10)  # 假设的输入和输出维度
train(env, agent, num_episodes=50)

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
import torchvision.models as models
import random
import numpy as np

# 定义一个简单的图像-文本融合网络
class TextImageFusionModel(nn.Module):
    def __init__(self, text_input_dim, image_input_dim, output_dim):
        super(TextImageFusionModel, self).__init__()
        self.text_fc = nn.Linear(text_input_dim, 128)  # 文本处理层
        self.image_fc = nn.Linear(image_input_dim, 128)  # 图像处理层
        self.output_fc = nn.Linear(256, output_dim)  # 融合后的输出层

    def forward(self, text, image):
        text_features = torch.relu(self.text_fc(text))
        image_features = torch.relu(self.image_fc(image))
        combined_features = torch.cat((text_features, image_features), dim=1)
        output = self.output_fc(combined_features)
        return output

# DQN 代理
class DQNAgent:
    def __init__(self, text_input_dim, image_input_dim, output_dim):
        self.model = TextImageFusionModel(text_input_dim, image_input_dim, output_dim)
        self.optimizer = optim.Adam(self.model.parameters(), lr=0.001)

    def generate(self, text, image):
        # 生成动作（在这个例子中是一些输出值）
        output = self.model(text, image)
        return output

    def update(self, batch):
        # 更新模型（根据您的具体任务来实现）
        pass

# 假设环境
class FusionEnvironment:
    def reset(self):
        # 初始化环境并返回初始状态
        return torch.randn(10), torch.randn(512)  # 假设的文本和图像特征

    def step(self, action):
        # 执行动作并返回新状态和奖励（需要根据您的具体任务来实现）
        new_state = torch.randn(10), torch.randn(512)  # 新的随机状态
        reward = random.random()  # 随机奖励
        return new_state, reward

# 训练循环
def train(env, agent, num_episodes):
    for episode in range(num_episodes):
        state = env.reset()
        total_reward = 0

        for t in range(100):
            text, image = state
            action = agent.generate(text, image)
            state, reward = env.step(action)
            total_reward += reward
            # 存储经验、更新模型等

        print(f"Episode: {episode}, Total Reward: {total_reward}")

# 实例化环境和代理，并开始训练
env = FusionEnvironment()
agent = DQNAgent(10, 512, 10)  # 假设的输入和输出维度
train(env, agent, num_episodes=50)



import torch
import torch.nn as nn
import torch.optim as optim
import random
import numpy as np

# 假设环境提供以下接口
class Environment:
    def reset(self):
        # 重置环境到初始状态
        pass

    def step(self, action):
        # 执行动作，返回新状态、奖励和完成标志
        pass

# 多模态数据处理网络（CNN + LSTM）
class MultiModalNet(nn.Module):
    def __init__(self):
        super(MultiModalNet, self).__init__()
        # 定义处理图像的 CNN 部分
        # 定义处理文本/时序的 LSTM 部分
        # 定义其他必要的层

    def forward(self, image, text):
        # 处理图像数据
        # 处理文本数据
        # 融合并返回决策
        pass

# DQN 算法
class DQN:
    def __init__(self):
        self.model = MultiModalNet()
        self.target_model = MultiModalNet()
        self.optimizer = optim.Adam(self.model.parameters(), lr=0.001)

    def select_action(self, state):
        # 选择动作
        pass

    def update(self, batch):
        # 更新模型
        pass

# 训练循环
def train(env, agent, num_episodes):
    for episode in range(num_episodes):
        state = env.reset()
        total_reward = 0
        done = False

        while not done:
            action = agent.select_action(state)
            next_state, reward, done = env.step(action)

            # 存储经验
            # ...

            # 更新模型
            # ...

            state = next_state
            total_reward += reward

        print(f"Episode: {episode}, Total Reward: {total_reward}")

env = Environment()
agent = DQN()
train(env, agent, num_episodes=100)

import torch
import torch.nn as nn
import torch.optim as optim
import random

class TextImageGenerator(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim):
        super(TextImageGenerator, self).__init__()
        # 网络结构，处理输入并生成输出
        pass

class DQNGeneratorAgent:
    def __init__(self, input_dim, hidden_dim, output_dim):
        self.model = TextImageGenerator(input_dim, hidden_dim, output_dim)
        self.optimizer = optim.Adam(self.model.parameters(), lr=0.001)

    def generate(self, state):
        # 根据状态生成内容
        pass

    def update(self, batch):
        # 更新模型
        pass

# 假设环境
class TextImageEnvironment:
    def reset(self):
        # 初始化环境
        pass

    def step(self, action):
        # 根据动作生成新的状态和奖励
        pass

# 训练循环
def train_generator(env, agent, num_episodes):
    for episode in range(num_episodes):
        state = env.reset()
        total_reward = 0

        # 在这个循环中，agent 需要根据当前状态生成内容，并从环境中获取奖励
        for t in range(100):  # 假设每个episode有100个时间步
            action = agent.generate(state)
            next_state, reward = env.step(action)
            state = next_state
            total_reward += reward
            # 存储经验，更新模型等

        print(f"Episode: {episode}, Total Reward: {total_reward}")

import gym
from gym import spaces
import spacy
import random

# 加载Spacy的英文模型
nlp = spacy.load('en_core_web_sm')

class SentimentAnalysisEnv(gym.Env):
    """一个简化的情感分析环境"""
    metadata = {'render.modes': ['console']}

    def __init__(self):
        super(SentimentAnalysisEnv, self).__init__()
        # 定义一个只有两个动作的动作空间：0（负面情感），1（正面情感）
        self.action_space = spaces.Discrete(2)
        # 假设状态空间是一个句子的向量表示
        self.observation_space = spaces.Box(low=-1, high=1, shape=(300,), dtype=float)
        # 模拟的文本数据
        self.text_data = [
            ("I love this!", 1),
            ("I hate this!", 0),
            ("This is great!", 1),
            ("This is awful!", 0)
        ]

    def step(self, action):
        text, true_sentiment = self.current_text
        # 如果代理的动作和实际情感一致，给予正奖励
        reward = 1 if action == true_sentiment else -1
        # 这里没有真正的状态，只是返回下一个文本
        done = True  # 每个例子只做一次判断
        return self._next_observation(), reward, done, {}

    def reset(self):
        # 随机选择一个新文本
        self.current_text = random.choice(self.text_data)
        return self._next_observation()

    def render(self, mode='console'):
        if mode != 'console':
            raise NotImplementedError()
        text, sentiment = self.current_text
        print(f"Text: {text}, Sentiment: {'Positive' if sentiment else 'Negative'}")

    def _next_observation(self):
        # 这里只是一个示例，我们返回一个空的向量，实际上应该是文本的向量表示
        return self.observation_space.sample()

# 创建和使用环境
env = SentimentAnalysisEnv()
obs = env.reset()
env.render()

# 假设代理总是预测正面情感
action = 1
obs, reward, done, info = env.step(action)
print(f"Reward: {reward}")

"""# Experiments for the NLP Project

## Contrastive Learning

### Contrastive Tension
"""

# 导入相关的包
import numpy as np

# 扩展的嵌入表示
embedding_A = np.array([1, 2])
embedding_B = np.array([2, 1])
embedding_C = np.array([8, 9])
embedding_D = np.array([9, 8])
embedding_E = np.array([1, -2])
embedding_F = np.array([-2, 1])

# 定义一个函数来计算两个嵌入之间的欧氏距离
def euclidean_distance(vec1, vec2):
    return np.sqrt(np.sum((np.array(vec1) - np.array(vec2))**2))

# 计算扩展数据集中所有可能的正样本对和负样本对之间的距离
distances = {
    "A-B": euclidean_distance(embedding_A, embedding_B),
    "C-D": euclidean_distance(embedding_C, embedding_D),
    "E-F": euclidean_distance(embedding_E, embedding_F),
    "A-C": euclidean_distance(embedding_A, embedding_C),
    "A-D": euclidean_distance(embedding_A, embedding_D),
    "A-E": euclidean_distance(embedding_A, embedding_E),
    "A-F": euclidean_distance(embedding_A, embedding_F),
    # 可以继续添加更多的距离计算
}

# 打印计算结果
for pair, distance in distances.items():
    print(f"距离 {pair}: {distance}")

"""# Multi-Modal Data Mining Tasks

## Audio-Text

### Simple Fusion
"""

import torch
from torch.utils.data import Dataset, DataLoader
import numpy as np

class AudioTextDataset(Dataset):
    def __init__(self, num_samples=100, audio_size=1000, text_length=50, vocab_size=10000):
        self.num_samples = num_samples
        self.audio_data = torch.randn(num_samples, audio_size)  # 随机生成音频数据
        self.text_data = torch.randint(low=0, high=vocab_size, size=(num_samples, text_length))  # 随机生成文本数据
        self.labels = torch.randint(0, 2, (num_samples,))  # 假设是一个二分类问题

    def __len__(self):
        return self.num_samples

    def __getitem__(self, idx):
        return self.audio_data[idx], self.text_data[idx], self.labels[idx]

# 创建数据集和数据加载器
dataset = AudioTextDataset()
data_loader = DataLoader(dataset, batch_size=4, shuffle=True)

import torch.nn as nn

class AudioTextFusionModel(nn.Module):
    def __init__(self, audio_input_size, text_input_dim, hidden_size, output_dim, vocab_size):
        super(AudioTextFusionModel, self).__init__()
        self.audio_fc = nn.Linear(audio_input_size, hidden_size)  # 音频数据的全连接层
        self.text_embedding = nn.Embedding(vocab_size, text_input_dim)  # 文本数据的嵌入层
        self.text_lstm = nn.LSTM(text_input_dim, hidden_size, batch_first=True)  # 文本数据的 LSTM 层
        self.fc = nn.Linear(2 * hidden_size, output_dim)  # 融合音频和文本后的全连接层

    def forward(self, audio, text):
        audio_output = torch.relu(self.audio_fc(audio))
        text_embedded = self.text_embedding(text)
        _, (text_output, _) = self.text_lstm(text_embedded)
        text_output = text_output[-1]
        combined = torch.cat((audio_output, text_output), dim=1)
        output = self.fc(combined)
        return output

# 设置设备
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# 定义模型参数
audio_input_size = 1000
text_input_dim = 128
hidden_size = 128
output_dim = 2
vocab_size = 10000

# 实例化模型、损失函数和优化器
model = AudioTextFusionModel(audio_input_size, text_input_dim, hidden_size, output_dim, vocab_size).to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# 训练循环
num_epochs = 5
for epoch in range(num_epochs):
    for audio, text, labels in data_loader:
        audio, text, labels = audio.to(device), text.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(audio, text)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}")



"""## Audio-Image (Video)

### Simple Fusion
"""

import torch
from torch.utils.data import Dataset, DataLoader

class VideoDataset(Dataset):
    def __init__(self, num_samples=100, audio_size=1000, image_size=(3, 64, 64)):
        self.num_samples = num_samples
        self.audio_data = torch.randn(num_samples, audio_size)  # 随机生成音频数据
        self.image_data = torch.randn(num_samples, *image_size)  # 随机生成图像数据
        self.labels = torch.randint(0, 10, (num_samples,))  # 假设有10个类别

    def __len__(self):
        return self.num_samples

    def __getitem__(self, idx):
        return self.audio_data[idx], self.image_data[idx], self.labels[idx]

# 实例化数据集和数据加载器
dataset = VideoDataset()
data_loader = DataLoader(dataset, batch_size=4, shuffle=True)

import torch.nn as nn
import torchvision.models as models

class AudioImageFusionModel(nn.Module):
    def __init__(self, audio_input_size, image_input_dim, hidden_size, num_classes):
        super(AudioImageFusionModel, self).__init__()
        self.audio_fc = nn.Linear(audio_input_size, hidden_size)
        self.image_cnn = models.resnet18(pretrained=True)
        self.image_cnn.fc = nn.Linear(self.image_cnn.fc.in_features, hidden_size)
        self.fc = nn.Linear(2 * hidden_size, num_classes)

    def forward(self, audio, image):
        audio_features = torch.relu(self.audio_fc(audio))
        image_features = torch.relu(self.image_cnn(image))
        combined_features = torch.cat([audio_features, image_features], dim=1)
        output = self.fc(combined_features)
        return output

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

model = AudioImageFusionModel(audio_input_size=1000, image_input_dim=512, hidden_size=128, num_classes=10).to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

num_epochs = 5
for epoch in range(num_epochs):
    for audio, image, labels in data_loader:
        audio, image, labels = audio.to(device), image.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(audio, image)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}")

"""## Audio-Graph

### Simple Fusion
"""



"""## Audio-Time

### Simple Fusion
"""

import torch
from torch.utils.data import Dataset, DataLoader
import numpy as np

class AudioTimeSeriesDataset(Dataset):
    def __init__(self, num_samples=100, audio_size=1000, time_series_length=100):
        self.num_samples = num_samples
        self.audio_data = torch.randn(num_samples, audio_size)  # 随机生成音频数据
        self.time_series_data = torch.randn(num_samples, time_series_length)  # 随机生成时间序列数据
        self.labels = torch.randint(0, 2, (num_samples,))  # 假设是一个二分类问题

    def __len__(self):
        return self.num_samples

    def __getitem__(self, idx):
        return self.audio_data[idx], self.time_series_data[idx], self.labels[idx]

# 实例化数据集和数据加载器
dataset = AudioTimeSeriesDataset()
data_loader = DataLoader(dataset, batch_size=4, shuffle=True)

import torch.nn as nn

class AudioTimeSeriesFusionModel(nn.Module):
    def __init__(self, audio_input_size, time_series_input_size, hidden_size, output_dim):
        super(AudioTimeSeriesFusionModel, self).__init__()
        self.audio_fc = nn.Linear(audio_input_size, hidden_size)  # 音频数据的全连接层
        self.time_series_fc = nn.Linear(time_series_input_size, hidden_size)  # 时间序列数据的全连接层
        self.fc = nn.Linear(2 * hidden_size, output_dim)  # 融合后的全连接层

    def forward(self, audio, time_series):
        audio_output = torch.relu(self.audio_fc(audio))
        time_series_output = torch.relu(self.time_series_fc(time_series))
        combined = torch.cat((audio_output, time_series_output), dim=1)
        output = self.fc(combined)
        return output

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

model = AudioTimeSeriesFusionModel(audio_input_size=1000, time_series_input_size=100, hidden_size=128, output_dim=2).to(device)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

num_epochs = 5
for epoch in range(num_epochs):
    for audio, time_series, labels in data_loader:
        audio, time_series, labels = audio.to(device), time_series.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(audio, time_series)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}")

"""## Text-Image

### Simple Fusion
"""

import torch
import torch.nn as nn
import torchvision.models as models

class TextImageFusionModel(nn.Module):
    def __init__(self, text_embedding_dim, hidden_dim, vocab_size, num_classes):
        super(TextImageFusionModel, self).__init__()

        # 文本部分 - LSTM
        self.embedding = nn.Embedding(vocab_size, text_embedding_dim)
        self.lstm = nn.LSTM(text_embedding_dim, hidden_dim, batch_first=True)

        # 图像部分 - CNN (使用预训练的ResNet)
        self.cnn = models.resnet18(pretrained=True)
        self.cnn.fc = nn.Identity()  # 移除最后的全连接层

        # 分类器
        self.fc = nn.Linear(hidden_dim + 512, num_classes)  # LSTM的输出和CNN的输出拼接

    def forward(self, text, text_lengths, images):
        # 文本处理
        text_embedded = self.embedding(text)
        packed_input = nn.utils.rnn.pack_padded_sequence(text_embedded, text_lengths, batch_first=True, enforce_sorted=False)
        packed_output, (ht, ct) = self.lstm(packed_input)
        text_output = ht[-1]  # 使用最后一个隐藏状态

        # 图像处理
        image_output = self.cnn(images)

        # 融合并分类
        combined = torch.cat((text_output, image_output), dim=1)

        return self.fc(combined)  # 确保这里返回的是输出张量

def train(model, data_loader, criterion, optimizer, device, num_epochs):
    model.train()  # 将模型设置为训练模式
    for epoch in range(num_epochs):
        for text, text_lengths, images, labels in data_loader:
            text, images, labels = text.to(device), images.to(device), labels.to(device)

            optimizer.zero_grad()
            outputs = model(text, text_lengths, images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}")

def evaluate(model, data_loader, criterion, device):
    model.eval()  # 将模型设置为评估模式
    total_loss = 0
    correct = 0
    total = 0
    with torch.no_grad():
        for text, text_lengths, images, labels in data_loader:
            text, images, labels = text.to(device), images.to(device), labels.to(device)
            outputs = model(text, text_lengths, images)
            loss = criterion(outputs, labels)
            total_loss += loss.item()
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    avg_loss = total_loss / len(data_loader)
    accuracy = correct / total
    return avg_loss, accuracy

# 模型参数
text_embedding_dim = 100
hidden_dim = 128
vocab_size = 10000  # 假设词汇表大小为 10000
num_classes = 10  # 假设有 10 个类别

# 实例化模型
model = TextImageFusionModel(text_embedding_dim, hidden_dim, vocab_size, num_classes)

# 定义损失函数和优化器
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# 设备配置
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

from torch.utils.data import Dataset, DataLoader
import torch
import random

class TextImageData(Dataset):
    def __init__(self, num_samples=100, text_len=20, vocab_size=10000, image_size=(3, 64, 64)):
        self.num_samples = num_samples
        self.text_len = text_len
        self.vocab_size = vocab_size
        self.image_size = image_size

        # 模拟文本数据：随机生成文本序列
        self.texts = torch.randint(0, vocab_size, (num_samples, text_len))

        # 模拟图像数据：随机生成图像
        self.images = torch.randn(num_samples, *image_size)

        # 模拟标签数据
        self.labels = torch.randint(0, 10, (num_samples,))

    def __len__(self):
        return self.num_samples

    def __getitem__(self, idx):
        text = self.texts[idx]
        image = self.images[idx]
        label = self.labels[idx]

        # 生成文本长度（这里简化为固定长度）
        text_length = self.text_len

        return text, text_length, image, label

# 创建数据集
train_dataset = TextImageData()
test_dataset = TextImageData()

# 创建 DataLoader
train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)

# 假设 train_loader 和 test_loader 是您的训练和测试数据加载器
num_epochs = 5
train(model, train_loader, criterion, optimizer, device, num_epochs)
test_loss, test_accuracy = evaluate(model, test_loader, criterion, device)
print(f"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}")

"""### Transformers

#### ViLBERT
"""



"""#### LXMERT"""



"""#### ()

## Text-Time

### Simple Fusion
"""

import torch
from torch.utils.data import Dataset, DataLoader
from transformers import BertTokenizer
import random
import numpy as np

# 假设的文本数据和时间序列数据
text_data = ["这是一条新闻文本" + str(i) for i in range(100)]
time_series_data = np.random.rand(100, 10, 5)  # 假设有100条数据，每条有10个时间步长，每个时间步长有5个特征

# BERT tokenizer
tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')

# 自定义数据集
class TextTimeSeriesDataset(Dataset):
    def __init__(self, texts, time_series):
        self.texts = texts
        self.time_series = time_series
        self.tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')

    def __len__(self):
        return len(self.texts)

    def __getitem__(self, idx):
        # 获取文本数据并进行编码
        text = self.texts[idx]
        encoded_text = self.tokenizer.encode_plus(
            text,
            add_special_tokens=True,
            max_length=64,
            padding='max_length',
            return_attention_mask=True,
            return_tensors='pt',
            truncation=True
        )
        # 获取时间序列数据
        series = torch.tensor(self.time_series[idx], dtype=torch.float32)
        return {
            'input_ids': encoded_text['input_ids'].flatten(),
            'attention_mask': encoded_text['attention_mask'].flatten(),
            'time_series': series
        }

# 创建数据集和数据加载器
dataset = TextTimeSeriesDataset(text_data, time_series_data)
loader = DataLoader(dataset, batch_size=8, shuffle=True)

import torch
import torch.nn as nn
from transformers import BertModel

class TextTimeSeriesFusionModel(nn.Module):
    def __init__(self, bert_model_name, time_series_feature_size, hidden_size, output_size):
        super(TextTimeSeriesFusionModel, self).__init__()
        # 文本组件 - 使用BERT
        self.bert = BertModel.from_pretrained(bert_model_name)
        # 时序组件 - 使用LSTM
        self.lstm = nn.LSTM(input_size=time_series_feature_size, hidden_size=hidden_size, batch_first=True)
        # 融合层
        self.fc = nn.Linear(hidden_size + self.bert.config.hidden_size, output_size)

    def forward(self, input_ids, attention_mask, time_series):
        # 处理文本数据
        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)
        text_representation = outputs.pooler_output
        # 处理时序数据
        _, (hidden, _) = self.lstm(time_series)
        # 取LSTM最后一个隐藏状态
        time_series_representation = hidden[-1]
        # 融合文本和时序特征
        combined_representation = torch.cat((text_representation, time_series_representation), dim=1)
        # 进行预测
        output = self.fc(combined_representation)
        return output

# 超参数
bert_model_name = 'bert-base-chinese' # 'bert-base-uncased' as an alternative
time_series_feature_size = 5  # 假设时间序列数据有5个特征
hidden_size = 128
output_size = 1  # 例如，预测价格变动

# 实例化模型
model = TextTimeSeriesFusionModel(bert_model_name, time_series_feature_size, hidden_size, output_size)

def train_model(model, data_loader, loss_fn, optimizer, num_epochs):
    for epoch in range(num_epochs):
        for batch in data_loader:
            input_ids = batch['input_ids']
            attention_mask = batch['attention_mask']
            time_series = batch['time_series']

            # 模型预测
            predictions = model(input_ids, attention_mask, time_series)

            # 计算损失
            labels = torch.rand(predictions.shape)  # 这里我们使用随机生成的标签来模拟真实标签
            loss = loss_fn(predictions, labels)

            # 反向传播
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            print(f"Epoch {epoch}, Loss: {loss.item()}")

# 设置损失函数和优化器
loss_fn = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)

# 开始训练
train_model(model, loader, loss_fn, optimizer, num_epochs=3)

def evaluate_model(model, data_loader, loss_fn):
    model.eval()  # 将模型设置为评估模式
    total_loss = 0
    with torch.no_grad():  # 在评估过程中不计算梯度
        for batch in data_loader:
            input_ids = batch['input_ids']
            attention_mask = batch['attention_mask']
            time_series = batch['time_series']
            labels = torch.rand(input_ids.shape[0])  # 假设的标签

            predictions = model(input_ids, attention_mask, time_series)
            loss = loss_fn(predictions, labels.unsqueeze(1))
            total_loss += loss.item()

    avg_loss = total_loss / len(data_loader)
    print(f"Average Loss: {avg_loss:.4f}")

# 评估模型
evaluate_model(model, loader, loss_fn)

"""## Image-Time

### Simple Fusion (Video)
"""

import torch
import torch.nn as nn
import torchvision.models as models

class CNNLSTM(nn.Module):
    def __init__(self, num_classes, hidden_size, num_layers):
        super(CNNLSTM, self).__init__()
        # 使用预训练的 ResNet18 作为 CNN 部分
        self.cnn = models.resnet18(pretrained=True)
        self.cnn.fc = nn.Identity()  # 移除最后的全连接层

        # LSTM 部分
        self.lstm = nn.LSTM(input_size=512, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)

        # 全连接层，用于分类
        self.fc = nn.Linear(hidden_size, num_classes)

    def forward(self, images, sequences):
        batch_size, seq_len, c, h, w = images.shape
        cnn_out = torch.zeros(batch_size, seq_len, 512).to(images.device)

        for t in range(seq_len):
            # 处理每一个时间步的图像
            x = self.cnn(images[:, t, :, :, :])
            cnn_out[:, t, :] = x

        # LSTM 部分
        lstm_out, _ = self.lstm(cnn_out)

        # 分类
        out = self.fc(lstm_out[:, -1, :])
        return out

num_classes = 10  # 假设我们有10个类别
hidden_size = 128  # LSTM的隐藏层大小
num_layers = 2  # LSTM的层数

model = CNNLSTM(num_classes, hidden_size, num_layers)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

import torch
from torch.utils.data import Dataset, DataLoader
import numpy as np

class MyDataset(Dataset):
    def __init__(self, num_samples=100, image_size=(3, 64, 64), sequence_length=30):
        self.num_samples = num_samples
        self.image_size = image_size
        self.sequence_length = sequence_length

        # 模拟数据
        self.images = torch.randn(num_samples, *image_size)
        self.sequences = torch.randn(num_samples, sequence_length)
        self.labels = torch.randint(0, 10, (num_samples,))  # 假设有10个类别

    def __len__(self):
        return self.num_samples

    def __getitem__(self, idx):
        return self.images[idx], self.sequences[idx], self.labels[idx]

# 实例化数据集
dataset = MyDataset()
data_loader = DataLoader(dataset, batch_size=4, shuffle=True)

# 示例：从 DataLoader 中获取一批数据
for images, sequences, labels in data_loader:
    print(f"Images shape: {images.shape}")
    print(f"Sequences shape: {sequences.shape}")
    print(f"Labels: {labels}")
    break  # 只展示第一批数据

def train(model, data_loader, criterion, optimizer, num_epochs):
    model.train()
    for epoch in range(num_epochs):
        for images, sequences, labels in data_loader:
            # 假设 images, sequences, labels 是从 DataLoader 中获取的
            images = images.unsqueeze(1)
            optimizer.zero_grad()
            outputs = model(images, sequences)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}")

# 训练模型
train(model, data_loader, criterion, optimizer, num_epochs=5)

def evaluate(model, data_loader, criterion):
    model.eval()  # 将模型设置为评估模式
    total_loss = 0
    correct = 0
    total = 0

    with torch.no_grad():  # 在评估过程中不计算梯度
        for images, sequences, labels in data_loader:
            images = images.unsqueeze(1)
            outputs = model(images, sequences)
            loss = criterion(outputs, labels)
            total_loss += loss.item()

            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    avg_loss = total_loss / len(data_loader)
    accuracy = correct / total
    return avg_loss, accuracy

test_loss, test_accuracy = evaluate(model, data_loader, criterion)
print(f"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}")

"""## Health Data (XML: Text, Image, Graph, Time-Series)

### Step Analysis

#### 0. Parsing
"""

import xml.etree.ElementTree as ET
import pandas as pd
from google.colab import drive
from datetime import datetime

# 加载google drive
drive.mount("/content/drive")

# 用您的 XML 文件路径替换这里
file_path = '/content/drive/MyDrive/output.xml'

# 解析 XML 文件
tree = ET.parse(file_path)
root = tree.getroot()

# 提取步数数据
steps_data = []
for record in root.findall('Record'):
    if record.get('type') == 'HKQuantityTypeIdentifierStepCount':
        date = record.get('creationDate')
        value = record.get('value')
        steps_data.append({'date': date, 'steps': int(value)})

# 转换为 DataFrame
df = pd.DataFrame(steps_data)

# 将日期字符串转换为 datetime 对象
df['date'] = pd.to_datetime(df['date'])

# 对步数进行简单统计分析
print("步数统计分析:")
print(df.groupby(df['date'].dt.date)['steps'].sum().describe())

# 可以根据需要进行更多复杂的分析

"""#### 1. Plotting on Statistics"""

import matplotlib.pyplot as plt

# 设置图表大小
plt.figure(figsize=(10, 6))

# 绘制每天的步数
df.groupby(df['date'].dt.date)['steps'].sum().plot(kind='line')

plt.title('Daily Step Count Over Time')
plt.xlabel('Date')
plt.ylabel('Steps')
plt.show()

# 添加星期列
df['weekday'] = df['date'].dt.day_name()

# 计算每个星期的平均步数
weekday_steps = df.groupby('weekday')['steps'].mean().reindex(['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])

# 绘制图表
weekday_steps.plot(kind='bar')
plt.title('Average Steps by Day of Week')
plt.xlabel('Day of Week')
plt.ylabel('Average Steps')
plt.show()

# 定义步数水平的分类
def categorize_steps(steps):
    if steps < 5000:
        return 'Low'
    elif 5000 <= steps < 10000:
        return 'Moderate'
    else:
        return 'High'

df['activity_level'] = df['steps'].apply(categorize_steps)

# 计算每个类别的频率
activity_levels = df['activity_level'].value_counts(normalize=True) * 100

# 绘制图表
activity_levels.plot(kind='bar')
plt.title('Activity Level Distribution')
plt.xlabel('Activity Level')
plt.ylabel('Percentage')
plt.show()

# 计算日步数总和
daily_steps = df.groupby(df['date'].dt.date)['steps'].sum()

# 计算均值和标准差
mean_steps = daily_steps.mean()
std_steps = daily_steps.std()

# 寻找异常值
outliers = daily_steps[(daily_steps < mean_steps - 2 * std_steps) | (daily_steps > mean_steps + 2 * std_steps)]
print("异常活动日：")
print(outliers)

"""#### 2. Time-Series

##### XML to CSV
"""

import xml.etree.ElementTree as ET
import pandas as pd

def parse_xml_to_csv(xml_file, csv_file):
    tree = ET.parse(xml_file)
    root = tree.getroot()

    health_data = []
    for record in root.findall('Record'):
        record_type = record.get('type')
        if record_type in ['HKQuantityTypeIdentifierStepCount', 'HKQuantityTypeIdentifierHeartRate']:
            date = record.get('creationDate')
            value = record.get('value')
            health_data.append({'date': date, 'type': record_type, 'value': value})

    df = pd.DataFrame(health_data)
    df.to_csv(csv_file, index=False)

# 使用您的 XML 文件路径和期望的 CSV 文件路径替换这里
xml_file_path = '/content/drive/MyDrive/output.xml'
csv_file_path = '/content/drive/MyDrive/output.csv'

parse_xml_to_csv(xml_file_path, csv_file_path)

"""##### Visualization"""

import pandas as pd
from prophet import Prophet
import matplotlib.pyplot as plt

# 读取CSV文件
csv_file_path = '/content/drive/MyDrive/output.csv'
df = pd.read_csv(csv_file_path)

# 将日期列转换为datetime类型，并筛选步数数据
df['date'] = pd.to_datetime(df['date'])
steps_data = df[df['type'] == 'HKQuantityTypeIdentifierStepCount']

# 将数据聚合为每日步数总和
daily_steps = steps_data.groupby(steps_data['date'].dt.date)['value'].sum().reset_index()
daily_steps.columns = ['ds', 'y']  # Prophet需要列名为'ds'（日期）和'y'（预测值）

# 创建Prophet模型
model = Prophet()
model.fit(daily_steps)

# 构建未来日期的数据帧
future = model.make_future_dataframe(periods=30)  # 预测接下来30天的趋势

# 进行预测
forecast = model.predict(future)

# 绘制预测结果
fig1 = model.plot(forecast)
plt.title('Step Count Forecast')
plt.ylabel('Total Steps')
plt.xlabel('Date')

# 显示图形
plt.show()

"""#### 3. Graph to Image"""

!pip install spacy
python -m spacy download en_core_web_sm



from google.colab import drive
import xml.etree.ElementTree as ET
import pandas as pd

drive.mount('/content/drive')

def parse_health_data(xml_file):
    tree = ET.parse(xml_file)
    root = tree.getroot()

    health_data = []
    for record in root.findall('.//Record'):
        health_record = {
            'type': record.get('type'),
            'value': record.get('value'),
            'date': record.get('startDate')  # 或 'endDate'
        }
        health_data.append(health_record)

    return health_data

# 使用函数解析数据
xml_file = '/content/drive/MyDrive/output.xml'
health_data = parse_health_data(xml_file)

import networkx as nx

def build_health_graph(health_data):
    G = nx.Graph()

    for record in health_data:
        # 将日期作为节点
        date_node = record['date']
        G.add_node(date_node, type='date')

        # 将健康指标作为节点，并添加边连接到日期
        health_node = f"{record['type']}_{record['date']}"
        G.add_node(health_node, type=record['type'], value=record['value'])
        G.add_edge(date_node, health_node)

    return G

health_graph = build_health_graph(health_data)

import networkx as nx

def build_large_health_graph(health_data):
    G = nx.Graph()

    for record in health_data:
        # 为了处理大型数据，可能需要简化节点和边的属性
        date_node = record['date']
        health_node = f"{record['type']}_{record['date']}"

        # 可能需要根据数据的性质来调整节点和边的构建方式
        if not G.has_node(date_node):
            G.add_node(date_node)
        if not G.has_node(health_node):
            G.add_node(health_node)

        G.add_edge(date_node, health_node)

    return G

# 假设 health_data 是大型数据集
large_health_graph = build_large_health_graph(large_health_data)

import matplotlib.pyplot as plt

# 可视化数据图
plt.figure(figsize=(12, 8))
nx.draw(health_graph, with_labels=True, font_weight='bold')
plt.show()

import matplotlib.pyplot as plt

plt.figure(figsize=(12, 8))
nx.draw(health_graph, with_labels=True, font_weight='bold')
plt.show()

"""##### To Graph"""



"""##### To Image"""



"""### Heart Beat Analysis"""

from google.colab import drive
import xml.etree.ElementTree as ET

# 递归函数打印节点的属性
def print_attributes(element, indent=0):
    for child in element:
        attributes = child.attrib  # 获取节点的所有属性
        if attributes:
            print("  " * indent + child.tag + ": " + str(attributes))
        print_attributes(child, indent+1)  # 递归处理子节点

# 加载并解析XML文件
drive.mount("/content/drive")
tree = ET.parse('drive/MyDrive/output.xml')
root = tree.getroot()

# 打印根节点的属性
print(root.tag + ": " + str(root.attrib))

# 从根节点开始递归打印所有属性
print_attributes(root)

import xml.etree.ElementTree as ET
import json

# 解析XML文件
tree = ET.parse('drive/MyDrive/output.xml')
root = tree.getroot()

# 假设每个Record节点都包含一个JSON字符串
for record in root.findall('.//Record'):
    # 获取节点文本，它是一个JSON字符串
    json_text = record.text
    # 解析JSON
    data = json.loads(json_text)

    # 提取'type'字段
    record_type = data['type']
    print(f"Original type: {record_type}")

    # 这里可以根据需要修改'type'字段
    data['type'] = 'YourNewTypeValue'

    # 把修改后的数据转换回JSON字符串并更新XML节点文本
    record.text = json.dumps(data)

# 如果需要，可以将修改后的XML树写回文件
tree.write('modified_example.xml')

import xml.etree.ElementTree as ET

def parse_health_data(xml_file):
    """
    解析苹果健康数据的XML文件。
    """
    # 解析XML文件
    tree = ET.parse(xml_file)
    root = tree.getroot()

    # 遍历XML文件中的记录
    for record in root.findall('Record'):
        # 提取感兴趣的数据，例如类型、日期和值
        record_type = record.get('type')
        record_date = record.get('startDate')
        record_value = record.get('value')

        # 打印或处理记录数据
        print(f"Type: {record_type}, Date: {record_date}, Value: {record_value}")

# 使用示例
xml_file_path = '.xml'  # 替换为你的文件路径
parse_health_data(xml_file_path)

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

# 假设df_heart_rates和df_hrv已经包含了正确的特征和标签（'label'）
# 'label'可以是基于心理评估的情绪或压力标签，例如：0 = '低压力', 1 = '高压力'

# 示例：简单的随机森林分类器
X = df_heart_rates[['heart_rate', 'hrv']]  # 特征
y = df_heart_rates['label']  # 标签

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

clf = RandomForestClassifier()
clf.fit(X_train, y_train)

# 评估模型
accuracy = clf.score(X_test, y_test)
print(f"模型准确率：{accuracy:.2f}")



"""### Sleep Time Analysis"""



"""### Harvard Clinical-NLP

#### Depression Analysis: Step, Heart Beat, and Sleep Time
"""



"""#### Anxiety Analysis: Traces, Eye Motion, and Captions"""



"""#### Microbiology: Genomics, Immunology, and

### Tertiary-Modal Learning
"""

import librosa

# 假设 audio_file 是音频文件路径
y, sr = librosa.load(audio_file)
mfccs = librosa.feature.mfcc(y=y, sr=sr)

from transformers import BertTokenizer, BertModel

tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
model = BertModel.from_pretrained('bert-base-uncased')

# 假设 text 是要分析的文本
inputs = tokenizer(text, return_tensors="pt", max_length=512, truncation=True)
outputs = model(**inputs)

import cv2
import dlib

# 假设 image_file 是图像文件路径
image = cv2.imread(image_file)
face_detector = dlib.get_frontal_face_detector()
faces = face_detector(image, 1)
# 对于每个检测到的脸部，提取特征

"""## Federated Learning

### 同态加密
"""

!pip install pycryptodome numpy

from Crypto.PublicKey import RSA
from Crypto.Cipher import PKCS1_OAEP
import numpy as np

def generate_key_pair(key_size=2048):
    key = RSA.generate(key_size)
    private_key = key.export_key()
    public_key = key.publickey().export_key()
    return private_key, public_key

def encrypt_message(message, public_key):
    rsa_key = RSA.import_key(public_key)
    rsa_cipher = PKCS1_OAEP.new(rsa_key)
    encrypted_message = rsa_cipher.encrypt(message)
    return encrypted_message

def decrypt_message(encrypted_message, private_key):
    rsa_key = RSA.import_key(private_key)
    rsa_cipher = PKCS1_OAEP.new(rsa_key)
    decrypted_message = rsa_cipher.decrypt(encrypted_message)
    return decrypted_message

# 生成密钥对
private_key, public_key = generate_key_pair()

# 加密一个简单的消息
original_message = b"Hello, World!"
encrypted_message = encrypt_message(original_message, public_key)
print(f"Encrypted: {encrypted_message}")

# 解密消息
decrypted_message = decrypt_message(encrypted_message, private_key)
print(f"Decrypted: {decrypted_message}")

"""### 多方安全计算"""

import random

def generate_shares(secret, n, threshold):
    """ 分割秘密为n份，其中任意threshold份可以重建秘密 """
    coeffs = [random.randint(0, 10**5) for _ in range(threshold - 1)] + [secret]
    shares = [(i, sum([coeff * (i ** power) for power, coeff in enumerate(coeffs)])) for i in range(1, n + 1)]
    return shares

def reconstruct_secret(shares, threshold):
    """ 从shares中重建秘密 """
    sum = 0
    for j, share_j in shares:
        product = share_j
        for i, _ in shares:
            if i != j:
                product *= i / (i - j)
        sum += product
    return round(sum)

# 定义秘密和参与者数量
secret = 12345
num_participants = 5
threshold = 3

# 生成秘密份额
shares = generate_shares(secret, num_participants, threshold)

# 选取任意threshold份进行秘密重建
selected_shares = random.sample(shares, threshold)
reconstructed_secret = reconstruct_secret(selected_shares, threshold)

print("原始秘密:", secret)
print("重建秘密:", reconstructed_secret)

"""### 差分隐私"""

!pip install --upgrade opacus

import torch
from torch import nn, optim
from torchvision import datasets, transforms
from opacus import PrivacyEngine

# 加载数据集
transform = transforms.Compose([transforms.ToTensor()])
train_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)
train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)

# 定义一个简单的模型
model = nn.Sequential(
    nn.Flatten(),
    nn.Linear(28 * 28, 128),
    nn.ReLU(),
    nn.Linear(128, 10)
)

# 定义损失函数和优化器
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.05)

# 应用差分隐私
privacy_engine = PrivacyEngine()
model, optimizer, train_loader = privacy_engine.make_private(
    module=model,
    optimizer=optimizer,
    data_loader=train_loader,
    noise_multiplier=1.0,  # 添加的噪声量
    max_grad_norm=1.0,     # 梯度的裁剪阈值
)

# 训练模型
num_epochs = 3
for epoch in range(num_epochs):
    for inputs, targets in train_loader:
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, targets)
        loss.backward()
        optimizer.step()
    print(f"Epoch {epoch+1}/{num_epochs} completed.")

# 获取和打印隐私预算
target_delta = 1e-5  # 一个常见的选择，具体值取决于数据集的大小和隐私要求
epsilon = privacy_engine.get_epsilon(delta=target_delta)
print(f"Spent privacy budget: ε = {epsilon}, δ = {target_delta}")